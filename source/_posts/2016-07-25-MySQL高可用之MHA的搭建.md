---
title: MySQL高可用之MHA的搭建
categories: 技术与干货
tag: MySQL
abbrlink: d872247d
date: 2016-07-25 00:00:00
---
# MHA简介
> MHA（Master High Availability）目前在MySQL高可用方面是一个相对成熟的解决方案，它由日本DeNA公司youshimaton（现就职于Facebook公司）开发，是一套优秀的作为MySQL高可用性环境下故障切换和主从提升的高可用软件。在MySQL故障切换过程中，MHA能做到在0~30秒之内自动完成数据库的故障切换操作，并且在进行故障切换的过程中，MHA能在最大程度上保证数据的一致性，以达到真正意义上的高可用。

<!--more-->

> 该软件由两部分组成：MHA Manager（管理节点）和MHA Node（数据节点）。MHA Manager可以单独部署在一台独立的机器上管理多个master-slave集群，也可以部署在一台slave节点上。MHA Node运行在每台MySQL服务器上，MHA Manager会定时探测集群中的master节点，当master出现故障时，它可以自动将最新数据的slave提升为新的master，然后将所有其他的slave重新指向新的master。整个故障转移过程对应用程序完全透明。

> 在MHA自动故障切换过程中，MHA试图从宕机的主服务器上保存二进制日志，最大程度的保证数据的不丢失，但这并不总是可行的。例如，如果主服务器硬件故障或无法通过ssh访问，MHA没法保存二进制日志，只进行故障转移而丢失了最新的数据。使用MySQL 5.5的半同步复制，可以大大降低数据丢失的风险。MHA可以与半同步复制结合起来。如果只有一个slave已经收到了最新的二进制日志，MHA可以将最新的二进制日志应用于其他所有的slave服务器上，因此可以保证所有节点的数据一致性。

** 目前MHA主要支持一主多从的架构，要搭建MHA,要求一个复制集群中必须最少有三台数据库服务器，一主二从，即一台充当master，一台充当备用master，另外一台充当从库，因此至少需要三台服务器。 **

# MHA工作原理总结为以下几条

1. 从宕机崩溃的master保存二进制日志事件（binlog events）;
2. 识别含有最新更新的slave;
3. 应用差异的中继日志(relay log) 到其他slave;
4. 应用从master保存的二进制日志事件(binlog events);
5. 提升一个slave为新master;
6. 使用其他的slave连接新的master进行复制。

# 准备工作
> 准备四台虚拟机, 均为CentOS-7-x86_64最小化安装, iptables与SELinux均处于关闭状态, 配置好yum源(base和epel). 做好快照, 以便每次实验后快速恢复.
- 确保各节点时间保持一致
- 各节点需开启二进制日志和中继日志
- 各节点彼此可通过主机名进行通信
- 各节点彼此间无密钥进行通信

```
HostA(Master)
OS: CentOS-7-x86_64
hostname: 80e54d87.twoyang.com
eno16777736: 172.18.71.101/16
gateway: 172.18.0.1

HostB(Slave)
OS: CentOS-7-x86_64
hostname: b9cf468b.twoyang.com
eno16777736: 172.18.71.102/16
gateway: 172.18.0.1

HostC(Slave)
OS: CentOS-7-x86_64
hostname: 1f5fafa6.twoyang.com
eno16777736: 172.18.71.103/16
gateway: 172.18.0.1

HostD(MHA Manager)
OS: CentOS-7-x86_64
hostname: 1478a474.twoyang.com
eno16777736: 172.18.71.130/16
gateway: 172.18.0.1
```
** 先不管MHA, 按照主从复制模型搭建好集群. **

# 主从复制
## HostA(Master)
```
[root@80e54d87 ~]# yum install -y mariadb-server

sed -i '/\[server\]/a\character-set-server=utf8' /etc/my.cnf.d/server.cnf
sed -i '/\[server\]/a\collation-server=utf8_general_ci' /etc/my.cnf.d/server.cnf
sed -i '/\[server\]/a\default-storage-engine=InnoDB' /etc/my.cnf.d/server.cnf
sed -i '/\[server\]/a\innodb-file-per-table=TRUE' /etc/my.cnf.d/server.cnf
sed -i '/\[server\]/a\skip-name-resolve=TRUE' /etc/my.cnf.d/server.cnf
sed -i '/\[server\]/a\log_bin=master-binlog' /etc/my.cnf.d/server.cnf
# 注意server_id为集群内的唯一标识.
sed -i '/\[server\]/a\server_id=1' /etc/my.cnf.d/server.cnf

[root@80e54d87 ~]# systemctl start mariadb.service
[root@80e54d87 ~]# mysql
...
# 创建用户前记录下二进制日志文件位置, 一会儿让从节点从此处开始复制, 就会自动创建此用户了.
# 因为主节点宕机时, 从节点有可能会被MHA管理节点提升为主节点供其它从节点复制.
MariaDB [(none)]> SHOW MASTER STATUS;
+----------------------+----------+--------------+------------------+
| File                 | Position | Binlog_Do_DB | Binlog_Ignore_DB |
+----------------------+----------+--------------+------------------+
| master-binlog.000003 |      245 |              |                  |
+----------------------+----------+--------------+------------------+
1 row in set (0.00 sec)
# 授权用户'repl'@'172.18.71.%'可以复制数据
MariaDB [(none)]> GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'repl'@'172.18.71.%' IDENTIFIED BY 'magedu';
Query OK, 0 rows affected (0.00 sec)
# 另外还得创建一个SUPER权限的用户用于MHA管理节点来控制.
MariaDB [(none)]> GRANT ALL PRIVILEGES ON *.* TO 'mha'@'%' IDENTIFIED BY 'magedu';
Query OK, 0 rows affected (0.00 sec)
MariaDB [(none)]> FLUSH PRIVILEGES;
Query OK, 0 rows affected (0.00 sec)
```

## HostB(Slave)
```
[root@b9cf468b ~]# yum install -y mariadb-server

sed -i '/\[server\]/a\character-set-server=utf8' /etc/my.cnf.d/server.cnf
sed -i '/\[server\]/a\collation-server=utf8_general_ci' /etc/my.cnf.d/server.cnf
sed -i '/\[server\]/a\default-storage-engine=InnoDB' /etc/my.cnf.d/server.cnf
sed -i '/\[server\]/a\innodb-file-per-table=TRUE' /etc/my.cnf.d/server.cnf
sed -i '/\[server\]/a\skip-name-resolve=TRUE' /etc/my.cnf.d/server.cnf
# 从节点也要开启二进制日志, 因为可能会被提升为主节点.
sed -i '/\[server\]/a\log_bin=master-binlog' /etc/my.cnf.d/server.cnf
sed -i '/\[server\]/a\relay_log=relaylog' /etc/my.cnf.d/server.cnf
# 对于某些滞后从库的恢复依赖于其他从库的relay_log，因此采取禁用自动删除功能以及定期清理的办法.
sed -i '/\[server\]/a\relay_log_purge=OFF' /etc/my.cnf.d/server.cnf
sed -i '/\[server\]/a\read-only=ON' /etc/my.cnf.d/server.cnf
# 注意server_id为集群内的唯一标识.
sed -i '/\[server\]/a\server_id=5' /etc/my.cnf.d/server.cnf

[root@b9cf468b ~]# systemctl start mariadb.service
[root@b9cf468b ~]# mysql
...
# 指向HostA将其作为主节点
MariaDB [(none)]> CHANGE MASTER TO MASTER_HOST='172.18.71.101', MASTER_USER='repl', MASTER_PASSWORD='magedu', MASTER_LOG_FILE='master-binlog.000003', MASTER_LOG_POS=245;
Query OK, 0 rows affected (0.00 sec)

# 启动从节点, 即启动IO_thread和SQL_thread进程, 开始复制.
MariaDB [(none)]> START SLAVE;
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]> SHOW SLAVE STATUS\G
*************************** 1. row ***************************
               Slave_IO_State: Waiting for master to send event
                  Master_Host: 172.18.71.101
                  Master_User: repl
                  Master_Port: 3306
                Connect_Retry: 60
              Master_Log_File: master-binlog.000003
          Read_Master_Log_Pos: 555
               Relay_Log_File: relaylog.000002
                Relay_Log_Pos: 843
        Relay_Master_Log_File: master-binlog.000003
             Slave_IO_Running: Yes
            Slave_SQL_Running: Yes
......
1 row in set (0.00 sec)
```

## HostC(Slave)
** HostC与HostB做相同配置, 仅server_id必须不同. **

# MHA
## 集群初始化

> 建立主机信任, 时间同步, 统一增加yum源. 这一步其实在哪个节点上做都可以, 我这里选择HostA.

```
# 写了个脚本来做这个事情
[root@80e54d87 ~]# wget https://raw.githubusercontent.com/twoyang0917/LearnInMagedu/master/shell/sshtrust.sh
# 有效代码是这个样子的
[root@80e54d87 ~]# cat sshtrust.sh
...
HOSTS=("172.18.71.101" "172.18.71.102")

if ! [ $# -eq 1 ]; then
   echo "$0 --key"
   echo "$0 \"COMMAND\""
   exit 1
fi 

if [ "$1" = "--key" ]; then
    [ -f ~/.ssh/id_rsa ] || ssh-keygen -t rsa -f ~/.ssh/id_rsa -N ''
    [ -f ~/.ssh/id_rsa.pub ] && cat ~/.ssh/id_rsa.pub > ~/.ssh/authorized_keys && chmod 600 ~/.ssh/authorized_keys
    for host in ${HOSTS[*]}; do
        # 因为其它节点上都没有~/.ssh这么一个目录, 还得远程创建, 这导致分发密钥时要输两次密码还挺烦的.
        ssh root@$host "[ -d ~/.ssh ] || mkdir ~/.ssh"
        scp -p ~/.ssh/{id_rsa,authorized_keys} root@$host:~/.ssh/
    done
else
    for host in ${HOSTS[*]}; do
        ssh root@$host $1
    done
fi
# 将集群中所有节点IP地址(包括本机)都加入这个主机列表数组
[root@80e54d87 ~]# vim sshtrust.sh
HOSTS=("172.18.71.101" "172.18.71.102" "172.18.71.103" "172.18.71.130")
# 分发密钥, 两两节点间均建立主机信任.
[root@80e54d87 ~]# bash sshtrust.sh --key
Generating public/private rsa key pair.
Created directory '/root/.ssh'.
Your identification has been saved in /root/.ssh/id_rsa.
Your public key has been saved in /root/.ssh/id_rsa.pub.
The key fingerprint is:
02:de:f2:86:5b:4b:3d:2b:70:cc:1c:c9:d2:65:5d:0b root@80e54d87.twoyang.com
The key's randomart image is:
+--[ RSA 2048]----+
|         .E..    |
|        o .. .   |
|    .o +    .    |
|   ..o=          |
|    o=o.S        |
|    .+=o         |
|    .o= o        |
|     =.. o       |
|    . ...        |
+-----------------+
The authenticity of host '172.18.71.101 (172.18.71.101)' can't be established.
ECDSA key fingerprint is 2d:37:94:8b:81:ea:57:bc:93:18:44:d6:f6:97:6c:5b.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '172.18.71.101' (ECDSA) to the list of known hosts.
The authenticity of host '172.18.71.102 (172.18.71.102)' can't be established.
ECDSA key fingerprint is 07:d0:4c:77:32:95:bc:df:8b:c1:b0:41:d6:af:66:59.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '172.18.71.102' (ECDSA) to the list of known hosts.
root@172.18.71.102's password: 
root@172.18.71.102's password: 
id_rsa                                                                        100% 1679     1.6KB/s   00:00    
authorized_keys                                                               100%  407     0.4KB/s   00:00    
The authenticity of host '172.18.71.103 (172.18.71.103)' can't be established.
ECDSA key fingerprint is e5:49:95:0f:18:ac:e8:e3:22:6a:7e:09:ae:f9:61:55.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '172.18.71.103' (ECDSA) to the list of known hosts.
root@172.18.71.103's password: 
root@172.18.71.103's password: 
id_rsa                                                                        100% 1679     1.6KB/s   00:00    
authorized_keys                                                               100%  407     0.4KB/s   00:00    
The authenticity of host '172.18.71.130 (172.18.71.130)' can't be established.
ECDSA key fingerprint is 6d:01:30:42:82:4a:ae:5a:ec:7e:62:7c:7e:31:64:b9.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '172.18.71.130' (ECDSA) to the list of known hosts.
root@172.18.71.130's password: 
root@172.18.71.130's password: 
id_rsa                                                                        100% 1679     1.6KB/s   00:00    
authorized_keys                                                               100%  407     
0.4KB/s   00:00
# 同步时间
[root@80e54d87 ~]# bash sshtrust.sh "ntpdate 172.18.0.1"
 6 Jun 20:55:36 ntpdate[3354]: step time server 172.18.0.1 offset 2644756.261973 sec
 6 Jun 20:53:30 ntpdate[11248]: step time server 172.18.0.1 offset 2640569.256399 sec
 6 Jun 20:53:36 ntpdate[40408]: step time server 172.18.0.1 offset -2.854146 sec
 6 Jun 20:53:42 ntpdate[3457]: step time server 172.18.0.1 offset 3975759.234646 sec
[root@80e54d87 ~]# bash sshtrust.sh "hwclock --systohc"
[root@80e54d87 ~]# bash sshtrust.sh date
Mon Jun  6 20:56:25 CST 2016
Mon Jun  6 20:56:25 CST 2016
Mon Jun  6 20:56:25 CST 2016
Mon Jun  6 20:56:25 CST 2016
# 因为MHA在cenots官方yum源中没有提供, 所以从Google Driver上下载下来做成了yum源.
[root@80e54d87 ~]# bash sshtrust.sh "yum-config-manager --add-repo=http://172.18.71.254/templates/twoyang-c7.repo"
Loaded plugins: fastestmirror, langpacks
adding repo from: http://172.18.71.254/templates/twoyang-c7.repo
grabbing file http://172.18.71.254/templates/twoyang-c7.repo to /etc/yum.repos.d/twoyang-c7.repo
repo saved to /etc/yum.repos.d/twoyang-c7.repo
Loaded plugins: fastestmirror, langpacks
adding repo from: http://172.18.71.254/templates/twoyang-c7.repo
grabbing file http://172.18.71.254/templates/twoyang-c7.repo to /etc/yum.repos.d/twoyang-c7.repo
repo saved to /etc/yum.repos.d/twoyang-c7.repo
Loaded plugins: fastestmirror, langpacks
adding repo from: http://172.18.71.254/templates/twoyang-c7.repo
grabbing file http://172.18.71.254/templates/twoyang-c7.repo to /etc/yum.repos.d/twoyang-c7.repo
repo saved to /etc/yum.repos.d/twoyang-c7.repo
Loaded plugins: fastestmirror, langpacks
adding repo from: http://172.18.71.254/templates/twoyang-c7.repo
grabbing file http://172.18.71.254/templates/twoyang-c7.repo to /etc/yum.repos.d/twoyang-c7.repo
repo saved to /etc/yum.repos.d/twoyang-c7.repo
```

# 安装配置MHA
```
# 集群内所有节点(包括管理节点)需要安装Node包
[root@80e54d87 ~]# bash sshtrust.sh "yum install -y mha4mysql-node.noarch"

# HostD作为MHA管理节点需要安装Manager包
[root@1478a474 ~]# yum install -y mha4mysql-manager.noarch

# 默认是没有配置文件, 自己建立目录和配置文件.
[root@1478a474 ~]# mkdir /etc/masterha
[root@1478a474 ~]# vim /etc/masterha/app1.cnf
[server default]
user=mha	#  被控节点授权给管理节点SUPER权限的用户
password=magedu	#  被控节点授权给管理节点SUPER权限用户的口令
manager_workdir=/data/masterha/app1	# 管理节点的工作目录, 会自动建立.
manager_log=/data/masterha/app1/manager.log	# 管理节点的日志
remote_workdir=/data/masterha/app1 # 被控节点的工作目录, 会自动建立.
ssh_user=root	# 被控节点的ssh用户
repl_user=repl	# 用于数据库复制的用户
repl_password=magedu # 用于数据库复制的用户的口令
ping_interval=1 # 被控节点的健康检查时间间隔

[server1]
hostname=172.18.71.101
candidate_master=1	# 作为主节点候选

[server2]
hostname=172.18.71.102
candidate_master=1

[server3]
hostname=172.18.71.103
no_master=1	# 永远不作为主节点

# 用mha提供的脚本做主机信任检查.
[root@1478a474 ~]# masterha_check_ssh --conf=/etc/masterha/app1.cnf
Mon Jun  6 22:12:23 2016 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping.
Mon Jun  6 22:12:23 2016 - [info] Reading application default configuration from /etc/masterha/app1.cnf..
Mon Jun  6 22:12:23 2016 - [info] Reading server configuration from /etc/masterha/app1.cnf..
Mon Jun  6 22:12:23 2016 - [info] Starting SSH connection tests..
Mon Jun  6 22:12:24 2016 - [debug] 
Mon Jun  6 22:12:24 2016 - [info] All SSH connection tests passed successfully.

# 用mha提供的脚本做数据库复制检查.
[root@1478a474 ~]# masterha_check_repl --conf=/etc/masterha/app1.cnf
Mon Jun  6 22:19:40 2016 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping.
Mon Jun  6 22:19:40 2016 - [info] Reading application default configuration from /etc/masterha/app1.cnf..
Mon Jun  6 22:19:40 2016 - [info] Reading server configuration from /etc/masterha/app1.cnf..
Mon Jun  6 22:19:40 2016 - [info] MHA::MasterMonitor version 0.57.
Mon Jun  6 22:19:40 2016 - [info] GTID failover mode = 0
Mon Jun  6 22:19:40 2016 - [info] Dead Servers:
Mon Jun  6 22:19:40 2016 - [info] Alive Servers:
Mon Jun  6 22:19:40 2016 - [info]   172.18.71.101(172.18.71.101:3306)
Mon Jun  6 22:19:40 2016 - [info]   172.18.71.102(172.18.71.102:3306)
Mon Jun  6 22:19:40 2016 - [info]   172.18.71.103(172.18.71.103:3306)
Mon Jun  6 22:19:40 2016 - [info] Alive Slaves:
Mon Jun  6 22:19:40 2016 - [info]   172.18.71.102(172.18.71.102:3306)  Version=5.5.44-MariaDB-log (oldest major version between slaves) log-bin:enabled
Mon Jun  6 22:19:40 2016 - [info]     Replicating from 172.18.71.101(172.18.71.101:3306)
Mon Jun  6 22:19:40 2016 - [info]     Primary candidate for the new Master (candidate_master is set)
Mon Jun  6 22:19:40 2016 - [info]   172.18.71.103(172.18.71.103:3306)  Version=5.5.44-MariaDB-log (oldest major version between slaves) log-bin:enabled
Mon Jun  6 22:19:40 2016 - [info]     Replicating from 172.18.71.101(172.18.71.101:3306)
Mon Jun  6 22:19:40 2016 - [info]     Not candidate for the new Master (no_master is set)
Mon Jun  6 22:19:40 2016 - [info] Current Alive Master: 172.18.71.101(172.18.71.101:3306)
Mon Jun  6 22:19:40 2016 - [info] Checking slave configurations..
Mon Jun  6 22:19:40 2016 - [info] Checking replication filtering settings..
Mon Jun  6 22:19:40 2016 - [info]  binlog_do_db= , binlog_ignore_db= 
Mon Jun  6 22:19:40 2016 - [info]  Replication filtering check ok.
Mon Jun  6 22:19:40 2016 - [info] GTID (with auto-pos) is not supported
Mon Jun  6 22:19:40 2016 - [info] Starting SSH connection tests..
Mon Jun  6 22:19:42 2016 - [info] All SSH connection tests passed successfully.
Mon Jun  6 22:19:42 2016 - [info] Checking MHA Node version..
Mon Jun  6 22:19:42 2016 - [info]  Version check ok.
Mon Jun  6 22:19:42 2016 - [info] Checking SSH publickey authentication settings on the current master..
Mon Jun  6 22:19:43 2016 - [info] HealthCheck: SSH to 172.18.71.101 is reachable.
Mon Jun  6 22:19:43 2016 - [info] Master MHA Node version is 0.57.
Mon Jun  6 22:19:43 2016 - [info] Checking recovery script configurations on 172.18.71.101(172.18.71.101:3306)..
Mon Jun  6 22:19:43 2016 - [info]   Executing command: save_binary_logs --command=test --start_pos=4 --binlog_dir=/var/lib/mysql,/var/log/mysql --output_file=/data/masterha/app1/save_binary_logs_test --manager_version=0.57 --start_file=master-binlog.000003 
Mon Jun  6 22:19:43 2016 - [info]   Connecting to root@172.18.71.101(172.18.71.101:22).. 
  Creating /data/masterha/app1 if not exists.. Creating directory /data/masterha/app1.. done.
   ok.
  Checking output directory is accessible or not..
   ok.
  Binlog found at /var/lib/mysql, up to master-binlog.000003
Mon Jun  6 22:19:43 2016 - [info] Binlog setting check done.
Mon Jun  6 22:19:43 2016 - [info] Checking SSH publickey authentication and checking recovery script configurations on all alive slave servers..
Mon Jun  6 22:19:43 2016 - [info]   Executing command : apply_diff_relay_logs --command=test --slave_user='mha' --slave_host=172.18.71.102 --slave_ip=172.18.71.102 --slave_port=3306 --workdir=/data/masterha/app1 --target_version=5.5.44-MariaDB-log --manager_version=0.57 --relay_log_info=/var/lib/mysql/relay-log.info  --relay_dir=/var/lib/mysql/  --slave_pass=xxx
Mon Jun  6 22:19:43 2016 - [info]   Connecting to root@172.18.71.102(172.18.71.102:22).. 
Creating directory /data/masterha/app1.. done.
  Checking slave recovery environment settings..
    Opening /var/lib/mysql/relay-log.info ... ok.
    Relay log found at /var/lib/mysql, up to relaylog.000006
    Temporary relay log file is /var/lib/mysql/relaylog.000006
    Testing mysql connection and privileges.. done.
    Testing mysqlbinlog output.. done.
    Cleaning up test file(s).. done.
Mon Jun  6 22:19:43 2016 - [info]   Executing command : apply_diff_relay_logs --command=test --slave_user='mha' --slave_host=172.18.71.103 --slave_ip=172.18.71.103 --slave_port=3306 --workdir=/data/masterha/app1 --target_version=5.5.44-MariaDB-log --manager_version=0.57 --relay_log_info=/var/lib/mysql/relay-log.info  --relay_dir=/var/lib/mysql/  --slave_pass=xxx
Mon Jun  6 22:19:43 2016 - [info]   Connecting to root@172.18.71.103(172.18.71.103:22).. 
Creating directory /data/masterha/app1.. done.
  Checking slave recovery environment settings..
    Opening /var/lib/mysql/relay-log.info ... ok.
    Relay log found at /var/lib/mysql, up to relaylog.000004
    Temporary relay log file is /var/lib/mysql/relaylog.000004
    Testing mysql connection and privileges.. done.
    Testing mysqlbinlog output.. done.
    Cleaning up test file(s).. done.
Mon Jun  6 22:19:43 2016 - [info] Slaves settings check done.
Mon Jun  6 22:19:43 2016 - [info] 
172.18.71.101(172.18.71.101:3306) (current master)
 +--172.18.71.102(172.18.71.102:3306)
 +--172.18.71.103(172.18.71.103:3306)

Mon Jun  6 22:19:43 2016 - [info] Checking replication health on 172.18.71.102..
Mon Jun  6 22:19:43 2016 - [info]  ok.
Mon Jun  6 22:19:43 2016 - [info] Checking replication health on 172.18.71.103..
Mon Jun  6 22:19:43 2016 - [info]  ok.
# 这里已经提示了没有定义主节点故障VIP如何漂移的脚本.
Mon Jun  6 22:19:43 2016 - [warning] master_ip_failover_script is not defined.
# 也没有定义STONITH脚本, 以防止集群脑裂.
Mon Jun  6 22:19:43 2016 - [warning] shutdown_script is not defined.
Mon Jun  6 22:19:43 2016 - [info] Got exit code 0 (Not master dead).

MySQL Replication Health is OK.

# 测试通过就可以启动MHA了
[root@1478a474 ~]# nohup masterha_manager --conf=/etc/masterha/app1.cnf &> /data/masterha/app1/manager.log &

# 查看状态
[root@1478a474 ~]# masterha_check_status --conf=/etc/masterha/app1.cnf
app1 (pid:30255) is running(0:PING_OK), master:172.18.71.101

# 如需停止MHA, 执行以下命令.
[root@1478a474 ~]# masterha_stop --conf=/etc/masterha/app1.cnf
Stopped app1 successfully.
[1]+  Exit 1                  nohup masterha_manager --conf=/etc/masterha/app1.cnf &>/data/masterha/app1/manager.log

```

# 测试验证
关闭HostA(Master)的mariadb服务, 期望MHA能够检测到HostA故障, 将HostB提升为Master.

```
# 杀死HostA上的mysqld和mysqld_safe进程
[root@80e54d87 ~]# killall -9 mysqld mysqld_safe

# 查看MHA的日志, 可以看到故障转移报告.
[root@1478a474 ~]# less /data/masterha/app1/manager.log
...
----- Failover Report -----

app1: MySQL Master failover 172.18.71.101(172.18.71.101:3306) to 172.18.71.102(172.18.71.102:3306) succeeded

Master 172.18.71.101(172.18.71.101:3306) is down!

Check MHA Manager logs at 1478a474.twoyang.com:/data/masterha/app1/manager.log for details.

Started automated(non-interactive) failover.
The latest slave 172.18.71.102(172.18.71.102:3306) has all relay logs for recovery.
Selected 172.18.71.102(172.18.71.102:3306) as a new master.
172.18.71.102(172.18.71.102:3306): OK: Applying all logs succeeded.
172.18.71.103(172.18.71.103:3306): This host has the latest relay log events.
Generating relay diff files from the latest slave succeeded.
172.18.71.103(172.18.71.103:3306): OK: Applying all logs succeeded. Slave started, replicating from 172.18.71.102(172.18.71.102:3306)
172.18.71.102(172.18.71.102:3306): Resetting slave info succeeded.
Master failover to 172.18.71.102(172.18.71.102:3306) completed successfully.

# 再看另一个从节点HostC上, MHA已经将其主节点由HostA修改为了HostB了.
MariaDB [(none)]> SHOW SLAVE STATUS\G
*************************** 1. row ***************************
               Slave_IO_State: Waiting for master to send event
                  Master_Host: 172.18.71.102
                  Master_User: repl
                  Master_Port: 3306
                Connect_Retry: 60
              Master_Log_File: master-binlog.000001
          Read_Master_Log_Pos: 245
               Relay_Log_File: relaylog.000002
                Relay_Log_Pos: 533
        Relay_Master_Log_File: master-binlog.000001
             Slave_IO_Running: Yes
            Slave_SQL_Running: Yes
......
1 row in set (0.00 sec)

# 注意: 故障转移完成后, MHA将会自动停止进程.
[root@1478a474 ~]# masterha_check_status --conf=/etc/masterha/app1.cnf
app1 is stopped(2:NOT_RUNNING).
```

# 最后
还有几个问题需要说明一下:
- 因为主从异步复制时难免会出现从节点落后主节点的情况, 这样主机点宕机就会出现丢失数据的情况. 所以如果是做半同步复制情况就会好很多.
- 这里没有考虑VIP和STONITH的问题, 其实前面用MHA做复制检查时已经警告过我们了. VIP地址漂移的问题可以通过脚本来实现, 也可以通过keepalived来实现. 而STONITH也可以通过脚本来实现, 不过既然是脑裂基本上就是联系不上对方, 那通过脚本来STONITH也就不太靠谱; 想靠谱基本上只有上硬件, 那可就贵了.
原文地址：[点我](http://twoyang.net/2016/06/06/mariadb%20MHA/)