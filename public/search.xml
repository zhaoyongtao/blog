<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[KVM虚拟Mac OS X Sierra]]></title>
      <url>%2Fposts%2F638d5663%2F</url>
      <content type="text"><![CDATA[KVM虚拟Mac OS X Sierra 大致可行的方法有两种： 123456第一种，重新编译内核、编译qemu、编译kvm、kvm-mod，加上OS X的支持。详情：http://www.tuicool.com/articles/JBzANrU在使用此种方法编译kvm时，报错，无法安装，文件内容都与作者标识的不一致。才疏学浅，未能成功。。。第二种,GitHub上有OSX-KVM项目，相对来说较为简单，本次采用此种方法。具体请参考：https://github.com/kholia/OSX-KVM 本文所需文件：1234在Mac下制作的Install_macOS_Sierra_OS_X_10.12.iso引导文件enoch_rev2839_boot创建的磁盘mac_hdd.imgqemu配置文件OSX_KVM.xml 链接：http://pan.baidu.com/s/1qYbe12W 密码：6znh 环境准备123456789101112131415物理机系统说明：作者在以下系统中测试过:Ubuntu 15.10 running on i5-6500 CPU.Ubuntu 16.10 running on i7-3960X CPU.Fedora 24 running on i5-6500 + i7-6600U CPU.QEMU版本：2.4.1, 2.5, 2.6.1, and 2.8.AMD CPU有问题。AMD FX-8350 可以工作，但是Phenom II X3 720不工作需要开启 Intel VT-x/AMD-v虚拟化技术本次使用环境：Ubuntu Server 16.04 LTS QEMU:2.5.0 安装qemu和virt-manager1sudo apt-get install qemu uml-utilities virt-manager 安装桥接网络管理管理工具1sudo apt-get install bridge-utils 配置桥接网络12345678910111213141516171819202122232425root@fin75:~# vim /etc/network/interface# This file describes the network interfaces available on your system# and how to activate them. For more information, see interfaces(5).source /etc/network/interfaces.d/*# The loopback network interfaceauto loiface lo inet loopbackauto br0iface br0 inet static address 172.16.0.75 network 172.16.0.0 netmask 255.255.255.0 broadcast 172.16.0.255 gateway 172.16.0.1 dns-nameservers 223.5.5.5 bridge_ports eno1 bridge_stp off bridge_fd 0 bridge_maxwait 0 post-up ip link set br0 address aa:2b:3c:4d:5e:6froot@fin75:~# reboot 注意：virbr0是安装kvm时系统建立的，为NAT网络专用，跟我们要使用的桥接完全不同 按照官方文档直接重启服务会失败，重启物理机就可以了。 参考：https://help.ubuntu.com/community/KVM/Networking 创建磁盘文件1qemu-img create -f qcow2 /u01/mac_hdd.img 200G 安装方法可以使用boot-macOS.sh/boot.sh，或者使用macOS-libvirt.xml本次使用libvirt文件的方式 修改libvirt文件1234567891011121314151617181920212223#只需修改这几处即可。#引导文件位置&lt;kernel&gt;/u01/boot/enoch_rev2839_boot&lt;/kernel&gt; #磁盘文件位置&lt;source file='/u01/mac_hdd.img'/&gt; #ISO镜像位置&lt;qemu:arg value='id=MacDVD,if=none,snapshot=on,file=/opt/Install_macOS_Sierra_OS_X_10.12.iso'/&gt;#如果有多台OS X系统，还需修改&lt;uuid&gt;c757b31e-115f-4d1a-b574-0ae7b3cc8a58&lt;/uuid&gt;#kvm中合理的Mac地址为52:54:00开头&lt;mac address='52:54:00:3d:f8:25'/&gt; #可在shell中执行以下命令获取合理的Mac地址：MACADDR="52:54:00:$(dd if=/dev/urandom bs=512 count=1 2&gt;/dev/null | md5sum | sed 's/^\(..\)\(..\)\(..\).*$/\1:\2:\3/')"; echo $MACADDR#vnc中的port需更改为与第一个虚拟机不同&lt;graphics type='vnc' port='5900' autoport='no' listen='127.0.0.1' keymap='en-us'&gt; 重新定义libvirt文件123virsh define /somepath/OSX-KVM/macOS-libvirt.xml #定义后，在/etc/libvirt/qemu/目录下会有macOS-libvirt.xml文件，以后修改后只需重新定义此文件即可 安装OS X在virt-manager中启动OSX 步骤： 选择磁盘工具 格式化KVM磁盘 退出磁盘工具，打开终端输入命令，拷贝安装文件：1cp -av /Extra /Volumes/KVMDisk 退出终端，启动安装即可！ #错误合集 virt-manager启动虚拟机，打不开安装界面，显示boot，无限重启解决办法：开启ignore_msrs1echo 1 &gt; /sys/module/kvm/parameters/ignore_msrs 开机执行12vim /etc/rc.localecho 1 &gt; /sys/module/kvm/parameters/ignore_msrs 启动域时出错:internal error: process exited while connecting to monitor: 2017-04-05 T06\:\25:53.648209Z qemu-system-x86_64: -drive id=MacDVD,if=none,snapshot=on,file=/opt/Install_macOS_Sierra_OS_X_10.12.iso: Could not open ‘/opt/Install_macOS_Sierra_OS_X_10.12.iso’: Permission denied #解决办法kvm需要selinux装载安全模块，默认的Ubuntu server没有安装selinux 123sudo apt-get install selinux#设置selinux=permissivereboot virt-manager显示乱码123456sudo apt install font-manager sudo apt install fonts-arphic-ukai sudo apt install ttf-wqy-zenhei xfonts-wqy ttf-wqy-microhei sudo apt install fonts-cwtex-fs sudo apt install ttf-hanazono sudo apt install ttf-mscorefonts-installer Ubuntu虚拟Windows需要将显示协议由Spice服务器更改为VNC服务器，并且将键映射改为：en-us，不然会出现键盘无法使用的情况 需要将显卡由QXL改为Cirrus，不然kvm安装windows系统时会卡在Starting Windows画面http://serverfault.com/questions/776406/windows-7-setup-hangs-at-starting-windows-using-proxmox-4-2 需要将NIC网卡由rtl8139更改为e1000，不然会出现断网的情况 参考https://github.com/kholia/OSX-KVMhttp://www.tuicool.com/articles/JBzANrUhttp://www.jianshu.com/p/e95c458d78bdhttps://blog.ostanin.org/2014/02/11/playing-with-mac-os-x-on-kvm/http://www.cnblogs.com/huntaiji/p/3918941.html]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[samba服务器搭建]]></title>
      <url>%2Fposts%2Feb0f8299%2F</url>
      <content type="text"><![CDATA[安装1~]# yum -y install samba samba-common samba-client samba服务器访问过慢的问题123456具体表现： samba服务正常启动，win下可以访问，打开时要等待很久解决办法： 1、查看/etc/sysconfig/network中hostname 2、编辑/etc/hosts文件，添加hostname的值到127.0.0.1 3、重启服务或服务器 配置samba配置123456789101112131415161718192021222324252627282930313233343536~]# vim /etc/samba/smb.conf[global] workgroup = WORKGROUP server string = Samba Server Version %v log file = /var/log/samba/log.%m max log size = 50 security = user passdb backend = tdbsam load printers = yes hosts allow = 192.168.1. cups options = raw[公共] comment = This is a public directory path = /data/public public = yes writable = yes create mask = 0755 directory mask = 0755[开发组] path = /data/kaifazu valid users = @kaifazu group = kaifazu read list = @kaifazu write list = @kaifazu create mode = 0664 directory mode = 0775[测试组] path = /data/ceshizu valid users = @ceshizu group = @ceshizu write list = @ceshizu create mode = 0664 directory mode = 0775 组配置12kaifazu:x:531:zhangsan,lisiceshizu:x:532:wangwu samba服务器磁盘检测脚本123456789101112131415161718192021222324252627282930313233343536373839404142#!/bin/bashfunction fun_chksize() &#123; # $1 file_name # $2 file_size # $3 max_size # $4 mail_addr # switch_file_size=file_size/1024 将K转换为M，方便阅读 if [ $2 -ge $3 ];then switch_file_size=$(($2/1024)) echo -n -e "samba服务器 $&#123;1&#125; 空间已使用$&#123;switch_file_size&#125;M\n" | mail -s "samba服务器空间使用告警" $4 fi&#125;#定义一些变量smb_dir=/dataip=`ifconfig | grep Bcast | awk '&#123;print $2&#125;' | awk -F: '&#123;print $2&#125;'` #IP地址admin_mail_addr="123456@qq.com" #管理员邮箱total_max_size=1024000 #总空间最大可用1G，单位Ktotal_use_size=`du -s $smb_dir | awk '&#123;print $1&#125;'` #总使用大小，单位Kmax_size=10240 #子目录默认最大可用10M public_max_size=10240 #public最大可用10M#检测总目录大小fun_chksize $smb_dir $total_use_size $total_max_size $admin_mail_addr#检测子目录大小for list1 in $&#123;smb_dir&#125;/*; do file_list=`basename $list1` #列表 cd $smb_dir file_size=`du -s $file_list | awk '&#123;print $1&#125;'` #大小，单位K switch_file_size=$(($file_size/1024)) #将K转换为M file_name=`du -s $file_list | awk '&#123;print $2&#125;'` #文件名或目录名 case $file_name in public) fun_chksize $file_name $file_size $public_max_size $admin_mail_addr ;; kaifazu) fun_chksize $file_name $file_size $max_size $admin_mail_addr ;; *) fun_chksize $file_name $file_size $max_size $admin_mail_addr ;; esacdone]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python函数定义&调用]]></title>
      <url>%2Fposts%2F7b381b54%2F</url>
      <content type="text"><![CDATA[为代码块起一个名字，在需要执行代码块时，直接使用函数名调用 定义12def hello(): print("hello,world!") 如上示例:使用def关键字定义函数hello为函数名，需要满足Python变量的命名规范小括号()定义函数参数冒号:表示函数定义结束使用缩进代码块定义函数体 调用1hello() 使用函数名()进行函数调用(执行函数体内代码) 函数返回值函数一般会在经过一系列语句处理后为调用者返回执行结果1234567def return_hello(): return "hello,world!"调用&gt;&gt;&gt; rt = return_hello()&gt;&gt;&gt; rt'hello,world!' 在函数体内使用return关键字为调用者返回执行结果使用变量赋值的方式用变量接收函数执行结果函数可以有多个返回值(元组类型)，并使用多个变量接收函数返回值 参数定义 &amp; 调用（标准调用）示例：12345def add(a,b): print(a,'+',b,'=',a+b)&gt;&gt;&gt; add(1,2)1 + 2 = 3 在函数定义语句括号内定义函数参数变量，可设置任意多个在函数调用语句括号内将数据传递到函数定义内在函数定义多个参数时，在函数调用时需要传递多个数据，数据之间使用逗号分隔，数据按照索引位置依次对应传递给函数定义的参数中 函数调用关键字参数1234def add(a,b,c): print(a,b,c)&gt;&gt;&gt; add(1,c=2,b=3) 在函数调用时使用参数名赋值方式，为参数指定对应的数据标准调用和关键字参数调用可混用，标准参数在前，关键字参数在后 默认参数12345def add(a,b,c=1): print(a+b)&gt;&gt;&gt; add(1,2) 在定义函数时可以为参数设置默认值，在调用时未设置对应数据时，则使用默认值默认参数必须置于函数参数最后 标准参数–关键字参数–默认参数 可变参数可变参数就是传入的参数个数是可变的，可以是1个、2个到任意个，还可以是0个。列表可变参数1234567def test(a,b,*args): print('a=',a,'b=',b,'args=',args)&gt;&gt;&gt; test(1,2)a= 1 b= 2 args= ()&gt;&gt;&gt; test(2,3,4,5,6)a= 2 b= 3 args= (4, 5, 6) 有上面的实例可以得知，列表可变参数中，列表可变参数返回的是包含多个参数的元组 关键字可变参数12345def test(a,b,**kargs): print('a=',a,'b=',b,'kargs=',kargs)&gt;&gt;&gt; test(2,3,c=4,d=5)a= 2 b= 3 kargs= &#123;'c': 4, 'd': 5&#125; 有上面的实例可以得知，关键字可变参数中，关键字参数返回的是包含多个key,value的字典 混用12345def test(a,b,*args,**kargs): print('a=',a,'b=',b,'args=',args,'kargs=',kargs)&gt;&gt;&gt; test(2,3,111,666,888,c=4,d=5)a= 2 b= 3 args= (111, 666, 888) kargs= &#123;'c': 4, 'd': 5&#125; 混用时，列表可变参数在前，关键字参数在后列表参数和关键字可变参数之间可定义多个变量(Python2.7不支持) 忽略返回值123456&gt;&gt;&gt; nums = [1,2,3,4,5,6]&gt;&gt;&gt; a,*b,c= nums&gt;&gt;&gt; print(a,c)1 6&gt;&gt;&gt; print(b)[2, 3, 4, 5] 函数也是变量可以将函数赋值给某个变量，此变量和函数名称一样函数名称可以传递给其它函数实例：1234567def add(a,b): return a + b&gt;&gt;&gt; add(1,2)3&gt;&gt;&gt; add2 = add&gt;&gt;&gt; add2(2,3)5 还可以将函数直接当成参数传递给另一个函数实例：12345678def result(a,b,func): print('a=',a,'b=',b,'result=',func(a,b))def add(a,b): return a+b&gt;&gt;&gt; result(1,2,add)a= 1 b= 2 result= 3 函数作用域在函数中变量的查找顺序为LGB原则L local 函数体和参数内 (p_a, p_b, l_a)G global 模块内 (g_a, g_b)B buildints python内置 传值与传址对于基本类型在函数传递时，直接传递值，在函数内修改值不影响函数体外的值 对引用类型在函数传递时，传递数据的地址，在函数内修改地址内的数据会影响函数体外（重新赋值后，则为在函数体内重新定义，与函数外变量指向已不同，不会影响函数体外） 匿名函数&amp;sorted&amp;list.sortlambda匿名函数 不需要定义函数名称（临时函数） 只做简单运算，并返回值，没有复杂的函数体 Python里的Lambda就是个匿名函数。典型的应用场景是结合sorted,filter,map,reduce等函数，通过闭包的特性，读取函数内部的某个变量，然后做相应简单的处理。例：1lambda x: x * x 等价于：12def f(x): return x * x 实例：123456def result(a,b,func): print('a=',a,'b=',b,'result=',func(a,b))&gt;&gt;&gt; result(1,2,lambda a,b:a+b)a= 1 b= 2 result= 3 sorted()函数和list.sort()函数：相同点： 都可以为list进行排序 参数相同，通过key指定排序的元素，使用reverse指定升序或者降序 区别： sorted返回一个新的list不影响原list，list.sort在原list上进行排序实例：123nums = [2,1,4,3,6,7,5]print(sorted(nums))print(nums) 根据第二项排序实例：12345nums = [(4,1),(2,2),(5,4),(1,3),(3,5)]print(sorted(nums,key=lambda nums:nums[1]))结果：[(4, 1), (2, 2), (1, 3), (5, 4), (3, 5)]]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[lnmp环境搭建]]></title>
      <url>%2Fposts%2F110e9b1f%2F</url>
      <content type="text"><![CDATA[准备Linux环境环境为CentOS6.7最小化安装安装开发包组12yum groupinstall "Development Tools"yum -y install pcre-devel bzip2-devel libmcrypt-devel gcc gcc-c++ openssl-devel pcre-devel libxml2-devel libcurl-devel libpng-devel freetype-devel libxslt-devel libtool gd-devel 安装MySQL1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586871、准备MySQL数据存放的文件目录数据目录为/data，而后需要创建/data/mysql目录做为mysql数据的存放目录。2、新建用户以安全方式运行进程：# groupadd -r mysql# useradd -g mysql -r -s /sbin/nologin -M -d /data/mysql mysql# chown -R mysql:mysql /data/mysql3、安装并初始化mysqlhttps://cdn.mysql.com//Downloads/MySQL-5.7/mysql-5.7.19-linux-glibc2.12-x86_64.tar.gz# tar xf mysql-5.7.19-linux-glibc2.12-x86_64.tar.gz -C /usr/local# cd /usr/local/# ln -sv mysql-5.7.19-linux-glibc2.12-x86_64 mysql# cd mysql # chown -R mysql:mysql .# bin/mysql_install_db --user=mysql --datadir=/data/mysql# chown -R root .4、为mysql提供主配置文件：参考链接https://dev.mysql.com/doc/refman/5.7/en/server-configuration-defaults.html从MySQL 5.7.18开始，my-default.ini不再包含在分发包中或由分发包安装。# vim /etc/my.cnf[mysqld]# innodb_buffer_pool_size = 128M# join_buffer_size = 128M# sort_buffer_size = 2M# read_rnd_buffer_size = 2Mdatadir=/data/mysqlsocket=/var/lib/mysql/mysql.sock# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid5、为mysql提供sysv服务脚本：# cd /usr/local/mysql# cp support-files/mysql.server /etc/rc.d/init.d/mysqld添加至服务列表：# chkconfig --add mysqld# chkconfig mysqld on而后就可以启动服务测试使用了。为了使用mysql的安装符合系统使用规范，并将其开发组件导出给系统使用，这里还需要进行如下步骤：6、输出mysql的man手册至man命令的查找路径：编辑/etc/man.config，添加如下行即可：MANPATH /usr/local/mysql/man7、输出mysql的头文件至系统头文件路径/usr/include：这可以通过简单的创建链接实现：# ln -sv /usr/local/mysql/include /usr/include/mysql8、输出mysql的库文件给系统库查找路径：# echo '/usr/local/mysql/lib' &gt; /etc/ld.so.conf.d/mysql.conf而后让系统重新载入系统库：# ldconfig9、修改PATH环境变量，让系统可以直接使用mysql的相关命令。在/etc/profile.d下新建mysql.sh内容如下：MYSQL_BASE=/usr/local/mysqlPATH=$MYSQL_BASE/bin:$PATH执行source /etc/profile.d/mysql.sh10、连接MySQL首次使用执行mysql_secure_installation执行完成后使用root连接mysql -uroot -h127.0.0.1 -p&gt;password Nginx1、下载官网下载地址：http://nginx.org/download/nginx-1.10.3.tar.gz2、安装首先添加用户nginx，实现以之运行nginx服务进程：12# groupadd -r nginx# useradd -r -g nginx nginx 接着开始编译和安装：123456789101112131415161718192021# ./configure \ --prefix=/usr/local/nginx \ --sbin-path=/usr/local/nginx/sbin/nginx \ --conf-path=/etc/nginx/nginx.conf \ --error-log-path=/var/log/nginx/error.log \ --http-log-path=/var/log/nginx/access.log \ --pid-path=/var/run/nginx/nginx.pid \ --lock-path=/var/lock/nginx.lock \ --user=nginx \ --group=nginx \ --with-http_ssl_module \ --with-http_flv_module \ --with-http_stub_status_module \ --with-http_gzip_static_module \ --http-client-body-temp-path=/var/tmp/nginx/client/ \ --http-proxy-temp-path=/var/tmp/nginx/proxy/ \ --http-fastcgi-temp-path=/var/tmp/nginx/fcgi/ \ --http-uwsgi-temp-path=/var/tmp/nginx/uwsgi \ --http-scgi-temp-path=/var/tmp/nginx/scgi \ --with-pcre# make &amp;&amp; make install 3、为nginx提供SysV init脚本: 新建文件/etc/rc.d/init.d/nginx，内容如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126#!/bin/sh## nginx - this script starts and stops the nginx daemon## chkconfig: - 85 15 # description: Nginx is an HTTP(S) server, HTTP(S) reverse \# proxy and IMAP/POP3 proxy server# processname: nginx# config: /etc/nginx/nginx.conf# config: /etc/sysconfig/nginx# pidfile: /var/run/nginx.pid # Source function library.. /etc/rc.d/init.d/functions # Source networking configuration.. /etc/sysconfig/network # Check that networking is up.[ "$NETWORKING" = "no" ] &amp;&amp; exit 0 nginx="/usr/sbin/nginx"prog=$(basename $nginx) NGINX_CONF_FILE="/etc/nginx/nginx.conf" [ -f /etc/sysconfig/nginx ] &amp;&amp; . /etc/sysconfig/nginx lockfile=/var/lock/subsys/nginx make_dirs() &#123; # make required directories user=`nginx -V 2&gt;&amp;1 | grep "configure arguments:" | sed 's/[^*]*--user=\([^ ]*\).*/\1/g' -` options=`$nginx -V 2&gt;&amp;1 | grep 'configure arguments:'` for opt in $options; do if [ `echo $opt | grep '.*-temp-path'` ]; then value=`echo $opt | cut -d "=" -f 2` if [ ! -d "$value" ]; then # echo "creating" $value mkdir -p $value &amp;&amp; chown -R $user $value fi fi done&#125; start() &#123; [ -x $nginx ] || exit 5 [ -f $NGINX_CONF_FILE ] || exit 6 make_dirs echo -n $"Starting $prog: " daemon $nginx -c $NGINX_CONF_FILE retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval&#125; stop() &#123; echo -n $"Stopping $prog: " killproc $prog -QUIT retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval&#125; restart() &#123; configtest || return $? stop sleep 1 start&#125; reload() &#123; configtest || return $? echo -n $"Reloading $prog: " killproc $nginx -HUP RETVAL=$? echo&#125; force_reload() &#123; restart&#125; configtest() &#123; $nginx -t -c $NGINX_CONF_FILE&#125; rh_status() &#123; status $prog&#125; rh_status_q() &#123; rh_status &gt;/dev/null 2&gt;&amp;1&#125; case "$1" in start) rh_status_q &amp;&amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart|configtest) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 ;; *) echo $"Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest&#125;" exit 2esac 而后为此脚本赋予执行权限：1# chmod +x /etc/rc.d/init.d/nginx 添加至服务管理列表，并让其开机自动启动：12# chkconfig --add nginx# chkconfig nginx on 而后就可以启动服务并测试了：1# service nginx start php1、下载http://php.net/downloads.php这里选择5.6.31版本 2、编译安装12345[root@lnmp php-5.6.31]# ./configure --prefix=/usr/local/php --with-mysql=/usr/local/mysql --with-openssl --enable-fpm --enable-sockets --enable-sysvshm --with-mysqli=/usr/local/mysql/bin/mysql_config --enable-mbstring --with-freetype-dir --with-jpeg-dir --with-png-dir --with-zlib-dir --with-libxml-dir=/usr --enable-xml --with-mhash --with-mcrypt --with-config-file-path=/etc --with-config-file-scan-dir=/etc/php.d --with-bz2 --with-curl [root@lnmp php-5.6.31]# make[root@lnmp php-5.6.31]# make test #此步骤可以不做，非常耗时间[root@lnmp php-5.6.31]# make intall 3、为php提供配置文件：1[root@lnmp php-5.6.31]# cp php.ini-production /etc/php.ini 4、为php-fpm提供Sysv init脚本，并将其添加至服务列表：1234[root@lnmp php-5.6.31]# cp sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm[root@lnmp php-5.6.31]# chmod +x /etc/rc.d/init.d/php-fpm[root@lnmp php-5.6.31]# chkconfig --add php-fpm[root@lnmp php-5.6.31]# chkconfig php-fpm on 5、为php-fpm提供配置文件：1[root@lnmp php-5.6.31]# cp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf 6、编辑php-fpm的配置文件：1234567891011[root@lnmp php-5.6.31]# vim /usr/local/php/etc/php-fpm.conf配置fpm的相关选项为你所需要的值，并启用pid文件（如下最后一行）：pm.max_children = 150pm.start_servers = 8pm.min_spare_servers = 5pm.max_spare_servers = 10pid = /usr/local/php/var/run/php-fpm.pid # 可以设置运行用户和组user = nginxgroup = nginx 接下来就可以启动php-fpm了：1# service php-fpm start 使用如下命令来验正（如果此命令输出有中几个php-fpm进程就说明启动成功了）：1# ps aux | grep php-fpm 整合nginx和php51、编辑/etc/nginx/nginx.conf，启用如下选项：1234567location ~ \.php$ &#123; #root html; root html; #可以自定义根路径 fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include /etc/nginx/fastcgi.conf; &#125; 并在所支持的主页面格式中添加php格式的主页，类似如下：1234location / &#123; root html; #可以自定义根路径 index index.php index.html index.htm; &#125; 而后重新载入nginx的配置文件：1# service nginx reload 3、在/usr/local/nginx/html新建index.php的测试页面，测试php是否能正常工作：1234# vim /usr/local/nginx/html/index.php&lt;?php phpinfo();?&gt; 接着就可以通过浏览器访问此测试页面了。 测试php和MySQL联通性在/usr/local/nginx/html新建index2.php的测试页面，测试php是否能正常工作12345678910111213# vim /usr/local/nginx/html/index2.php&lt;?php$con=mysql_connect('127.0.0.1:3306','root','password'); if($con) &#123; die('ok'); &#125; else &#123; die('Could not connect: ' . mysql_error()); &#125;?&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Django小项目之留言板]]></title>
      <url>%2Fposts%2Fecf0dfea%2F</url>
      <content type="text"><![CDATA[Django在线留言板小练习 环境1ubuntu16.04 + python3 + django1.11 1、创建项目1django-admin.py startproject message 进入项目message 2、创建APP1python manager.py startapp guestbook 项目结构123456789101112131415161718192021.├── guestbook│ ├── admin.py│ ├── apps.py│ ├── __init__.py│ ├── migrations│ │ └── __init__.py│ ├── models.py│ ├── tests.py│ └── views.py├── manage.py└── message ├── __init__.py ├── __pycache__ │ ├── __init__.cpython-35.pyc │ └── settings.cpython-35.pyc ├── settings.py ├── urls.py └── wsgi.py4 directories, 14 files 需要做的事： 配置项目setting 、初始化数据库、配置url 、编写views 、创建HTML文件 项目配置打开message/settings.py12345678910111213141516设置哪些主机可以访问,*代表所有主机ALLOWED_HOSTS = ["*"]INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'guestbook', #刚刚创建的APP，加入到此项目中]#数据库默认用sqlite3,后期可以换成MySQL或者SQL Server等TIME_ZONE = 'PRC' #时区设置为中国 创建数据库字段12345678910111213#encoding: utf-8from django.db import modelsclass Message(models.Model): username=models.CharField(max_length=256) title=models.CharField(max_length=512) content=models.TextField(max_length=256) publish=models.DateTimeField() #为了显示 def __str__(self): tpl = '&lt;Message:[username=&#123;username&#125;, title=&#123;title&#125;, content=&#123;content&#125;, publish=&#123;publish&#125;]&gt;' return tpl.format(username=self.username, title=self.title, content=self.content, publish=self.publish) 初始化数据库123456789101112131415161718192021222324252627# 1. 创建更改的文件root@python:/online/message# python3 manage.py makemigrationsMigrations for 'guestbook': guestbook/migrations/0001_initial.py - Create model Message# 2. 将生成的py文件应用到数据库root@python:/online/message# python3 manage.py migrateOperations to perform: Apply all migrations: admin, auth, contenttypes, guestbook, sessionsRunning migrations: Applying contenttypes.0001_initial... OK Applying auth.0001_initial... OK Applying admin.0001_initial... OK Applying admin.0002_logentry_remove_auto_add... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying auth.0007_alter_validators_add_error_messages... OK Applying auth.0008_alter_user_username_max_length... OK Applying guestbook.0001_initial... OK Applying sessions.0001_initial... OK 配置url设置项目message/urls.py1234567from django.conf.urls import url,include #添加了includefrom django.contrib import adminurlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^guestbook/', include('guestbook.urls',namespace='guestbook')), #表示在url地址中所有guestbook的都交给guestbook下面的url来处理，后面的逗号不要省略] 设置APP的url如果是初次创建APP，urls.py在APP中一般不存在，创建即可123456789vim guestbook/urls.py# 内容如下from django.conf.urls import urlfrom . import viewsurlpatterns = [ url(r'^index/',views.index,name='index'), #不要忘了逗号] 编写views编辑APP中的views.py12345678from django.shortcuts import renderfrom django.http import HttpResponseRedirectfrom . import models# Create your views here.def index(request): messages = models.Message.objects.all() return render(request, 'guestbook/index.html', &#123;'messages' : messages&#125;) 编写HTML文件创建APP/templates/guestbook/index.html目录及文件 #使用bootstrap美化了1234567891011121314151617181920212223242526272829303132333435363738&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8" /&gt; &lt;title&gt;留言板&lt;/title&gt; &lt;link rel="stylesheet" href="https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap.min.css" crossorigin="anonymous"&gt; &lt;/head&gt; &lt;body&gt; &lt;table class="table table-striped table-bordered table-hover table-condensed"&gt; &lt;thead&gt; &lt;tr class="danger"&gt; &lt;th&gt;留言时间&lt;/th&gt; &lt;th&gt;留言者&lt;/th&gt; &lt;th&gt;标题&lt;/th&gt; &lt;th&gt;内容&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &#123;% if messages %&#125; &#123;% for message in messages %&#125; &lt;tr class="&#123;% cycle 'active' 'success' 'warning' 'info' %&#125;"&gt; &lt;td&gt;&#123;&#123; message.publish|date:'Y-m-d H:i:s' &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; message.username &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; message.title &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; message.content &#125;&#125;&lt;/td&gt; &lt;/tr&gt; &#123;% endfor %&#125; &#123;% else %&#125; &lt;tr&gt; &lt;td colspan="4"&gt;无数据&lt;/td&gt; &lt;/tr&gt; &#123;% endif %&#125; &lt;/tbody&gt; &lt;/table&gt; &lt;a class="btn btn-xs btn-info" href="/guestbook/create/"&gt;去留言&lt;/a&gt; &lt;/body&gt;&lt;/html&gt; 调试index页面1python manage.py runserver 0.0.0.0:99 打开浏览器访问http://开发机器ip地址:99/guestbook/index/ 图1 留言展示页面成功 创建留言页面12345678910111213141516171819202122&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8" /&gt; &lt;title&gt;留言&lt;/title&gt; &lt;link rel="stylesheet" href="https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap.min.css" crossorigin="anonymous"&gt; &lt;/head&gt; &lt;body&gt; &lt;!-- 我是注释 --&gt; &lt;h3&gt;留言&lt;/h3&gt; &lt;!--h1-&gt; h6--&gt; &lt;!--method: POST /GET --&gt; &lt;form action="/online/save/" method="POST" novalidate="novalidate"&gt; &#123;% csrf_token %&#125; &lt;table class="table table-striped table-bordered table-hover table-condensed"&gt; &lt;label&gt;用户名:&lt;/label&gt; &lt;input type="text" name="username" placeholder="用户名" /&gt; &lt;br /&gt;&lt;br /&gt; &lt;label&gt;标 题:&lt;/label&gt; &lt;input type="text" name="title" placeholder="标题" /&gt;&lt;br /&gt;&lt;br /&gt; &lt;label&gt;内 容:&lt;/label&gt; &lt;textarea name="content" placeholder="内容"&gt; &lt;/textarea&gt;&lt;br /&gt;&lt;br /&gt; &lt;/table&gt; &lt;input class="btn btn-success" type="submit" value="留言"/&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 配置APP下的url1234567vim guestbook/urls.pyurlpatterns = [ url(r'^index/',views.index,name='index'), #不要忘了逗号 url(r'^create/$', views.create, name='create'), url(r'^save/$', views.save, name='save'), ] 编辑views.py1234567891011121314151617#先导入时间模块import datetime#添加create、savedef create(request): return render(request, 'guestbook/create.html')def save(request): username = request.POST.get("username") title = request.POST.get("title") content = request.POST.get("content") publish = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") message = models.Message(title=title, content=content, username=username, publish=publish) message.save() return HttpResponseRedirect('/guestbook/index/') OK，再次运行，enjoy it!]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python进阶]]></title>
      <url>%2Fposts%2F37f2eeef%2F</url>
      <content type="text"><![CDATA[一、循环设计在上一节，我们已经讨论了Python基本的语法。这一节，我们将接触更加灵活的循环方式。 1、range()在Python中，for循环后的in跟随一个序列的话，循环每次使用的序列元素，而不是序列的下标。之前我们已经使用过 range() 来控制for循环。现在，我们继续开发range的功能，以实现下标对循环的控制：123S = 'abcdefghijk'for i in range(0,len(S),2): print(S[i]) 在该例子中，我们利用 len() 函数和 range() 函数，用 i 作为 S 序列的下标来控制循环。在range函数中，分别定义上限，下限和每次循环的步长。这就和C语言中的for循环相类似了。 2、enumerate()利用enumerate()函数，可以在每次循环中同时得到下标和元素：1234S = 'abcdefghijk'for (index,char) in enumerate(S): print(index) print(char) 实际上，enumerate()在每次循环中，返回的是一个包含两个元素的定值表(tuple)，两个元素分别赋予index和char。 3、zip()如果你多个等长的序列，然后想要每次循环时从各个序列分别取出一个元素，可以利用zip()方便地实现：12345ta = [1,2,3]tb = [9,8,7]tc = ['a','b','c']for (a,b,c) in zip(ta,tb,tc): print(a,b,c) 每次循环时，从各个序列分别从左到右取出一个元素，合并成一个tuple，然后tuple的元素赋予给a,b,c 。zip()函数的功能，就是从多个列表中，依次各取出一个元素。每次取出的(来自不同列表的)元素合成一个元组，合并成的元组放入zip()返回的列表中。zip()函数起到了聚合列表的功能。我们可以分解聚合后的列表，如下:12345678910ta = [1,2,3]tb = [9,8,7]# clusterzipped = zip(ta,tb)print(zipped)# decomposena, nb = zip(*zipped)print(na, nb) 二、循环对象这一讲的主要目的是为了大家在读Python程序的时候对循环对象有一个基本概念。循环对象的并不是随着Python的诞生就存在的，但它的发展迅速，特别是Python 3x的时代，循环对象正在成为循环的标准形式。 1、什么是循环对象循环对象是这样一个对象，它包含有一个next()方法 ( next() 方法，在python 3x中 )， 这个方法的目的是进行到下一个结果，而在结束一系列结果之后，举出StopIteration错误。当一个循环结构（比如for）调用循环对象时，它就会每次循环的时候调用next()方法，直到StopIteration出现，for循环接收到，就知道循环已经结束，停止调用next()。假设我们有一个test.txt的文件:1231234abcdefg 我们运行一下python命令行：1234567&gt;&gt;&gt;f = open('test.txt')&gt;&gt;&gt;f.next()&gt;&gt;&gt;f.next()... 不断输入f.next()，直到最后出现StopIteration 。open()返回的实际上是一个循环对象，包含有next()方法。而该next()方法每次返回的就是新的一行的内容，到达文件结尾时举出StopIteration。这样，我们相当于手工进行了循环。自动进行的话，就是：12for line in open('test.txt'): print(line) 在这里，for结构自动调用next()方法，将该方法的返回值赋予给line。循环直到出现StopIteration的时候结束。相对于序列，用循环对象的好处在于：不用在循环还没有开始的时候，就生成好要使用的元素。所使用的元素可以在循环过程中逐次生成。这样，节省了空间，提高了效率，编程更灵活。 2、迭代器从技术上来说，循环对象和for循环调用之间还有一个中间层，就是要将循环对象转换成迭代器(iterator)。这一转换是通过使用iter()函数实现的。但从逻辑层面上，常常可以忽略这一层，所以循环对象和迭代器常常相互指代对方。 3、生成器生成器(generator)的主要目的是构成一个用户自定义的循环对象。生成器的编写方法和函数定义类似，只是在return的地方改为yield。生成器中可以有多个yield。当生成器遇到一个yield时，会暂停运行生成器，返回yield后面的值。当再次调用生成器的时候，会从刚才暂停的地方继续运行，直到下一个yield。生成器自身又构成一个循环器，每次循环使用一个yield返回的值。下面是一个生成器:123456def gen(): a = 100 yield a a = a*8 yield a yield 1000 该生成器共有三个yield， 如果用作循环器时，会进行三次循环。12for i in gen(): print(i) 再考虑如下一个生成器:123def gen(): for i in range(4): yield i 它又可以写成生成器表达式(Generator Expression)：1G = (x for x in range(4)) 生成器表达式是生成器的一种简便的编写方式。读者可进一步查阅。 4、表推导表推导(list comprehension)是快速生成表的方法。它的语法简单，很有实用价值。假设我们生成表 L ：123L = []for x in range(10): L.append(x**2) 以上产生了表L，但实际上有快捷的写法，也就是表推导的方式:1L = [x**2 for x in range(10)] 这与生成器表达式类似，只不过用的是中括号。（表推导的机制实际上是利用循环对象，有兴趣可以查阅。） 三、函数对象秉承着一切皆对象的理念，我们再次回头来看函数(function)。函数也是一个对象，具有属性（可以使用dir()查询）。作为对象，它还可以赋值给其它对象名，或者作为参数传递。 1、lambda函数在展开之前，我们先提一下lambda函数。可以利用lambda函数的语法，定义函数。lambda例子如下：12func = lambda x,y: x + yprint(func(3,4)) lambda生成一个函数对象。该函数参数为x,y，返回值为x+y。函数对象赋给func。func的调用与正常函数无异。以上定义可以写成以下形式：12def func(x, y): return x + y 2、函数作为参数传递函数可以作为一个对象，进行参数传递。函数名(比如func)即该对象。比如说:12345def test(f, a, b): print('test') print(f(a, b))test(func, 3, 5) test函数的第一个参数f就是一个函数对象。将func传递给f，test中的f()就拥有了func()的功能。我们因此可以提高程序的灵活性。可以使用上面的test函数，带入不同的函数参数。比如:1test((lambda x,y: x**2 + y), 6, 9) 3、map()函数map()是Python的内置函数。它的第一个参数是一个函数对象。1re = map((lambda x: x+3),[1,3,5,6]) 这里，map()有两个参数，一个是lambda所定义的函数对象，一个是包含有多个元素的表。map()的功能是将函数对象依次作用于表的每一个元素，每次作用的结果储存于返回的表re中。map通过读入的函数(这里是lambda函数)来操作数据（这里“数据”是表中的每一个元素，“操作”是对每个数据加3）。在Python 3.X中，map()的返回值是一个循环对象。可以利用list()函数，将该循环对象转换成表。如果作为参数的函数对象有多个参数，可使用下面的方式，向map()传递函数参数的多个参数：1re = map((lambda x,y: x+y),[1,2,3],[6,7,9]) map()将每次从两个表中分别取出一个元素，带入lambda所定义的函数。 4、filter()函数filter函数的第一个参数也是一个函数对象。它也是将作为参数的函数对象作用于多个元素。如果函数对象返回的是True，则该次的元素被储存于返回的表中。 filter通过读入的函数来筛选数据。同样，在Python 3.X中，filter返回的不是表，而是循环对象。filter函数的使用如下例:1234567def func(a): if a &gt; 100: return True else: return Falseprint(filter(func,[10,56,101,500]) 5、reduce()函数reduce函数的第一个参数也是函数，但有一个要求，就是这个函数自身能接收两个参数。reduce可以累进地将函数作用于各个参数。如下例：1print(reduce((lambda x,y: x+y),[1,2,5,7,9]) reduce的第一个参数是lambda函数，它接收两个参数x,y, 返回x+y。reduce将表中的前两个元素(1和2)传递给lambda函数，得到3。该返回值(3)将作为lambda函数的第一个参数，而表中的下一个元素(5)作为lambda函数的第二个参数，进行下一次的对lambda函数的调用，得到8。依次调用lambda函数，每次lambda函数的第一个参数是上一次运算结果，而第二个参数为表中的下一个元素，直到表中没有剩余元素。上面例子，相当于(((1+2)+5)+7)+9提醒： reduce()函数在3.0里面不能直接用的，它被定义在了functools包里面，需要引入包。 四、错误处理1、异常处理在项目开发中，异常处理是不可或缺的。异常处理帮助人们debug，通过更加丰富的信息，让人们更容易找到bug的所在。异常处理还可以提高程序的容错性。我们之前在讲循环对象的时候，曾提到一个StopIteration的异常，该异常是在循环对象穷尽所有元素时的报错。我们以它为例，来说明基本的异常处理。一个包含异常的程序:123456re = iter(range(5))for i in range(100): print(re.next())print('HaHaHaHa') 首先，我们定义了一个循环对象re，该循环对象将进行5次循环，每次使用序列的一个元素。在随后的for循环中，我们手工调用next()函数。当循环进行到第6次的时候，re.next()不会再返回元素，而是抛出(raise)StopIteration的异常。整个程序将会中断。我们可以修改以上异常程序，直到完美的没有bug。但另一方面，如果我们在写程序的时候，知道这里可能犯错以及可能的犯错类型，我们可以针对该异常类型定义好”应急预案”。123456789re = iter(range(5))try: for i in range(100): print(re.next()except StopIteration: print('here is end ',i)print('HaHaHaHa') 在try程序段中，我们放入容易犯错的部分。我们可以跟上except，来说明如果在try部分的语句发生StopIteration时，程序该做的事情。如果没有发生异常，则except部分被跳过。随后，程序将继续运行，而不是彻底中断。完整的语法结构如下：123456789101112try: ...except exception1: ...except exception2: ...except: ...else: ...finally: ... 如果try中有异常发生时，将执行异常的归属，执行except。异常层层比较，看是否是exception1, exception2…，直到找到其归属，执行相应的except中的语句。如果except后面没有任何参数，那么表示所有的exception都交给这段程序处理。比如:123456try: print(a*2)except TypeError: print("TypeError")except: print("Not Type Error &amp; Error noted") 由于a没有定义，所以是NameError。异常最终被except:部分的程序捕捉。如果无法将异常交给合适的对象，异常将继续向上层抛出，直到被捕捉或者造成主程序报错。比如下面的程序：12345678910def test_func(): try: m = 1/0 except NameError: print("Catch NameError in the sub-function")try: test_func()except ZeroDivisionError: print("Catch error in the main program") 子程序的try…except…结构无法处理相应的除以0的错误，所以错误被抛给上层的主程序。如果try中没有异常，那么except部分将跳过，执行else中的语句。finally是无论是否有异常，最后都要做的一些事情。流程如下: ● try-&gt;异常-&gt;except-&gt;finally ● try-&gt;无异常-&gt;else-&gt;finally 2、抛出异常我们也可以自己写一个抛出异常的例子:123print('Lalala')raise StopIterationprint('Hahaha') 这个例子不具备任何实际意义。只是为了说明raise语句的作用。StopIteration是一个类。抛出异常时，会自动有一个中间环节，就是生成StopIteration的一个对象。Python实际上抛出的，是这个对象。当然，也可以自行生成对象:1raise StopIteration() 五、动态类型动态类型(dynamic typing)是Python另一个重要的核心概念。我们之前说过，Python的变量(variable)不需要声明，而在赋值时，变量可以重新赋值为任意值。这些都与动态类型的概念相关。 1、动态类型在我们接触的对象中，有一类特殊的对象，是用于存储数据的。常见的该类对象包括各种数字，字符串，表，词典。在C语言中，我们称这样一些数据结构为变量。而在Python中，这些是对象。对象是储存在内存中的实体。但我们并不能直接接触到该对象。我们在程序中写的对象名，只是指向这一对象的引用(reference)。引用和对象分离，是动态类型的核心。引用可以随时指向一个新的对象：12a = 3a = 'at' 第一个语句中，3是储存在内存中的一个整数对象。通过赋值，引用a指向对象3。第二个语句中，内存中建立对象‘at’，是一个字符串(string)。引用a指向了’at’。此时，对象3不再有引用指向它。Python会自动将没有引用指向的对象销毁(destruct)，释放相应内存。(对于小的整数和短字符串，Python会缓存这些对象，而不是频繁的建立和销毁。)123a = 5b = aa = a + 2 再看这个例子。通过前两个句子，我们让a,b指向同一个整数对象5( b = a的含义是让引用b指向引用a所指的那一个对象)。但第三个句子实际上对引用a重新赋值，让a指向一个新的对象7。此时a,b分别指向不同的对象。我们看到，即使是多个引用指向同一个对象，如果一个引用值发生变化，那么实际上是让这个引用指向一个新的引用，并不影响其他的引用的指向。从效果上看，就是各个引用各自独立，互不影响。其它数据对象也是如此:123L1 = [1,2,3]L2 = L1L1 = 1 但注意以下情况:1234L1 = [1,2,3]L2 = L1L1[0] = 10print(L2) 在该情况下，我们不再对L1这一引用赋值，而是对L1所指向的表的元素赋值。结果是，L2也同时发生变化。原因何在呢？因为L1，L2的指向没有发生变化，依然指向那个表。表实际上是包含了多个引用的对象（每个引用是一个元素，比如L1[0]，L1[1]…, 每个引用指向一个对象，比如1,2,3), 。而L1[0] = 10这一赋值操作，并不是改变L1的指向，而是对L1[0], 也就是表对象的一部份(一个元素)，进行操作，所以所有指向该对象的引用都受到影响。（与之形成对比的是，我们之前的赋值操作都没有对对象自身发生作用，只是改变引用指向。）列表可以通过引用其元素，改变对象自身(in-place change)。这种对象类型，称为可变数据对象(mutable object)，词典也是这样的数据类型。而像之前的数字和字符串，不能改变对象本身，只能改变引用的指向，称为不可变数据对象(immutable object)。我们之前学的元组(tuple)，尽管可以调用引用元素，但不可以赋值，因此不能改变对象自身，所以也算是immutable object。 2、从动态类型看函数的参数传递函数的参数传递，本质上传递的是引用。比如说：1234567def f(x): x = 100 print(x)a = 1f(a)print(a) 参数x是一个新的引用，指向a所指的对象。如果参数是不可变(immutable)的对象，a和x引用之间相互独立。对参数x的操作不会影响引用a。这样的传递类似于C语言中的值传递。如果传递的是可变(mutable)的对象，那么改变函数参数，有可能改变原对象。所有指向原对象的引用都会受影响，编程的时候要对此问题留心。比如说：1234567def f(x): x[0] = 100 print(x)a = [1,2,3]f(a)print(a) 动态类型是Python的核心机制之一。可以在应用中慢慢熟悉。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Python之10分钟快速入门]]></title>
      <url>%2Fposts%2Ff65a1069%2F</url>
      <content type="text"><![CDATA[【搭建开发环境】1 可以到Welcome to Python.org下载安装包，然后通过configure、make、make install进行安装。 2 也可以到ActiveState | ActiveState去下载ActivePython组件包。（ActivePython是对Python核心和常用模块的二 进制包装，它是ActiveState公司发布的Python开发环境。ActivePython使得Python的安装更加容易，并且可以应用在各种操 作系统上。ActivePython包含了一些常用的Python扩展，以及Windows环境的编程接口）。对ActivePython来说，如果你是 windows用户，下载msi包安装即可；如果你是Unix用户，下载tar.gz包直接解压即可。 3 Python的IDE，包括PythonWin、Eclipse+PyDev插件、Komodo、EditPlus、Sublime等 【版本】python2与python3是目前主要的两个版本。 如下两种情况下，建议使用python2： 1 你无法完全控制你即将部署的环境时； 2 你需要使用一些特定的第三方包或扩展时； python3是官方推荐的且是未来全力支持的版本，目前很多功能提升仅在python3版本上进行。 【hello world】1 创建hello.py 2 编写程序：12if __name__ == '__main__': print "hello word" 3 运行程序：python ./hello.py 【注释】1 无论是行注释还是段注释，均以#加一个空格来注释。 2 如果需要在代码中使用中文注释，必须在python文件的最前面加上如下注释说明： 1# -* - coding: UTF-8 -* - 3 如下注释用于指定解释器1#! /usr/bin/python 【文件类型】1 Python的文件类型分为3种，即源代码、字节代码和优化代码。这些都可以直接运行，不需要进行编译或连接。 2 源代码以.py为扩展名，由python来负责解释； 3 源文件经过编译后生成扩展名为.pyc的文件，即编译过的字节文件。这种文件不能使用文本编辑器修改。pyc文件是和平台无关的，可以在大部分操作系统上运行。如下语句可以用来产生pyc文件： 12import py_compilepy_compile.compile(‘hello.py’) 4 经过优化的源文件会以.pyo为后缀，即优化代码。它也不能直接用文本编辑器修改，如下命令可用来生成pyo文件：1python -O -m py_complie hello.py 【变量】1 python中的变量不需要声明，变量的赋值操作即使变量声明和定义的过程。 2 python中一次新的赋值，将创建一个新的变量。即使变量的名称相同，变量的标识并不相同。用id()函数可以获取变量标识：1234x = 1print id(x)x = 2print id(x) 3 如果变量没有赋值，则python认为该变量不存在 4 在函数之外定义的变量都可以称为全局变量。全局变量可以被文件内部的任何函数和外部文件访问。 5 全局变量建议在文件的开头定义。 6 也可以把全局变量放到一个专门的文件中，然后通过import来引用： gl.py文件中内容如下：12_a = 1_b = 2 use_global.py中引用全局变量：12345import gldef fun(): print gl._a print gl._bfun() 【常量】python中没有提供定义常量的保留字。可以自己定义一个常量类来实现常量的功能。 12345678class _const: class ConstError(TypeError): pass def __setattr__(self,name,vlaue): if self.__dict__.has_key(name): raise self.ConstError, “Can’t rebind const(%s)”%name self.__dict__[name]=valueimport syssys.modules[__name__]=_const() 【数据类型】1 python的数字类型分为整型、长整型、浮点型、布尔型、复数类型。 2 python没有字符类型 3 python内部没有普通类型，任何类型都是对象。 4 如果需要查看变量的类型，可以使用type类，该类可以返回变量的类型或创建一个新的类型。 5 python有3种表示字符串类型的方式，即单引号、双引号、三引号。单引号和双引号的作用是相同的。python程序员更喜欢用单引号，C/Java程序员则习惯使用双引号表示字符串。三引号中可以输入单引号、双引号或换行等字符。 【运算符和表达式】1 python不支持自增运算符和自减运算符。例如i++/i–是错误的，但i+=1是可以的。 2 1/2在python2.5之前会等于0.5，在python2.5之后会等于0。 3 不等于为!=或&lt;&gt; 4 等于用==表示 5 逻辑表达式中and表示逻辑与，or表示逻辑或，not表示逻辑非 【控制语句】1、条件语句：1234if (表达式) : 语句1else : 语句2 2、多条件语句：123456789if (表达式) : 语句1elif (表达式) : 语句2…elif (表达式) : 语句nelse : 语句m 3 条件嵌套： 123456789101112if (表达式1) : if (表达式2) : 语句1 elif (表达式3) : 语句2 … else: 语句3elif (表达式n) : …else : … 4 python本身没有switch语句。 5 循环语句:1234while(表达式) : …else : … 6 循环语句：1234for 变量 in 集合 : …else : … 7 python不支持类似c的for(i=0;i&lt;5;i++)这样的循环语句，但可以借助range模拟： 12for x in range(0,5,2): print x 【数组相关】1 元组（tuple）：python中一种内置的数据结构。元组由不同的元素组成，每个元素可以存储不同类型的数据，如字符串、数字甚至元素。元组是写保护 的，即元组创建之后不能再修改。元组往往代表一行数据，而元组中的元素代表不同的数据项。可以把元组看做不可修改的数组。创建元组示例如下：1tuple_name=(“apple”,”banana”,”grape”,”orange”) 2 列表（list）：列表和元组相似，也由一组元素组成，列表可以实现添加、删除和查找操作，元素的值可以被修改。列表是传统意义上的数组。列表创建示例如下：1list=[“apple”,”banana”,”grage”,”orange”] 可以使用append方法来在尾部追加元素，使用remove来删除元素。 3 字典（dictionary）：由键-值对组成的集合，字典中的值通过键来引用。键和值之间用冒号隔开，键-值对之间用逗号隔开，并且被包含在一对花括号中。创建示例如下：1dict=&#123;“a”:”apple”, “b”:”banana”, “g”:”grage”, “o”:”orange”&#125; 4 序列：序列是具有索引和切片能力的集合。元组、列表和字符串都属于序列。 【函数相关】1 python程序由包（package）、模块（module）和函数组成。包是由一系列模块组成的集合。模块是处理某一类问题的函数和类的集合。 2 包就是一个完成特定任务的工具箱。 3 包必须含有一个init.py文件，它用于标识当前文件夹是一个包。 4 python的程序是由一个个模块组成的。模块把一组相关的函数或代码组织到一个文件中，一个文件即是一个模块。模块由代码、函数和类组成。导入模块使用import语句。 5 包的作用是实现程序的重用。 6 函数是一段可以重复多次调用的代码，函数定义示例如下： 1234567def arithmetic(x,y,operator): result=&#123; “+”:x+y, “-“:x-y, “*”:x*y, “/”:x/y &#125; 7 函数返回值可以用return来控制。 【字符串相关】1 格式化输出: 12format=”%s%d” % (str1,num)print format 2 用+进行字符串的合并： 123str1=”hello”str2=”world”result=str1+str2 3 字符串截取可以通过索引/切片，也可以通过split函数。 4 通过切片截取字符串： 12word=”world”print word[0:3] 5 python使用==和!=来进行字符串比较。如果比较的两个变量的类型不相同，那么结果必然为不同。 【文件处理】1 简单处理文件: 1234context=”hello,world”f=file(“hello.txt”,’w’)f.write(context);f.close() 2 读取文件可以使用readline()函数、readlines()函数和read函数。 3 写入文件可以使用write()、writelines()函数 【对象和类】1 python用class保留字来定义一个类，类名的首字符要大写。当程序员需要创建的类型不能用简单类型来表示时，就需要定义类，然后利用定义的类创建对象。定义类示例： 123class Fruit: def grow(self): print “Fruit grow” 2 当一个对象被创建后，包含了三方面的特性，即对象的句柄、属性和方法。创建对象的方法： 12fruit = Fruit()fruit.grow() 3 python没有保护类型的修饰符 4 类的方法也分为公有方法和私有方法。私有函数不能被该类之外的函数调用，私有的方法也不能被外部的类或函数调用。 5 python使用函数”staticmethod()“或”@ staticmethod“指令的方法把普通的函数转换为静态方法。静态方法相当于全局函数。 6 python的构造函数名为init，析构函数名为del 7 继承的使用方法： 12class Apple(Fruit): def … 【连接mysql】1 用MySQLdb模块操作MySQL数据库非常方便。示例代码如下： 12345678910111213141516171819202122import os, sysimport MySQLdbtry: conn=MySQLdb.connect(host=’localhost’,user=’root’,passwd=’password’,db=’address’except Exception,e: print e sys.exit()cursor=conn.cursor()sql=’insert into address(name, address) values(%s, %s)’value=((“zhangsan”,”haidian”),(“lisi”,”haidian”))try cursor.executemany(sql,values)except Exception, e: print esql=”select * from address”cursor.execute(sql)data=cursor.fetchall()if data for x in data: print x[0],x[1]cursor.close()conn.close()]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[指尖流沙]]></title>
      <url>%2Fposts%2F3080612f%2F</url>
      <content type="text"><![CDATA[世界上最容易失去的便是时间了，我们总是蓦然回首，而时间早已流去。曾经的种种，时时刻刻在我们脑中出现，让我们感到开心，快乐，幸福等。有时好想有一种冲动，回到过去，再感受一下心中的那份触动。 毕业就像指尖流沙，而我们便是那从指尖流过的沙子。我不知道该怎样来总结我的大学，大一在一个校区，大二又去了一个校区，大三，本该去实习的我们，有一半的人又去了洛阳。所以，大家大二结束后吃了一顿饭，也是班里仅有的一次集体聚餐。或许大家都认为我这个人比较沉默，可是对我而言，我只是想做一个简简单单的人而已。在我的心里我当做朋友的会一直当作朋友，即使以后大家都鲜有机会再聚在一起，我讨厌酒桌上的朋友，所以我不会用喝酒这件事情来作为我们彼此情感的见证。我是一个不善于卖弄和殷勤的人，可能我太简单，可能我又爱又恨，可是那是因为我想做一个表里如一的人。朋友对我而言，一直是我所珍视的人，我想我喜欢的是大家在一起的时光，而不是在一起喝酒的时候。 2015年感悟：人有两种状态要不得，一种是没有想法，一种是有很多种想法，这两种都是原地踏步，其实最简单的就是，及时出发。 又一年过去了，2016，继续前进，开创永远的回忆。 ==================更新于2017年============== 2016年，培训，第一份工作：自学能力(专业技能，生活技能)无论何时都是重要的。找到工作，离开了小伙伴，自己一个人生活。说实话，孤独，害怕。但是，总要一个人的，不是吗？ 2017，多写博客分享技术经验和生活杂谈，专注于博客内容而不是博客版式、UI、特效等。我要换一份工作，换一个居住的更好地方要努力学习Python，年底要能做到开发一个cmdb监控系统、实现一些其它的好玩的功能一年呢，就做着试试呗。 2016年感悟：改变现状不一定能更好，但是不改变一定只会越来越差，安逸的环境容易丧失斗志，既然不愿接受，那就试着反抗下吧。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[解决kvm虚拟windows系统间歇性网络中断的问题]]></title>
      <url>%2Fposts%2Fd6278d54%2F</url>
      <content type="text"><![CDATA[现象 突然之间，网络完全中断，无法从网络访问虚拟机 用virt-manager或者console登录虚拟机，发现虚拟机还在正常工作，没有崩溃 使用 service network restart重启物理机网络服务，可以立即恢复网络 网络负载越大，故障出现的频率越高。轻网络负载的机器，没有出现故障 解决搜索了一下，发现ubuntu和centos都会出现这样的问题： https://bugs.launchpad.net/ubuntu/+source/libvirt/+bug/997978http://bugs.centos.org/view.php?id=5526 几个解决办法： 第1种：使用 e1000替代原有的windows网卡 第2种：使用 vhost_net 模块12echo vhost_net &gt; /etc/modulesmodprobe vhost_net 然后重新启动虚拟机，libvirtd就会自动使用 vhost_net 原因分析在kvm虚拟机里，默认windows系统虚拟的网卡是RTL8139C的网卡，此网卡在网络重负载下易发生崩溃现象。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Linux下Apache2.4+php5.5连接SQL Server2008]]></title>
      <url>%2Fposts%2F3d6aa6c1%2F</url>
      <content type="text"><![CDATA[此文档适用于CentOS6.7部署Apache+PHP连接SQL Server2008 软件版本： Apache: httpd-2.4.23 PHP: php-5.5.12 Apr: apr apr-1.5.2 Apr-util: apr-util-1.5.4 libiconv: libiconv-1.14 FreeTDS: freetds-1.00.15 先安装开发环境和依赖包 1yum install gcc openssl openssl-devel pcre pcre-devel libxml2 libxml2-devel libcurl libcurl-devel libpng libpng-devel freetype-devel libxslt-devel libxslt Apache 由于Apache2.4.x依赖于apr1.4+和apr-util1.4+，所以在编译安装Apache2.4时要先编译安装这两个包 123456789101112#安装apr~]# ./configure --prefix=/usr/local/apr~]# make &amp;&amp; make install#安装apr-util~]# ./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr~]# make &amp;&amp; make install#安装Apache(添加运行用户和组)~]# ./configure --prefix=/usr/local/apache24 --sysconfdir=/etc/httpd24 --enable-so --enable-ssl --enable-cgi --enable-rewrite --with-zlib --with-pcre --with-apr=/usr/local/apr --with-apr-util=/usr/local/apr-util --enable-modules=most --enable-mpms-shared=all --with-mpm=prefork~]# make &amp;&amp; make install 添加Apache服务管理脚本vim /etc/init.d/httpd123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899#!/bin/bash## httpd Startup script for the Apache HTTP Server## chkconfig: - 85 15# description: Apache is a World Wide Web server. It is used to serve \# HTML files and CGI.# processname: httpd# config: /etc/httpd/conf/httpd.conf# config: /etc/sysconfig/httpd# pidfile: /var/run/httpd.pid # Source function library.. /etc/rc.d/init.d/functions # Start httpd in the C locale by default.HTTPD_LANG=$&#123;HTTPD_LANG-"C"&#125; # This will prevent initlog from swallowing up a pass-phrase prompt if# mod_ssl needs a pass-phrase from the user.INITLOG_ARGS="" # Set HTTPD=/usr/sbin/httpd.worker in /etc/sysconfig/httpd to use a server# with the thread-based "worker" MPM; BE WARNED that some modules may not# work correctly with a thread-based MPM; notably PHP will refuse to start. # Path to the apachectl script, server binary, and short-form for messages.apachectl=/usr/local/apache24/bin/apachectl #根据自己安装路径httpd=$&#123;HTTPD-/usr/local/apache24/bin/httpd&#125;prog=httpdpidfile=$&#123;PIDFILE-/usr/local/apache24/logs/httpd.pid&#125; #自己安装路径下找lockfile=$&#123;LOCKFILE-/var/lock/subsys/httpd24&#125;RETVAL=0STOP_TIMEOUT=$&#123;STOP_TIMEOUT-10&#125;start() &#123; echo -n $"Starting $prog: " LANG=$HTTPD_LANG daemon --pidfile=$&#123;pidfile&#125; $httpd $OPTIONS RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; touch $&#123;lockfile&#125; return $RETVAL&#125;stop() &#123; echo -n $"Stopping $prog: " killproc -p $&#123;pidfile&#125; -d 10 $httpd RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; rm -f $&#123;lockfile&#125; $&#123;pidfile&#125;&#125;reload() &#123; echo -n $"Reloading $prog: " if ! LANG=$HTTPD_LANG $httpd $OPTIONS -t &gt;&amp;/dev/null; then RETVAL=$? echo $"not reloading due to configuration syntax error" failure $"not reloading $httpd due to configuration syntax error" else killproc -p $&#123;pidfile&#125; $httpd -HUP RETVAL=$? fi echo&#125; # See how we were called.case "$1" in start) start ;; stop) stop ;; status) status -p $&#123;pidfile&#125; $httpd RETVAL=$? ;; restart) stop start ;; condrestart) if [ -f $&#123;pidfile&#125; ] ; then stop start fi ;; reload) reload ;; graceful|help|configtest|fullstatus) $apachectl $@ RETVAL=$? ;; *) echo $"Usage: $prog &#123;start|stop|restart|condrestart|reload|status|fullstatus|graceful|help|configtest&#125;" exit 1esacexit $RETVAL 给/etc/init.d/httpd添加执行权限，并将httpd添加到开机自动启动123~]# chmod +x /etc/init.d/httpd~]# chkconfig httpd --add~]# chkconfig httpd on 编译安装PHP 后端PHP连接SQL Server时会出现乱码，解决办法：安装libiconv 编译安装libiconv12~]# ./configure --prefix=/usr/local/libiconv ~]# make -j 4 &amp;&amp; make install 编译安装PHP123~]# ./configure --prefix=/usr/local/php --with-curl --with-freetype-dir --with-gd --with-gettext --with-iconv-dir=/usr/local/libiconv --with-kerberos --with-libdir=lib64 --with-libxml-dir --with-openssl --with-pcre-regex --with-pdo-sqlite --with-pear --with-png-dir --with-xmlrpc --with-xsl --with-zlib --with-apxs2=/usr/local/apache24/bin/apxs --enable-libxml --enable-inline-optimization --enable-gd-native-ttf --enable-mbregex --enable-mbstring --enable-opcache --enable-pcntl --enable-shmop --enable-soap --enable-sockets --enable-sysvsem --enable-xml --enable-zip~]# make -j 4 &amp;&amp; make install -j 4 配置apache让它支持php修改apache的配置文件httpd.conf1~]# vim /usr/local/apache2.4/conf/httpd.conf 然后查找文本，取消注释1234LoadModule php5_module modules/libphp5.so #若已经取消进行下一步#添加AddType application/x-httpd-php .php 注意，如果上面一条没配置好的话会导致，，访问http:localhost/.php会直接下载，而不是打开 * 复制php配置文件1~]# cp php-5.6.3/php.ini-production /usr/local/php/lib/php.ini 重启httpd服务测试phpinfo页面Freetds编译安装 Freetds作用是Linux下PHP支持连接SQL Server 12345678910111213#下载~]# wget ftp://ftp.freetds.org/pub/freetds/stable/freetds-patched.tar.gz~]# tar -zxvf freetds-patched.tar.gz~]# cd freetds-1.00.15#编译安装~]# ./configure --prefix=/usr/local/freetds --with-tdsver=7.3 --enable-msdblib~]# make &amp;&amp; make install配置~]# cd ../~]# echo "/usr/local/freetds/lib/" &gt; /etc/ld.so.conf.d/freetds.conf~]# ldconfig 输入以下命令，查看TDS Version是否和你的SQL Server版本一致FreeTDS官网版本支持信息http://www.freetds.org/userguide/choosingtdsprotocol.htm1~]# /usr/local/freetds/bin/tsql -C 测试数据库是否联通1~]# /usr/local/freetds/bin/tsql -H 数据库服务器IP -p 端口号 -U 用户名 -P 密码 增加PHP的扩展mssql123456~]# cd /opt/software/php-5.5.12/ext/mssql/#linux下用phpize给PHP动态添加扩展~]# /usr/local/php/bin/phpize~]# ./configure --with-php-config=/usr/local/php/bin/php-config --with-mssql=/usr/local/freetds/~]# make &amp;&amp; make install 修改PHP配置文件1234在php.ini配置文件中增加.so~]# cd /usr/local/php/lib下的php.ini#增加：extension = "mssql.so" 重启httpd服务即可 错误有的页面正常打开，有的打开显示源码报错 刚开始以为是配置的环境问题，实际则是因为开发在windows环境下写php网页时，开头用的&lt;? ?&gt; 而不是Linux下的&lt;?php ?&gt; 解决办法：1234567第一种：将php.ini里的short_open_tag = Off修改为on第二种：让开发将&lt;? ?&gt; 修改为Linux下可以识别的&lt;?php ?&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[KeepAlived高可用Nginx]]></title>
      <url>%2Fposts%2Fbf9d2e83%2F</url>
      <content type="text"><![CDATA[主Nginx /etc/nginx/conf.d/default.conf同时修改nginx.conf里监听的端口 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748~]# vim /etc/nginx/conf.d/default.conf## The default server# upstream backend &#123; server 10.207.0.88 weight=1; server 10.207.0.89 weight=1; &#125; server &#123; listen 80; server_name localhost; # 当nginx将php代码送至后端RS处理时请求头中的Host值会是backend. # php代码在RS上处理时,其内部代码会去请求图片/层叠样式表等静态资源以填充页面. # 而php代码去请求后端资源时使用的是如http://backend/xxxx.php这样的url,自然是取不到的. # 所以我们要在nginx向后代理遇到Host为backend时,将其转换为127.0.0.1. set $my_host $http_host; if ($http_host = "backend") &#123; set $my_host "127.0.0.1"; &#125; location / &#123; proxy_pass http://backend; proxy_redirect off; proxy_set_header Host $my_host; &#125; &#125;server &#123; listen 8080 default_server; server_name localhost; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125;&#125; keepalived12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost # 邮件给本机root用户 &#125; notification_email_from admin@nginx-124.com smtp_server 127.0.0.1 # 使用本机作为smtp服务器 smtp_connect_timeout 30 router_id 8a028eb8 # 标识主机,可以使用主机名. vrrp_mcast_group4 224.0.71.18 # 多播地址,用于发送心跳信号.尽量让集群内的主机处于同一个独立的多播地址.&#125;# nginx进程监控脚本.如果进程不在,降低自身权重,使从节点主机优先级高于自身,将VRRP漂移至从节点主机.vrrp_script chk_nginx &#123; script "killall -0 nginx" interval 2 weight -8&#125;vrrp_instance VI_1 &#123; state MASTER # vrrp实例VI_1中作为主 interface eth0 virtual_router_id 71 # 0-255范围内的数字,用于区分vrrp实例,所以两个实例不能一致. priority 100 # MASTER的优先级要高一些 advert_int 1 authentication &#123; auth_type PASS auth_pass uWjblY61 # 简单字符认证, 8位任意字符串. &#125; virtual_ipaddress &#123; 10.207.0.164/24 brd 10.207.0.164 dev eth0 label eth0:0 # VIP1 &#125; # 在此处调用nginx进程监控脚本 track_script &#123; chk_nginx &#125; # 关闭争用. 争用是指当高优先级节点上线会立即争夺成为MASTER # 而不管其它节点是否正在给用户提供服务. #nopreempt # 开启争用时,会延迟一段时间才开始. #preempt_delay 300&#125;vrrp_instance VI_2 &#123; state BACKUP # vrrp实例VI_2中作为备 interface eth0 virtual_router_id 171 priority 95 # MASTER的优先级要高一些 advert_int 1 authentication &#123; auth_type PASS auth_pass uWjblY62 &#125; virtual_ipaddress &#123; 10.207.0.164/24 brd 10.207.0.164 dev eth0 label eth0:0 # VIP1 &#125; # 在此处调用nginx进程监控脚本 track_script &#123; chk_nginx &#125;&#125; 备Nginx /etc/nginx/conf.d/default.conf同时修改nginx.conf里监听的端口 12345678910111213141516171819202122232425262728293031323334353637383940414243444546upstream backend &#123; server 10.207.0.88 weight=1; server 10.207.0.89 weight=1; &#125; server &#123; listen 80; server_name localhost; # 当nginx将php代码送至后端RS处理时请求头中的Host值会是backend. # php代码在RS上处理时,其内部代码会去请求图片/层叠样式表等静态资源以填充页面. # 而php代码去请求资源时使用的是如http://backend/xxxx.php这样的url,自然是取不到的. # 所以我们要在nginx向后代理遇到Host为backend时,将其转换为127.0.0.1. set $my_host $http_host; if ($http_host = "backend") &#123; set $my_host "127.0.0.1"; &#125; location / &#123; proxy_pass http://backend; proxy_redirect off; proxy_set_header Host $my_host; &#125; &#125;server &#123; listen 8080 default_server; server_name localhost; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; &#125; keepalived12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost # 邮件给本机root用户 &#125; notification_email_from admin@nginx-133.com smtp_server 127.0.0.1 # 使用本机作为smtp服务器 smtp_connect_timeout 30 router_id 8a028eb8 # 标识主机,可以使用主机名. vrrp_mcast_group4 224.0.71.18 # 多播地址,用于发送心跳信号.尽量让集群内的主机处于同一个独立的多播地址.&#125;# nginx进程监控脚本.如果进程不在,降低自身权重,使从节点主机优先级高于自身,将VRRP漂移至从节点主机.vrrp_script chk_nginx &#123; script "killall -0 nginx" interval 2 weight -8&#125;vrrp_instance VI_1 &#123; state BACKUP # vrrp实例VI_1中HostA作为备 interface eth0 virtual_router_id 71 # 0-255范围内的数字,用于区分vrrp实例,所以两个实例不能一致. priority 95 # MASTER的优先级要高一些 advert_int 1 authentication &#123; auth_type PASS auth_pass uWjblY61 # 简单字符认证, 8位任意字符串. &#125; virtual_ipaddress &#123; 10.207.0.164/24 brd 10.207.0.164 dev eth0 label eth0:0 # VIP1 &#125; # 在此处调用nginx进程监控脚本 track_script &#123; chk_nginx &#125; # 关闭争用. 争用是指当高优先级节点上线会立即争夺成为MASTER # 而不管其它节点是否正在给用户提供服务. #nopreempt # 开启争用时,会延迟一段时间才开始. #preempt_delay 300&#125;vrrp_instance VI_2 &#123; state MASTER # vrrp实例VI_2中HostA作为主 interface eth0 virtual_router_id 171 priority 100 # BACKUP的优先级要低一些 advert_int 1 authentication &#123; auth_type PASS auth_pass uWjblY62 &#125; virtual_ipaddress &#123; 10.207.0.164/24 brd 10.207.0.164 dev eth0 label eth0:0 # VIP1 &#125; # 在此处调用nginx进程监控脚本 track_script &#123; chk_nginx &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS搭建KVM虚拟化环境]]></title>
      <url>%2Fposts%2Fd50e1795%2F</url>
      <content type="text"><![CDATA[kvm虚拟机安装 R730服务器为CentOS6.7关闭iptables、selinux在BIOS中开启CPU的虚拟化 检查你的系统是否支持虚拟化123~]# grep -Ei 'vmx|svm' /proc/cpuinfo如果有输出内容，则支持，其中intel cpu支持会有vmx，amd cpu支持会有svm 装载内核1234567~]# lsmod | grep kvm #查看是否有内容输出若无内容，则装载kvm的模块即可~]# modprobe kvm~]# modprobe kvm_intel~]# lsmod | grep kvm #再次查看是否有内容输出 安装虚拟化软件包组1~]# yum groupinstall -y "Virtualization" "Virtualization Platform" "Virtualization Client" "Virtualization Tools" 修改网络为桥接 注意：此种方式会造成网络中断，请确保能通过其它方式访问物理机。如：console端口 默认为nat方式：虚拟机不可以直接获取到和物理机同一网段的IP地址，必须通过物理机中转桥接方式：虚拟机可以获取到和物理机同一网段的IP地址 1234567891011121314151617181920212223242526~]# cd /etc/sysconfig/network-script/~]# cp ifcfg-em1&#123;,.bak&#125;~]# cp ifcfg-em1 ifcfg-br0~]# vim ifcfg-br0DEVICE=br0TYPE=BridgeONBOOT=yesNM_CONTROLLED=yesBOOTPROTO=noneIPADDR=10.207.0.112PREFIX=16GATEWAY=10.207.0.1DNS1=223.5.5.5~]# vim ifcfg-em1DEVICE=em1BRIDGE=br0ONBOOT=yesBOOTPROTO=noneTYPE=Ethernet# 默认的NetworkManager无法管理桥接网络, 所以要关闭NetworkManager服务, 使用network服务~]# service NetworkManager stop~]# chkconfig NetworkManager off 重启网络服务 会造成远程连接断开,我这里可通过10.207.22.xxx的远程控制卡方式(console端口)来设置 1service network restart 管理虚拟机1~]# virt-manager #可打开一个图形界面，前提是服务端有图形界面 错误总结R730开启虚拟化1开机按F2--&gt; system BIOS --&gt; Processor Settings --&gt; 启用virtualization 重启network失败12345678910111213前面重启网络服务时报错：弹出环回接口： [确定] 弹出界面 eth0： 错误：激活连接失败：Master connection not found or invalid [失败] 弹出界面 br0： 错误：激活连接失败：Failed to determine connection's virtual interface name [失败] RTNETLINK answers: File exists RTNETLINK answers: File exists RTNETLINK answers: File exists 解决办法~]# service NetworkManager stop~]# chkconfig NetworkManager off#原因：桥接网络NetworkManager无法管理, 关闭NetworkManager服务, 使用network服务 virt-manager启动失败12~]# service libvirtd start~]# chkconfig libvirtd on]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[戴尔R730服务器安装系统]]></title>
      <url>%2Fposts%2Fe11fbde0%2F</url>
      <content type="text"><![CDATA[总结下使用PowerEdge R730安装windows server 2012 R2遇到的坑。科普：PowerEdge服务器生命周期控制器：Lifecycle Controller 12345678910111213141516171819202122232425262728293031安装准备：系统光盘(刻录到U盘好像不能识别)，Dell引导盘(若没有就用系统光盘好像也可以)正确步骤：光驱插入Dell引导盘(或系统光盘)开机按F10 --&gt; 选择语言(中文)，键盘类型(默认) --&gt; ip地址(默认) --&gt;初始化完成进入Lifecycle Controller界面 step:1如果需要做raid，就在这里做。由于机房管理员已经做好了raid5+1，这里就直接选OS部署step:2启动模式选择uefi，安全引导选已启用为什么？windows server 2012 R2是采用和windows8一样的内核，默认采用uefi启动。之前这里一直选BIOS，之后重启就会出错。之前还以为是下的镜像有问题，测试了好几次，才发现是引导模式选错。step:3选手动部署step:4插入操作系统介质确保光驱里是系统光盘step:5重新引导step:6安装。 PowerEdge R730安装Xen Serve6.5由于有以上经验，这些都不是问题了。就是在上面step2时，启动模式还是要选择为bios。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[IT人士必备网站]]></title>
      <url>%2Fposts%2Fa7331ce9%2F</url>
      <content type="text"><![CDATA[我觉得，作为程序员，开发者，运维人员，科学上网应该就像人的尊严一样，没有它，你写代码都会浑身不舒服。 Google 不管是新手程序员还是老手程序员，工作和学习过程中都会遇到一些问题，那么遇到问题利用Google 搜索估计是最快解决方案。而且Google 的结果，让你很容易解决问题。关键是Google 不做恶，没广告。 Github 作为全世界最大的同性交流网站（代码托管平台），上面有各种大牛，作为新手的我只能默默地去撸大牛的代码，期待能和大牛的差距一步步减少。除了学习之外，你也可以利用闲暇的时间来来将自己的开源项目放在上面，从侧面也是对自己的宣传，对找工作也有帮助。类似的有国外的Bitbucket，gitcafe，coding.net 等等。 StackOverflow 最大的技术问答网站，Google 搜索技术问题，结果很大的比例都来自StackOverflow，而且可能我们折腾好久的问题，大牛的一句话都点中要害。 HackNews Hacker News 是一家关于计算机黑客和创业公司的社会化新闻网站，你可以讲自己写的博客或者对一些业界新闻拿出来来讨论。就算自己在上面多看看也是很涨见识的。而且我注意到，国外的很多人的博客都不留评论框，一般写完文章，就会放在HackNews 讨论。国内也有类似的网站。Startup News。 InfoQ InfoQ 是一个面对开发的服务网站，而他的自我介绍：促进软件开发领域知识与创新的传播。在上面你会看到很多专业人士分享的专业知识，他们分享的东西，可能是一般开发者很难接触到的。由InfoQ 主办的Qcon，ArchSummit 大会，也是非常值得一去的。 V2ex 我觉得V2ex 算是一个程序员吐槽，交流的网站。反正上面由好多好多程序员。而且有个专栏叫《酷工作》，反正由好多求职和招聘的。 SegmentFault SegmentFault 是一个面向开发者的技术问答社区，你可以在上面问答，写博客，线下交流活动等等。 开源中国 开源中国是目前中国最大的开源技术社区，为IT 开发者提供了一个发现、使用、并交流开源技术的平台。 技术博客 我们在学习过程中，很多时候都是看别人的技术博客来成长的，当然技术博客网站由很多。比如CSDN，cnBlogs，51CTO，itEyes 等等。 Mooc Mooc 翻译为中文叫做在线网络公开课，Mooc 的愿景是让那些没有机会接受正式教育的人能接受教育，主要做技术的Mooc 也有很多。比如像国外的coursera，edx，udacity，国内由像慕课网，极客学院等等。 开发者服务网站 这个标题可能叫可能叫的不太准确，稀土掘金：挖掘最优质的互联网技术。它主要邀请一些业界比较资深的开发者，作为联合编辑来推荐文章，文章质量有了保证。开发者头条：程序员的首选阅读分享平台。博乐在线：一个专注于IT互联网的聚合分享站点。当然其他的也很多啦，比如像ImportNew，酷勤网等等。 原文地址：http://tikitoo.me/2015/11/02/developer-website/]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[二十款免费渗透测试工具]]></title>
      <url>%2Fposts%2F7ab97256%2F</url>
      <content type="text"><![CDATA[对于企业的IT经理和网络管理员来说，保护相对脆弱的WiFi网络的最佳办法就拿黑客圈最流行的，“火力”最猛的工具入侵你自己的无线网络，从中找出网络安全漏洞并有针对性地补强。 根据最新的安全情报，提炼出20款免费工具推荐如下： 1、AircrackAircrack是目前最流行的WiFi密码破解工具。市面上能破解 WiFi加密的工具有很多，不外乎利用WEP安全漏洞或者暴力字典攻击的方式破解WPA/WPA2 PSK密码。WPA2 AES/CCMP加密依然是相对安全的选择。如果采用WPA2 PSK模式，那么你的密码长度最好是13位以上混合字符。在你的Wi-Fi网络被入侵或者“蹭网”之前，最好先用破解工具自我攻击一下。 Aircrack是一个开源的WEP/WPA/WPA2 PSK破解工具，可以运行在windows、Mac OS X、Linux和OpenBSD上。可以下载到Vmware镜像文件或Live CD文件。 下载链接: http://www.aircrack-ng.org/ 2、AirSnortAirSnort是另外一款流行的WLAN密码破解工具，可以破解WEP秘钥。 下载链接: http://sourceforge.net/projects/airsnort/ 3、KismetKismet是一个开源的WiFi扫描器，包嗅探器和入侵政策系统，可以在windows、Mac OSX、Linux和BSD上运行。Kismet能显示AP详细信息，包括隐藏的SSID，还能捕获原始无线数据包，还可以将数据导入 Wireshark、TCPdump等工具进行分析。在windows环境，受驱动程序限制，Kismet只能与 CACE AirPcap无线网卡配合工作。但在Mac OSX和Linux上，Kismet可以兼容很多无线网卡。 下载链接: http://www.kismetwireless.net/download.shtml 4、Cain &amp; AbleCain和Abel是windows上的密码恢复、破解和嗅探工具，可被用于展示如何从网络中嗅探明文密码。 下载链接: http://www.oxid.it/cain.html 5、WireSharkWireShark是当下非常流行的网络协议分析工具，关于最新的WireShark2.0版本的新功能的信息在这里。 下载链接: https://www.wireshark.org/ 6、Fern WiFi Wireless CrackerFern是一款优秀的网络漏洞扫描和WLAN破解工具，可以破解获取WEP/WPA/WPS秘钥。Fren的开发工作从未停顿，而且专业版还提供更多强大功能。 下载链接: http://www.fern-pro.com/downloads.php 7、CoWPAttyCoWPAtty也是一款无线密码破解工具，新版预置了包含上千个流行SSID的17万个字典文件，大大提高了破解速度，类似国内的各种WiFi钥匙应用。 下载链接: http://sourceforge.net/projects/cowpatty/ 8、AirjackAirjack是802.11包注入工具，过去曾被用来发起DOS或中间人攻击。 下载链接: http://sourceforge.net/projects/airjack/ 9、WepAttack顾名思义，WepAttack也是一个802.11WEP秘钥破解工具，同时也是一个开源的Linux工具。 下载链接: http://wepattack.sourceforge.net/ 10、NetStumblerNetStumbler是一个运行于Windows平台的无线密码破解工具。该工具已经很久未更新，无法兼容64位Windows版本，而且会被大多数无线入侵侦测工具发现，因此适合在家练手使用。 下载链接: http://www.stumbler.net/ 11、inSSIDerinSSIDer是Windows和Mac平台上最流行的WiFi扫描工具，曾荣获最佳开源网络软件称号，不过目前已经转为收费版本（19.99美元） 下载链接: http://www.inssider.com/ 12、Wifiphisher开源无线安全工具Wifiphisher能够对WPA加密的AP无线热点实施自动化钓鱼攻击，获取密码账户。由于利用了社工原理实施中间人攻击，Wifiphisher在实施攻击时无需进行暴力破解。WiFiphiser是基于MIT许可模式的开源软件，运行于Kali Linux之上。 下载链接：https://github.com/sophron/wifiphisher 13、KisMac一个类似Kismet的工具，面向Mac平台。 下载链接:http://kismac-ng.org/ 14、Reaver如果你使用的是无线路由器，那么你需要注意去年底发现的一个安全漏洞：很多路由器厂商提供的WPS（一键认证模式，方便用户完成路由器设备连接认证）的 PIN码可以在数小时内被破解。Reaver就是这样一个工具，Reaver是一个Linux程序，能在4-10小时内暴力破解无线路由器的WPS PIN码和WPA/WPA2 PSK密码。Reaver还提供一个方便使用的专用硬件方案：Reaver Pro，有图形web操作界面。 下载链接:https://code.google.com/p/reaver-wps/downloads/list 15、WifiteWifite是一个很不错的无线密码破解工具，支持通过Reaver破解WPS秘钥，运行于Linux平台。 下载链接: https://github.com/derv82/wifite 16、WepDecryptWepDecrypt是一款适合初学者的无线密码字典攻击工具，用C语言写成，但很久没有更新了。下载链接:http://wepdecrypt.sourceforge.net/wepdecrypt-manual.html 17、OmniPeekOmniPeek是一款网络包嗅探分析工具，属于Windows平台“独占”工具。需要使用者对网络协议和数据包有较深入的了解。 下载地址：http://www.wildpackets.com/products/distributed_network_analysis/omnipeek_network_analyzer 18、CloudCracker顾名思义，CloudCracker是一款云端WiFi密码破解工具。 下载地址: https://www.cloudcracker.com/ 19、CommonView for Wi-FiCommonView是一款流行的额网络监控和包分析工具，最大特点是拥有GUI图形界面。 下载地址：http://www.tamos.com/products/commwifi/ 20、PyritPyrit也是一款优秀的WiFi密码暴力破解工具（WPA/WPA2-PSK）。运行于FreeBSD、MacOS和Linux平台。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL高可用之MHA的搭建]]></title>
      <url>%2Fposts%2Fd872247d%2F</url>
      <content type="text"><![CDATA[MHA简介 MHA（Master High Availability）目前在MySQL高可用方面是一个相对成熟的解决方案，它由日本DeNA公司youshimaton（现就职于Facebook公司）开发，是一套优秀的作为MySQL高可用性环境下故障切换和主从提升的高可用软件。在MySQL故障切换过程中，MHA能做到在0~30秒之内自动完成数据库的故障切换操作，并且在进行故障切换的过程中，MHA能在最大程度上保证数据的一致性，以达到真正意义上的高可用。 该软件由两部分组成：MHA Manager（管理节点）和MHA Node（数据节点）。MHA Manager可以单独部署在一台独立的机器上管理多个master-slave集群，也可以部署在一台slave节点上。MHA Node运行在每台MySQL服务器上，MHA Manager会定时探测集群中的master节点，当master出现故障时，它可以自动将最新数据的slave提升为新的master，然后将所有其他的slave重新指向新的master。整个故障转移过程对应用程序完全透明。 在MHA自动故障切换过程中，MHA试图从宕机的主服务器上保存二进制日志，最大程度的保证数据的不丢失，但这并不总是可行的。例如，如果主服务器硬件故障或无法通过ssh访问，MHA没法保存二进制日志，只进行故障转移而丢失了最新的数据。使用MySQL 5.5的半同步复制，可以大大降低数据丢失的风险。MHA可以与半同步复制结合起来。如果只有一个slave已经收到了最新的二进制日志，MHA可以将最新的二进制日志应用于其他所有的slave服务器上，因此可以保证所有节点的数据一致性。 目前MHA主要支持一主多从的架构，要搭建MHA,要求一个复制集群中必须最少有三台数据库服务器，一主二从，即一台充当master，一台充当备用master，另外一台充当从库，因此至少需要三台服务器。 MHA工作原理总结为以下几条 从宕机崩溃的master保存二进制日志事件（binlog events）; 识别含有最新更新的slave; 应用差异的中继日志(relay log) 到其他slave; 应用从master保存的二进制日志事件(binlog events); 提升一个slave为新master; 使用其他的slave连接新的master进行复制。 准备工作 准备四台虚拟机, 均为CentOS-7-x86_64最小化安装, iptables与SELinux均处于关闭状态, 配置好yum源(base和epel). 做好快照, 以便每次实验后快速恢复. 确保各节点时间保持一致 各节点需开启二进制日志和中继日志 各节点彼此可通过主机名进行通信 各节点彼此间无密钥进行通信 1234567891011121314151617181920212223HostA(Master)OS: CentOS-7-x86_64hostname: 80e54d87.twoyang.comeno16777736: 172.18.71.101/16gateway: 172.18.0.1HostB(Slave)OS: CentOS-7-x86_64hostname: b9cf468b.twoyang.comeno16777736: 172.18.71.102/16gateway: 172.18.0.1HostC(Slave)OS: CentOS-7-x86_64hostname: 1f5fafa6.twoyang.comeno16777736: 172.18.71.103/16gateway: 172.18.0.1HostD(MHA Manager)OS: CentOS-7-x86_64hostname: 1478a474.twoyang.comeno16777736: 172.18.71.130/16gateway: 172.18.0.1 先不管MHA, 按照主从复制模型搭建好集群. 主从复制HostA(Master)12345678910111213141516171819202122232425262728293031[root@80e54d87 ~]# yum install -y mariadb-serversed -i '/\[server\]/a\character-set-server=utf8' /etc/my.cnf.d/server.cnfsed -i '/\[server\]/a\collation-server=utf8_general_ci' /etc/my.cnf.d/server.cnfsed -i '/\[server\]/a\default-storage-engine=InnoDB' /etc/my.cnf.d/server.cnfsed -i '/\[server\]/a\innodb-file-per-table=TRUE' /etc/my.cnf.d/server.cnfsed -i '/\[server\]/a\skip-name-resolve=TRUE' /etc/my.cnf.d/server.cnfsed -i '/\[server\]/a\log_bin=master-binlog' /etc/my.cnf.d/server.cnf# 注意server_id为集群内的唯一标识.sed -i '/\[server\]/a\server_id=1' /etc/my.cnf.d/server.cnf[root@80e54d87 ~]# systemctl start mariadb.service[root@80e54d87 ~]# mysql...# 创建用户前记录下二进制日志文件位置, 一会儿让从节点从此处开始复制, 就会自动创建此用户了.# 因为主节点宕机时, 从节点有可能会被MHA管理节点提升为主节点供其它从节点复制.MariaDB [(none)]&gt; SHOW MASTER STATUS;+----------------------+----------+--------------+------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+----------------------+----------+--------------+------------------+| master-binlog.000003 | 245 | | |+----------------------+----------+--------------+------------------+1 row in set (0.00 sec)# 授权用户'repl'@'172.18.71.%'可以复制数据MariaDB [(none)]&gt; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'repl'@'172.18.71.%' IDENTIFIED BY 'magedu';Query OK, 0 rows affected (0.00 sec)# 另外还得创建一个SUPER权限的用户用于MHA管理节点来控制.MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON *.* TO 'mha'@'%' IDENTIFIED BY 'magedu';Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; FLUSH PRIVILEGES;Query OK, 0 rows affected (0.00 sec) HostB(Slave)12345678910111213141516171819202122232425262728293031323334353637383940414243[root@b9cf468b ~]# yum install -y mariadb-serversed -i '/\[server\]/a\character-set-server=utf8' /etc/my.cnf.d/server.cnfsed -i '/\[server\]/a\collation-server=utf8_general_ci' /etc/my.cnf.d/server.cnfsed -i '/\[server\]/a\default-storage-engine=InnoDB' /etc/my.cnf.d/server.cnfsed -i '/\[server\]/a\innodb-file-per-table=TRUE' /etc/my.cnf.d/server.cnfsed -i '/\[server\]/a\skip-name-resolve=TRUE' /etc/my.cnf.d/server.cnf# 从节点也要开启二进制日志, 因为可能会被提升为主节点.sed -i '/\[server\]/a\log_bin=master-binlog' /etc/my.cnf.d/server.cnfsed -i '/\[server\]/a\relay_log=relaylog' /etc/my.cnf.d/server.cnf# 对于某些滞后从库的恢复依赖于其他从库的relay_log，因此采取禁用自动删除功能以及定期清理的办法.sed -i '/\[server\]/a\relay_log_purge=OFF' /etc/my.cnf.d/server.cnfsed -i '/\[server\]/a\read-only=ON' /etc/my.cnf.d/server.cnf# 注意server_id为集群内的唯一标识.sed -i '/\[server\]/a\server_id=5' /etc/my.cnf.d/server.cnf[root@b9cf468b ~]# systemctl start mariadb.service[root@b9cf468b ~]# mysql...# 指向HostA将其作为主节点MariaDB [(none)]&gt; CHANGE MASTER TO MASTER_HOST='172.18.71.101', MASTER_USER='repl', MASTER_PASSWORD='magedu', MASTER_LOG_FILE='master-binlog.000003', MASTER_LOG_POS=245;Query OK, 0 rows affected (0.00 sec)# 启动从节点, 即启动IO_thread和SQL_thread进程, 开始复制.MariaDB [(none)]&gt; START SLAVE;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; SHOW SLAVE STATUS\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.18.71.101 Master_User: repl Master_Port: 3306 Connect_Retry: 60 Master_Log_File: master-binlog.000003 Read_Master_Log_Pos: 555 Relay_Log_File: relaylog.000002 Relay_Log_Pos: 843 Relay_Master_Log_File: master-binlog.000003 Slave_IO_Running: Yes Slave_SQL_Running: Yes......1 row in set (0.00 sec) HostC(Slave) HostC与HostB做相同配置, 仅server_id必须不同. MHA集群初始化 建立主机信任, 时间同步, 统一增加yum源. 这一步其实在哪个节点上做都可以, 我这里选择HostA. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108# 写了个脚本来做这个事情[root@80e54d87 ~]# wget https://raw.githubusercontent.com/twoyang0917/LearnInMagedu/master/shell/sshtrust.sh# 有效代码是这个样子的[root@80e54d87 ~]# cat sshtrust.sh...HOSTS=("172.18.71.101" "172.18.71.102")if ! [ $# -eq 1 ]; then echo "$0 --key" echo "$0 \"COMMAND\"" exit 1fi if [ "$1" = "--key" ]; then [ -f ~/.ssh/id_rsa ] || ssh-keygen -t rsa -f ~/.ssh/id_rsa -N '' [ -f ~/.ssh/id_rsa.pub ] &amp;&amp; cat ~/.ssh/id_rsa.pub &gt; ~/.ssh/authorized_keys &amp;&amp; chmod 600 ~/.ssh/authorized_keys for host in $&#123;HOSTS[*]&#125;; do # 因为其它节点上都没有~/.ssh这么一个目录, 还得远程创建, 这导致分发密钥时要输两次密码还挺烦的. ssh root@$host "[ -d ~/.ssh ] || mkdir ~/.ssh" scp -p ~/.ssh/&#123;id_rsa,authorized_keys&#125; root@$host:~/.ssh/ doneelse for host in $&#123;HOSTS[*]&#125;; do ssh root@$host $1 donefi# 将集群中所有节点IP地址(包括本机)都加入这个主机列表数组[root@80e54d87 ~]# vim sshtrust.shHOSTS=("172.18.71.101" "172.18.71.102" "172.18.71.103" "172.18.71.130")# 分发密钥, 两两节点间均建立主机信任.[root@80e54d87 ~]# bash sshtrust.sh --keyGenerating public/private rsa key pair.Created directory '/root/.ssh'.Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:02:de:f2:86:5b:4b:3d:2b:70:cc:1c:c9:d2:65:5d:0b root@80e54d87.twoyang.comThe key's randomart image is:+--[ RSA 2048]----+| .E.. || o .. . || .o + . || ..o= || o=o.S || .+=o || .o= o || =.. o || . ... |+-----------------+The authenticity of host '172.18.71.101 (172.18.71.101)' can't be established.ECDSA key fingerprint is 2d:37:94:8b:81:ea:57:bc:93:18:44:d6:f6:97:6c:5b.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added '172.18.71.101' (ECDSA) to the list of known hosts.The authenticity of host '172.18.71.102 (172.18.71.102)' can't be established.ECDSA key fingerprint is 07:d0:4c:77:32:95:bc:df:8b:c1:b0:41:d6:af:66:59.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added '172.18.71.102' (ECDSA) to the list of known hosts.root@172.18.71.102's password: root@172.18.71.102's password: id_rsa 100% 1679 1.6KB/s 00:00 authorized_keys 100% 407 0.4KB/s 00:00 The authenticity of host '172.18.71.103 (172.18.71.103)' can't be established.ECDSA key fingerprint is e5:49:95:0f:18:ac:e8:e3:22:6a:7e:09:ae:f9:61:55.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added '172.18.71.103' (ECDSA) to the list of known hosts.root@172.18.71.103's password: root@172.18.71.103's password: id_rsa 100% 1679 1.6KB/s 00:00 authorized_keys 100% 407 0.4KB/s 00:00 The authenticity of host '172.18.71.130 (172.18.71.130)' can't be established.ECDSA key fingerprint is 6d:01:30:42:82:4a:ae:5a:ec:7e:62:7c:7e:31:64:b9.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added '172.18.71.130' (ECDSA) to the list of known hosts.root@172.18.71.130's password: root@172.18.71.130's password: id_rsa 100% 1679 1.6KB/s 00:00 authorized_keys 100% 407 0.4KB/s 00:00# 同步时间[root@80e54d87 ~]# bash sshtrust.sh "ntpdate 172.18.0.1" 6 Jun 20:55:36 ntpdate[3354]: step time server 172.18.0.1 offset 2644756.261973 sec 6 Jun 20:53:30 ntpdate[11248]: step time server 172.18.0.1 offset 2640569.256399 sec 6 Jun 20:53:36 ntpdate[40408]: step time server 172.18.0.1 offset -2.854146 sec 6 Jun 20:53:42 ntpdate[3457]: step time server 172.18.0.1 offset 3975759.234646 sec[root@80e54d87 ~]# bash sshtrust.sh "hwclock --systohc"[root@80e54d87 ~]# bash sshtrust.sh dateMon Jun 6 20:56:25 CST 2016Mon Jun 6 20:56:25 CST 2016Mon Jun 6 20:56:25 CST 2016Mon Jun 6 20:56:25 CST 2016# 因为MHA在cenots官方yum源中没有提供, 所以从Google Driver上下载下来做成了yum源.[root@80e54d87 ~]# bash sshtrust.sh "yum-config-manager --add-repo=http://172.18.71.254/templates/twoyang-c7.repo"Loaded plugins: fastestmirror, langpacksadding repo from: http://172.18.71.254/templates/twoyang-c7.repograbbing file http://172.18.71.254/templates/twoyang-c7.repo to /etc/yum.repos.d/twoyang-c7.reporepo saved to /etc/yum.repos.d/twoyang-c7.repoLoaded plugins: fastestmirror, langpacksadding repo from: http://172.18.71.254/templates/twoyang-c7.repograbbing file http://172.18.71.254/templates/twoyang-c7.repo to /etc/yum.repos.d/twoyang-c7.reporepo saved to /etc/yum.repos.d/twoyang-c7.repoLoaded plugins: fastestmirror, langpacksadding repo from: http://172.18.71.254/templates/twoyang-c7.repograbbing file http://172.18.71.254/templates/twoyang-c7.repo to /etc/yum.repos.d/twoyang-c7.reporepo saved to /etc/yum.repos.d/twoyang-c7.repoLoaded plugins: fastestmirror, langpacksadding repo from: http://172.18.71.254/templates/twoyang-c7.repograbbing file http://172.18.71.254/templates/twoyang-c7.repo to /etc/yum.repos.d/twoyang-c7.reporepo saved to /etc/yum.repos.d/twoyang-c7.repo 安装配置MHA123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132# 集群内所有节点(包括管理节点)需要安装Node包[root@80e54d87 ~]# bash sshtrust.sh "yum install -y mha4mysql-node.noarch"# HostD作为MHA管理节点需要安装Manager包[root@1478a474 ~]# yum install -y mha4mysql-manager.noarch# 默认是没有配置文件, 自己建立目录和配置文件.[root@1478a474 ~]# mkdir /etc/masterha[root@1478a474 ~]# vim /etc/masterha/app1.cnf[server default]user=mha # 被控节点授权给管理节点SUPER权限的用户password=magedu # 被控节点授权给管理节点SUPER权限用户的口令manager_workdir=/data/masterha/app1 # 管理节点的工作目录, 会自动建立.manager_log=/data/masterha/app1/manager.log # 管理节点的日志remote_workdir=/data/masterha/app1 # 被控节点的工作目录, 会自动建立.ssh_user=root # 被控节点的ssh用户repl_user=repl # 用于数据库复制的用户repl_password=magedu # 用于数据库复制的用户的口令ping_interval=1 # 被控节点的健康检查时间间隔[server1]hostname=172.18.71.101candidate_master=1 # 作为主节点候选[server2]hostname=172.18.71.102candidate_master=1[server3]hostname=172.18.71.103no_master=1 # 永远不作为主节点# 用mha提供的脚本做主机信任检查.[root@1478a474 ~]# masterha_check_ssh --conf=/etc/masterha/app1.cnfMon Jun 6 22:12:23 2016 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping.Mon Jun 6 22:12:23 2016 - [info] Reading application default configuration from /etc/masterha/app1.cnf..Mon Jun 6 22:12:23 2016 - [info] Reading server configuration from /etc/masterha/app1.cnf..Mon Jun 6 22:12:23 2016 - [info] Starting SSH connection tests..Mon Jun 6 22:12:24 2016 - [debug] Mon Jun 6 22:12:24 2016 - [info] All SSH connection tests passed successfully.# 用mha提供的脚本做数据库复制检查.[root@1478a474 ~]# masterha_check_repl --conf=/etc/masterha/app1.cnfMon Jun 6 22:19:40 2016 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping.Mon Jun 6 22:19:40 2016 - [info] Reading application default configuration from /etc/masterha/app1.cnf..Mon Jun 6 22:19:40 2016 - [info] Reading server configuration from /etc/masterha/app1.cnf..Mon Jun 6 22:19:40 2016 - [info] MHA::MasterMonitor version 0.57.Mon Jun 6 22:19:40 2016 - [info] GTID failover mode = 0Mon Jun 6 22:19:40 2016 - [info] Dead Servers:Mon Jun 6 22:19:40 2016 - [info] Alive Servers:Mon Jun 6 22:19:40 2016 - [info] 172.18.71.101(172.18.71.101:3306)Mon Jun 6 22:19:40 2016 - [info] 172.18.71.102(172.18.71.102:3306)Mon Jun 6 22:19:40 2016 - [info] 172.18.71.103(172.18.71.103:3306)Mon Jun 6 22:19:40 2016 - [info] Alive Slaves:Mon Jun 6 22:19:40 2016 - [info] 172.18.71.102(172.18.71.102:3306) Version=5.5.44-MariaDB-log (oldest major version between slaves) log-bin:enabledMon Jun 6 22:19:40 2016 - [info] Replicating from 172.18.71.101(172.18.71.101:3306)Mon Jun 6 22:19:40 2016 - [info] Primary candidate for the new Master (candidate_master is set)Mon Jun 6 22:19:40 2016 - [info] 172.18.71.103(172.18.71.103:3306) Version=5.5.44-MariaDB-log (oldest major version between slaves) log-bin:enabledMon Jun 6 22:19:40 2016 - [info] Replicating from 172.18.71.101(172.18.71.101:3306)Mon Jun 6 22:19:40 2016 - [info] Not candidate for the new Master (no_master is set)Mon Jun 6 22:19:40 2016 - [info] Current Alive Master: 172.18.71.101(172.18.71.101:3306)Mon Jun 6 22:19:40 2016 - [info] Checking slave configurations..Mon Jun 6 22:19:40 2016 - [info] Checking replication filtering settings..Mon Jun 6 22:19:40 2016 - [info] binlog_do_db= , binlog_ignore_db= Mon Jun 6 22:19:40 2016 - [info] Replication filtering check ok.Mon Jun 6 22:19:40 2016 - [info] GTID (with auto-pos) is not supportedMon Jun 6 22:19:40 2016 - [info] Starting SSH connection tests..Mon Jun 6 22:19:42 2016 - [info] All SSH connection tests passed successfully.Mon Jun 6 22:19:42 2016 - [info] Checking MHA Node version..Mon Jun 6 22:19:42 2016 - [info] Version check ok.Mon Jun 6 22:19:42 2016 - [info] Checking SSH publickey authentication settings on the current master..Mon Jun 6 22:19:43 2016 - [info] HealthCheck: SSH to 172.18.71.101 is reachable.Mon Jun 6 22:19:43 2016 - [info] Master MHA Node version is 0.57.Mon Jun 6 22:19:43 2016 - [info] Checking recovery script configurations on 172.18.71.101(172.18.71.101:3306)..Mon Jun 6 22:19:43 2016 - [info] Executing command: save_binary_logs --command=test --start_pos=4 --binlog_dir=/var/lib/mysql,/var/log/mysql --output_file=/data/masterha/app1/save_binary_logs_test --manager_version=0.57 --start_file=master-binlog.000003 Mon Jun 6 22:19:43 2016 - [info] Connecting to root@172.18.71.101(172.18.71.101:22).. Creating /data/masterha/app1 if not exists.. Creating directory /data/masterha/app1.. done. ok. Checking output directory is accessible or not.. ok. Binlog found at /var/lib/mysql, up to master-binlog.000003Mon Jun 6 22:19:43 2016 - [info] Binlog setting check done.Mon Jun 6 22:19:43 2016 - [info] Checking SSH publickey authentication and checking recovery script configurations on all alive slave servers..Mon Jun 6 22:19:43 2016 - [info] Executing command : apply_diff_relay_logs --command=test --slave_user='mha' --slave_host=172.18.71.102 --slave_ip=172.18.71.102 --slave_port=3306 --workdir=/data/masterha/app1 --target_version=5.5.44-MariaDB-log --manager_version=0.57 --relay_log_info=/var/lib/mysql/relay-log.info --relay_dir=/var/lib/mysql/ --slave_pass=xxxMon Jun 6 22:19:43 2016 - [info] Connecting to root@172.18.71.102(172.18.71.102:22).. Creating directory /data/masterha/app1.. done. Checking slave recovery environment settings.. Opening /var/lib/mysql/relay-log.info ... ok. Relay log found at /var/lib/mysql, up to relaylog.000006 Temporary relay log file is /var/lib/mysql/relaylog.000006 Testing mysql connection and privileges.. done. Testing mysqlbinlog output.. done. Cleaning up test file(s).. done.Mon Jun 6 22:19:43 2016 - [info] Executing command : apply_diff_relay_logs --command=test --slave_user='mha' --slave_host=172.18.71.103 --slave_ip=172.18.71.103 --slave_port=3306 --workdir=/data/masterha/app1 --target_version=5.5.44-MariaDB-log --manager_version=0.57 --relay_log_info=/var/lib/mysql/relay-log.info --relay_dir=/var/lib/mysql/ --slave_pass=xxxMon Jun 6 22:19:43 2016 - [info] Connecting to root@172.18.71.103(172.18.71.103:22).. Creating directory /data/masterha/app1.. done. Checking slave recovery environment settings.. Opening /var/lib/mysql/relay-log.info ... ok. Relay log found at /var/lib/mysql, up to relaylog.000004 Temporary relay log file is /var/lib/mysql/relaylog.000004 Testing mysql connection and privileges.. done. Testing mysqlbinlog output.. done. Cleaning up test file(s).. done.Mon Jun 6 22:19:43 2016 - [info] Slaves settings check done.Mon Jun 6 22:19:43 2016 - [info] 172.18.71.101(172.18.71.101:3306) (current master) +--172.18.71.102(172.18.71.102:3306) +--172.18.71.103(172.18.71.103:3306)Mon Jun 6 22:19:43 2016 - [info] Checking replication health on 172.18.71.102..Mon Jun 6 22:19:43 2016 - [info] ok.Mon Jun 6 22:19:43 2016 - [info] Checking replication health on 172.18.71.103..Mon Jun 6 22:19:43 2016 - [info] ok.# 这里已经提示了没有定义主节点故障VIP如何漂移的脚本.Mon Jun 6 22:19:43 2016 - [warning] master_ip_failover_script is not defined.# 也没有定义STONITH脚本, 以防止集群脑裂.Mon Jun 6 22:19:43 2016 - [warning] shutdown_script is not defined.Mon Jun 6 22:19:43 2016 - [info] Got exit code 0 (Not master dead).MySQL Replication Health is OK.# 测试通过就可以启动MHA了[root@1478a474 ~]# nohup masterha_manager --conf=/etc/masterha/app1.cnf &amp;&gt; /data/masterha/app1/manager.log &amp;# 查看状态[root@1478a474 ~]# masterha_check_status --conf=/etc/masterha/app1.cnfapp1 (pid:30255) is running(0:PING_OK), master:172.18.71.101# 如需停止MHA, 执行以下命令.[root@1478a474 ~]# masterha_stop --conf=/etc/masterha/app1.cnfStopped app1 successfully.[1]+ Exit 1 nohup masterha_manager --conf=/etc/masterha/app1.cnf &amp;&gt;/data/masterha/app1/manager.log 测试验证关闭HostA(Master)的mariadb服务, 期望MHA能够检测到HostA故障, 将HostB提升为Master. 123456789101112131415161718192021222324252627282930313233343536373839404142434445# 杀死HostA上的mysqld和mysqld_safe进程[root@80e54d87 ~]# killall -9 mysqld mysqld_safe# 查看MHA的日志, 可以看到故障转移报告.[root@1478a474 ~]# less /data/masterha/app1/manager.log...----- Failover Report -----app1: MySQL Master failover 172.18.71.101(172.18.71.101:3306) to 172.18.71.102(172.18.71.102:3306) succeededMaster 172.18.71.101(172.18.71.101:3306) is down!Check MHA Manager logs at 1478a474.twoyang.com:/data/masterha/app1/manager.log for details.Started automated(non-interactive) failover.The latest slave 172.18.71.102(172.18.71.102:3306) has all relay logs for recovery.Selected 172.18.71.102(172.18.71.102:3306) as a new master.172.18.71.102(172.18.71.102:3306): OK: Applying all logs succeeded.172.18.71.103(172.18.71.103:3306): This host has the latest relay log events.Generating relay diff files from the latest slave succeeded.172.18.71.103(172.18.71.103:3306): OK: Applying all logs succeeded. Slave started, replicating from 172.18.71.102(172.18.71.102:3306)172.18.71.102(172.18.71.102:3306): Resetting slave info succeeded.Master failover to 172.18.71.102(172.18.71.102:3306) completed successfully.# 再看另一个从节点HostC上, MHA已经将其主节点由HostA修改为了HostB了.MariaDB [(none)]&gt; SHOW SLAVE STATUS\G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.18.71.102 Master_User: repl Master_Port: 3306 Connect_Retry: 60 Master_Log_File: master-binlog.000001 Read_Master_Log_Pos: 245 Relay_Log_File: relaylog.000002 Relay_Log_Pos: 533 Relay_Master_Log_File: master-binlog.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes......1 row in set (0.00 sec)# 注意: 故障转移完成后, MHA将会自动停止进程.[root@1478a474 ~]# masterha_check_status --conf=/etc/masterha/app1.cnfapp1 is stopped(2:NOT_RUNNING). 最后还有几个问题需要说明一下: 因为主从异步复制时难免会出现从节点落后主节点的情况, 这样主机点宕机就会出现丢失数据的情况. 所以如果是做半同步复制情况就会好很多. 这里没有考虑VIP和STONITH的问题, 其实前面用MHA做复制检查时已经警告过我们了. VIP地址漂移的问题可以通过脚本来实现, 也可以通过keepalived来实现. 而STONITH也可以通过脚本来实现, 不过既然是脑裂基本上就是联系不上对方, 那通过脚本来STONITH也就不太靠谱; 想靠谱基本上只有上硬件, 那可就贵了.原文地址：点我]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL主从复制架构示例演示]]></title>
      <url>%2Fposts%2F87bc87f4%2F</url>
      <content type="text"><![CDATA[示例演示模型： 主从、主主、半同步复制、复制过滤器、基于SSL加密复制 主从配置过程123456789101112131415161718192021222324252627282930313233343536373839每个mysql配置都应该启用的配置：skip_name_resolve=ONinnodb_file_per_table=ON注意：mysql5.1版本skip_name_resolve不支持加参数写法主节点：编辑my.cnf配置文件(1)启动二进制日志log-bin=log_name(2)为当前节点设置一个全局的ID号server-id=# (配置文件配置)连接mysql数据库(3)创建有复制权限的帐号GRANT REPLICATION SLAVE,REPLICATION CLIENT ON *.* TO ‘USER’@’HOST’ IDENTIFIED BY ‘PASSWORD’注意：授权账号也是写操作，所以从服务器在主服务器授权账号之后再定义MASTER从节点：（1）启动中继日志relay-log=log_namerelay-log-index=relay-log.index(中继日志索引文件)（2）为当前节点配置一个全局唯一的ID号sever-id=#（3）使用有复制权限的帐号连接至主服务器，并启动复制线程授权：mysql&gt; CHANGE MASTER TO MASTER_HOST=’IP’,MASTER_USER=’USERNAME’, MASTER_PASSWORD=’PASS’,MASTER_LOG_FILE=’bin-log_file’ MASTER_LOG_POS=#;注意：最后一项是数值，无需添加引号，初始化的事件应该忽略启动复制线程：mysql&gt; START SLAVE;查看从服务器信息：SHOW SLAVE STATUS\G获取帮助：help CHANGE MASTER TO; 注意：主从配置的相关参数，在[mysql_safe]配置段是无效的 主主配置过程： 注意： 主主模式数据可能会不一致，慎用，由于两各节点都可以执行写操作，一旦发生同时写入数据的操作，对于可以自动增长的id字段，必然造成id冲突，导致数据库崩溃 为避免这样自动增长字段id冲突，有以下解决方法自动增长字段id需要手动配置（在my.cnf文件配置）12345678一个节点使用奇数idauto_increment_offset=1设置偏移量，即跳到哪各id作为起始idauto_increment_increment=2设置自动增长的数值另一节点使用偶数idauto_incremental_offset=2auto_incremental_increment=2 配置要点12345678910111213141516(1)各节点配置唯一的server idserver-id=your_server_id(2)都需要启用二进制日志文件和中继日志bin-log=log_namerelay-log=log_namerelay-log-index=log_name.index(3)配置自动增长字段id的奇偶：auto_incremnt_offset=auto_incremnt_increment= (4)创建拥有复制权限的用户帐号 GRANT RELPICATION SLAVE,REPLICATION CLIENT ON *.* TO ‘USER’@’HOST’ IDENTIFIED BY ‘PASSWORD’;(5)把对方指定为主节点，并启动复制线程CHANGEMASTERTOMASTER_HOST=’HOST’,MASTER_USER=’USER’,MASTER_PASSWORD=’PASSWD’,MASTER_LOG_FILE=’bin-log’,MASTER_LOG_POS=#; 半同步复制配置 其他配置同主从配置，重点如下 1234567891011master：mysql&gt; INSTALL PLUGIN rpl_semi_sync_master SONAME ‘semisync_master.so’;mysql&gt; SET GLOBAL rpl_semi_sync_master_enabled=1; slave:mysql&gt; INSTALL PLUGIN rpl_semi_sync_slave SONAME ‘semisync_slave.so’; mysql&gt; SET GLOBAL rpl_semi_sync_slave_enabled=1;查看相关变量参数：SHOW GLOBAL VARIABLES LIKE ‘%semi%’;SHOW GLOBAL STATUS LIKE ‘%semi%’; 复制过滤器 让从节点仅复制指定的数据库，或者指定数据库的指定表 有两种实现方式： (1)主节点仅向二进制日志中记录特定数据库或特定表的相关事件1234复制数据库白名单：binlog_do_db=”DB1,DB2,..”复制数据库黑名单：binlog_ignore_db=”DB1,DB2,..” 注意：不用同时使用以上两个参数 (2)从服务器SQL线程在replay中继日志的事件时，仅读取特定数据库或特定表12345678910replicate_do_db= 重放数据库白名单replicate_ignore_db= 重放数据库黑名单还可以过滤到表级别：（实际应用很少）replicate_do_table=replicate_ignore_table=使用通配过滤的表：replicate_wild_do_tabl=replicate_wild_ingore_tabl= 基于SSL证书进行复制 注意：各节点的时间必须同步好，否则证书将无法使用（多个节点可使用同以证书） 1234567891011121314151617181920212223(1)开启ssl功能：主从配置文件都需要连接以下内容sslssl_ca=/var/lib/mysql/ssl/cacert.pemssl_cert=/var/lib/mysql/ssl/cacert.crtssl_key=/var/lib/mysql/ssl/cakey.pem注意：以上配置项是开启ssl连接所必须的(2)主服务器授权：GRANT REPLICATION SLAVE，REPLICATION CLIENT ON *.* TO ‘USER’@’HOST’ IDENTIFIED BY‘PASSWORD’ REQUIRE SSL;(3)从服务器设置masterMariaDB [(none)]&gt; CHANGE MASTER TO MASTER_HOST=’172.18.17.179′,MASTER_USER=’backuser’,MASTER_PASSWORD=’backpasswd’,MASTER_LOG_FILE=’bin_log.000009′,MASTER_LOG_POS=436,MASTER_SSL_CA=’/var/lib/mysql/ssl/cacert.pem’,MASTER_SSL_CERT=’/var/lib/mysql/ssl/slave.crt’,MASTER_SSL_KEY=’/var/lib/mysql/ssl/slave.key’,MASTER_SSL=1;补充：测试是否可以基于ssl远程连接数据库# mysql -ubackuser -h172.18.17.179 -pbackpasswd –ssl-ca=/var/lib/mysql/ssl/cacert.pem –ssl-cert=/var/lib/mysql/ssl/slave.crt –ssl-key=/var/lib/mysql/ssl/slave.key参考： | MASTER_SSL = &#123;0|1&#125; | MASTER_SSL_CA = ‘ca_file_name’ | MASTER_SSL_CERT = ‘cert_file_name’ | MASTER_SSL_KEY = ‘key_file_name’ MySQL复制的监控和维护日志清理：12PURGE BINARY LOGS TO ‘mysql-bin.010’ 表示清理010之前的所有日志（不包含010）PURGE BINARY LOGS BEFORE ‘2016-05-15 22:26:27’ 表示清理此时间点之前的所有日志 注意：谨慎清理，除非你知道你在做什么 复制监控：123456SHOW MASTER STATUS;SHOW BINLOG ENVENT;SHOW SHOW BINARY LOGS;SHOW SLAVE STATUS;SHOW PROCESSLIST; 12345678查看从服务器是否落后于主服务器：Seconds_Behind_Master: 0如何确定主从节点数据是否一致：percona-tools提供的工具数据不一致如何修复：备份主服务器的数据，重新恢复到从服务器]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL备份]]></title>
      <url>%2Fposts%2F8255276b%2F</url>
      <content type="text"><![CDATA[备份的本质就是将数据集另存一个副本，但是原数据会不停的发生变化，所以利用备份只能回复到数据变化之前的数据。那变化之后的呢？所以制定一个好的备份策略很重要 一、备份的目的 做灾难恢复：对损坏的数据进行恢复和还原 需求改变：因需求改变而需要把数据还原到改变以前 测试：测试新功能是否可用 二、备份需要考虑的问题 可以容忍丢失多长时间的数据； 恢复数据要在多长时间内完； 恢复的时候是否需要持续提供服务； 恢复的对象，是整个库，多个表，还是单个库，单个表。 三、备份的类型1、根据是否需要数据库离线 冷备（cold backup）：需要关mysql服务，读写请求均不允许状态下进行；线上服务读写操作均不可执行 温备（warm backup）： 服务在线，但仅支持读请求，不允许写请求； 热备（hot backup）：备份的同时，业务不受影响。线上服务读写均可执行 实际上，热备份最复杂，备份难度最大，因为热备份要考虑备份的同时新数据产生的变化导致备份数据前后时间戳不一致，这样会导致备份失效，温备份就避免备份时数据会发生改变，因为对数据库的所有执行了读锁，不能写入数据，数据也就不会发生变化，但对业务的影响也是很明显的，而冷备，在备份时整个业务都需终止，基本是不可取的 注： 这种类型的备份，取决于业务的需求，而不是备份工具 MyISAM不支持热备，InnoDB支持热备，但是需要专门的工具 2、根据要备份的数据集合的范围 完全备份：full backup，备份整个数据集 部分备份：只备份数据子集（如数据库的某张表） 增量备份: incremental backup 上次完全备份或增量备份以来改变了的数据，不能单独使用，要借助完全备份，备份的频率取决于数据的更新频率。1234备份模型如下：——–&gt;|———&gt;|———-&gt;完整备份 差异备份1 差异备份2还原：先还原完全备份数据，再恢复每一个增量备份的数据 增量备份的优点是占用磁盘空间少，但恢复数据比较麻烦 差异备份：differential backup 上次完全备份以来改变了的数据。 123456备份模型如下：——–&gt; 完全备份 |——–&gt; 第一次差异备份 |—————–&gt; 第二次差异备份还原：先还原完全备份数据，再还原差异备份的数据 差异备份占用磁盘空间多，但恢复数据较为方便建议的恢复策略： 完全+增量+二进制日志 完全+差异+二进制日志 3、根据备份数据或文件物理备份：直接备份数据文件 物理备份时文件系统上的数据文件归档复制，简单易用，无需第额外三方工具，备份的数据量较大时，建议使用物理，备份而逻辑备份一般需要借助额外的备份工具进行，通过mysql协议连接服务器将数据抽取出来 123456优点： 备份和恢复操作都比较简单，能够跨mysql的版本， 恢复速度快，属于文件系统级别的建议： 不要假设备份一定可用，要测试 mysql&gt;check tables；检测表是否可用 逻辑备份: 备份表中的数据和代码 逻辑备份与存储引擎无关通过从数据库导出数据进行备份（需要相关备份工具） 12345678910优点： 恢复简单、 备份的结果为ASCII文件，可以编辑 与存储引擎无关 可以通过网络备份和恢复缺点： 备份或恢复都需要mysql服务器进程参与 备份结果占据更多的空间， 浮点数可能会丢失精度 还原之后，索引需要重建 备份时需要考虑的因素：1234567891011持锁多久– 能够接收业务中断的时间备份过程的时长– 预计备份所要消耗的时间，是否能在对业务影响最小的时间段内完成备份操作备份负载– 备份会加大磁盘IO压力，可能会导致业务中断，所以备份尽量避免在服务的高负载的时间段恢复过程的时长– 当数据损坏时，能够接收多大的恢复时长（分分钟几百万上下），若要尽量缩短数据恢复时间应该在平时就需要演练数据恢复的过程，一是确保备份的数据可用，二是熟悉恢复流程，可能需多个部门的协调，因为在巨大的压力下（若数据丢失时），人很可能是大脑一片空白，很可能会误操作，要是再把备份的数据删掉，那就真的需要跑路了 四、备份的对象 1、 数据；2、配置文件；3、代码：存储过程、存储函数、触发器、事件调度器4、os相关的配置文件5、复制相关的配置6、二进制日志、innodb事物日志文件 五、备份的方案和工具备份方案： 数据集：完全+增量（常用备份方式）备份手段：物理，逻辑 注意：热备份和冷备份于备份方式（物理，逻辑）是两个话题 备份工具：逻辑备份工具：mysqldump 适用所有存储引擎 温备份、完全备份、部分备份，对innodb支持热备份 物理备份：cp,tar等复制归档工具 适用所有存储引擎 冷备份，完全备份，部分备份 lvm2的快照：几乎热备，需借助cp等文件管理工具进行备份mysqlhotcopy: 几乎冷备，仅适用于MyISAM引擎xtrabackup: 备份工具的选择： mysqldump+复制binlog：mysqldump：完全备份；复制binlog中指定时间范围的event：增量备份； lvm2快照+复制binlog：lvm2快照：使用cp或tar等做物理备份；完全备份；复制binlog中指定时间范围的event：增量备份； xtrabackup：由Percona提供的支持对InnoDB做热备(物理备份)的工具；完全备份、增量备份； 逻辑备份工具：mysqldump, mysqldumper(实现并行逻辑备份), phpmyadmin 逻辑备份是将schema和数据存储在一起；是巨大的SQL语句，其将拉取出来的数据定义成INSERT语句，也就是每表要插入的数据；其同时又是一个巨大的备份文件，因为备份的数据都是存储在单个文件中 schema：表结构（表的相关属性定义） mysqldump使用方法1234567891011121314151617181920212223242526272829mysqldump [options] [db_name [tbl_name …]]option:-A，–all-databases: 备份所有数据库-B，–databases db_name: 备份指定的数据库-E: 备份指定数据相关的所有event scheduler-R: 备份指定数据相关的所有存储过程和存储函数–triggers：备份表相关的触发器–master-data=# （#为数字，如下）1：记录为CHANGE MASTER TO 语句，此语句不被注释（功用为扮演为从服务器）2：基于为注释的CHANGE MASTER TO语句 （建议使用此种方式）–master-data=2的作用：备份时，在导出的数据文件中添加一条注释信息，此注释信息为执行“备份一刻”所使用的二进制日志文件及其记录的当前事务起始位置（作用是用于时间点还原，还原日志文件记录的事务起始位置之后所发生事件）提醒：时间点还原使用二进制日志文件可能不止一个–flush-logs: 锁定表后滚动二进制日志– 主要用于表锁定后滚动二进制日志，然后备份二进制日志文件–lock-all-tables: 锁定所有库的所有表（温备）– 用于使用完全备份时施加全局读锁–lock-tables: 对于每个单独的数据库，在启动备份前锁定其所有表（温备）– 用备份单独指定的某个或某些个数据库时执行读锁–single-transaction：在备份时启动一个事务（热备） – 适用于事务型存储引擎的热备份选项（InnoDB适用） 主要有三种备份模式：备份指定数据库或数据库的表（可以是多张表）1shell&gt; mysqldump [options] db_name [tbl_name ...] 注意：不会自动生成CREATE DATABASE的语句（即导入时需要手动创建数据库） 备份指定的数据库（可以指定多个数据库）1shell&gt; mysqldump [options] --databases db_name ... 备份所有数据库，全库备份1shell&gt; mysqldump [options] --all-databases 备份示例：备份指定数据库：1mysqldump -uroot -hlocalhost -p --databases ops &gt; /root/backup.sql # 备份指定数据库 备份指定数据库的某张表1mysqldump -uroot -hloaclhost -p ops students &gt; /root/backup.sql # 备份指定数据库的某张表 备份所有数据库1mysqldump -uroot -hlocalhost -p --all-databases &gt; /root/backup.sql # 备份所有数据库 注意：二进制日志文件至关重要，建议存储在与存储数据不同的磁盘上，并且要做磁盘冗余，如果 条件允许，事物日志也应该放在非数据且有冗余的磁盘上 备份思路：每周执行一次完整备份，每天执行一次增量备份（备份二进制日志），完整备份和增量备份的频率需依照数据的数据变化速度调整 备份恢复示例： 完整备份+增量备份（二进制日志） (1)完全备份：(温备)1mysqldump --all-databases --lock-all-tables --master-data=2 &gt; /backups/alldb.sql (2)数据还原1、导入备份数据：1mysql &lt; /root/alldb.sql 2、时间点还原查询备份数据获取事件位置，信息如下：1234CHANGE MASTER TO MASTER_LOG_FILE='bin_log.000005', MASTER_LOG_POS=245;使用mysqlbinlog抽取指定位置之后的事件：shell&gt; mysqlbinlog --start-position=254 bin_log.000005&gt; /backups/binlog.sql 注意：指定的位置往后所发生的事件记录于二进制文件可能不止一个，多以肯能需要导入多个二进制日志文件进行时间点恢复 使用mysqlbinlog抽取指定位置之后的事件：1shell&gt; mysqlbinlog --start-position=254 bin_log.000005&gt; /backups/binlog.sql 注意：指定的位置往后所发生的事件记录于二进制文件可能不止一个，多以肯能需要导入多个二进制日志文件进行时间点恢复 3、导入到数据库中1shell&gt; mysql &lt; binlog.sql 二进制日志备份还原要点： 前最好先执行FLUSH LOGS滚动日志 使用二进制日志文件还原时，要先禁用二进制日志记录，再执行还原操作，还原后再启用 可以基于脚本实现自动备份注意尝试使用mysqldump实现热备份 基于lvm2的备份 前提，创建好逻辑卷格式化后挂载使用 (1)请求锁定所有表12mysql&gt; FLUSH TABLES WITH READ LOCK;– 注意：如果有写操作事务在进行，可能需要等待很长时间 (2)记录二进制日志文件及事件位置滚动日志：（不滚问题也不大）12mysql&gt; FLUSH LOGS;shell&gt; mysql -e "FLUSH LOGS" 导出二进制日志列表1shell&gt; mysql -e "SHOW LOGS STATUS" &gt; PATH (3)创建快照卷1lvcreate -L SIZE -s -p r -n NAME /YOUR_LV_PATH (4)释放全局锁1mysql&gt; UBLOCK TABLES; (5)挂载快照卷，执行数据备份mount &amp;&amp; cp (6)完成备份，删除快照卷rm命令 (7)制定好策略，通过源卷备份二进制日志cp binlog 注意：二进制文件备份要在原卷实行，不需要快照，在执行flush logs之后就应该执行备份操作 注意：物理物质的文件，回复时要确保属主属组时mysql （cp使用-a选项） xtrabackup备份 perconna出品,www.perconna.cominnobackupex为xtrabackup的前端工具,可理解为简装版的xtrabackup提醒：在实际的应用场景中，可能会需要创建授权专门的备份用户 InnoDB表空间管理简单概念 innoDB以表空间管理数据库，其管理方式是将表空间分页管理的，可以理解为block，每个block叫做一个innodb页（通常为16k大小），每个innodb页有一个日志序列号，称为LSN，数据页面发生变化时，日志序列号将滚动提升 xtrabackup的备份工作原理或要点 xtrabackup的备份基于innoDB页进行，通过识别LSN的变化判断页面数据是否发生改变； 完全备份，就是备份表空间的所有数据块，即innoDB页； 增量备份，仅备份序列号发生改变的数据块； 备份的是数据和事务日志文件 备份恢复要点 如果只做完全备份的恢复，没有增量备份，恢复数据时，完全备份整合应该将事务日志中尚未提交的事务同步到数据中，未提交的事务进行回滚 如果是完全备份+增量备份恢复，恢复数据时，完全备份整合应该将事务日志中未提交的事务同步至数据中（redo only），切记不可回滚未提交的事务，最后再整合增量备份 要做时间点还原，二进制日志必备份恢复不可少 完全备份和恢复 前提：1.确保表示类型是InnoDB，只有innodb支持热备和增量备份2.确保inndb_file_per_table = ON (很重要) 完全备份1innobackupex --user=DBUSER --password=DBPASSWD /SAVE/TO/SOMEWHERE 完全备份恢复 注意：要在需要恢复数据的服务端执行以下操作 整理备份1innobackpex –apply-log /BACKUP_PATH 确保有complete OK信息输出，表示整理备份可用 恢复 注意：不需要启动mysql 1innobackupex –copy-back /PATH/TO/BACKUP_DIR 通过备份目录下的xtrabackup_checkpoints可查看备份的信息（如备份类型） 增量备份和恢复12innobackupex –incremental /SAVE_TO_SOMEWHERE –incremental-basedir=BASEDIR–incremental-basedir= 基于谁做增量 增量和差异区别只在于: 是始终基于完全备份来备份数据，还是以最近的完全备份或增量备份来 整合完全备份1innobackupex –apply-log –redo-only BACKUP_PATH（完全备份） 注意：恢复的操作只需要提交，而不要回滚 整合每一个增量备份：12345innobackupex –apply-log –redo-only BACKUP_PATH –incremental-dir=INCREMENTAL_DIR1 （增量备份1）innobackupex –apply-log –redo-only BACKUP_PATH –incremental-dir=INCREMENTAL_DIR2（增量备份2） 注意：增量备份整合一定要使用绝对路径 恢复1innobackupex –copy-back /PATH/TO/BACKUP_DIR（完全备份） 导入或导出单张表1.导出表12innobackuppex –apply-log –export /path/to/backup# 会在表空间生成一个以.exp结尾的文件，可用于导入到其他服务器 2.导入表（最好是在不同服务上进行）先要创建表1mysql&gt; CREATE TABLE testtable (...) ENGINE=InnoDB; 再清空表空间1mysql&gt; ALTER TABLE DATABASE.TABLE DISCARD TABLESPACE; 导入表 将导出的表的.ibd文件盒.exp文件复制到当前服务器的数据库目录确保属主和属组是mysql，然后执行导入命令 1mysql&gt; ALTER TABLE mydatabase.mytable IMPORT TABLESTACE;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL主从复制及架构介绍]]></title>
      <url>%2Fposts%2Fa996e9ae%2F</url>
      <content type="text"><![CDATA[一、MySQL主从基础概念 MySQL通常是服务系统中最容产生性能瓶颈的组件，对于繁忙的web服务来讲，数据库压力通常是最大的，需要承载大量的读写操作，因而，数据库服务器的性能至关重要，通常数据库服务器的硬件也是服务系统中要求最高的，抛开性能不讲，数据本身就是信息服务的命脉！数据管理，马虎不得。解决数据库服务器的性能瓶颈，除了纵向扩展（使用更好的硬件）之外，通常是对其做横向扩展，即增加多个服务器，构建DB集群，通常使用主从模式，数据的同步就是本文要学习的内容 复制概述 Mysql内建的复制功能是构建大型，高性能应用程序的基础。将Mysql的数据分布到多个系统上去，这种分布的机制，是通过将Mysql的某一台主机的数据复制到其它主机（slaves）上，并重新执行一遍来实现的。复制过程中一个服务器充当主服务器，而一个或多个其它服务器充当从服务器。主服务器将更新写入二进制日志文件，并维护文件的一个索引以跟踪日志循环。这些日志可以记录发送到从服务器的更新。当一个从服务器连接主服务器时，它通知主服务器从服务器在日志中读取的最后一次成功更新的位置。从服务器接收从那时起发生的任何更新，然后封锁并等待主服务器通知新的更新。请注意当你进行复制时，所有对复制中的表的更新必须在主服务器上进行。否则，你必须要小心，以避免用户对主服务器上的表进行的更新与对从服务器上的表所进行的更新之间的冲突。 注：主从复制各节点时间要同步！ 1.1 mysql支持的复制类型： 基于语句的复制： 在主服务器上执行的SQL语句，在从服务器上执行同样的语句。MySQL默认采用基于语句的复制，效率比较高。 一旦发现没法精确复制时， 会自动选着基于行的复制。 基于行的复制：把改变的内容复制过去，而不是把命令在从服务器上执行一遍. 从mysql5.0开始支持 混合类型的复制: 默认采用基于语句的复制，一旦发现基于语句的无法精确的复制时，就会采用基于行的复制。 1.2 复制解决的问题 MySQL复制技术有以下一些特点： (1)数据分布 (Data distribution ):每个节点有相同的的数据集 (2)负载平衡(load balancing):可由前端读写分离器（调度器）将读请求负载均衡至从节点 (3)备份(Backups):利用从节点实现数据备份 (4)高可用性和容错行(High availability and failover):任意单个节点宕机，都可以有其他节点提供服务 1.3 复制如何工作 整体上来说，复制有3个步骤： 123(1)master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events）；(2)slave将master的binary log events拷贝到它的中继日志(relay log)；(3)slave重做中继日志中的事件，将改变反映它自己的数据(数据重放)。 复制过程主从复制需要启动专门的的线程来执行：Master：主节点Dump Thread：为每个Slave的I/O Thread启动一个dump线程，用于向其发送binary logevent（二进制日志事件） Slave：从节点I/O Thread：到Master请求二进制日志事件，并保存于中继日志中SQL Thread：从中继日志读取事件，在本地replay（重放），得到与Master一样的数据 主从复制的特点：异步复制，导致延迟，从节点数据落后于主节点 主从复制面临的问题 主从数据不同步 对于新的“写操作“，若将对新写入数据的“读请求”调度至从服务器，很可能会无法读取到数据；所以，调度器可能需要具备的功能：不将对新写入内容的读请求调度至从服务器，而是直接将读请求调度至主服务器 缓存命中率问题 调度器后端有多个从服务器，若对同一内容的读请求，先后调度至不同的从服务器，则缓存无法命中，读性能也就无从提升；所以，主从集群之上应部署第三方的缓存服务器，如memcached或redis，将所有查询结果缓存于memcached或redis中，用户的每次读请求，都将先查询缓存，未命中则再到从服务器中查询 从服务器宕机 若后端有多个从节点，读写分离器（调度器）则需要有健康状态检测功能，及时移除宕掉的服务器，又能够让恢复健康的节点重新上线 主服务器宕机 若主节点只有一个（假设），则无法再执行写操作，此时需要挑选出从节点中数据较新的节点，提升为主节点，若提升的主节点数据未完全与原来的主服务器同步，需要借助GTID（全局事务ID）来完成数据的同步，即对未提交事务进行提交以将数据同步于磁盘中 主从复制模型 M/S：主从模型，一主可以多从 M/M：双主（也叫主主）模型，两个节点互为主从 环状结构：多个节点互为主从（用之者甚少） 级联复制，从服务器还可以再有从服务器 一主多从模型:Master - Slave - Slave 使用场景： 在实际应用场景中，MySQL复制90%以上都是一个Master复制到一个或者多个Slave的架构模式，主要用于读压力比较大的应用的数据库端廉价扩展解决方案。因为只要Master和Slave的压力不是太大（尤其是Slave端压力）的话，异步复制的延时一般都很少很少。尤其是自从Slave端的复制方式改成两个线程处理之后，更是减小了Slave端的延时问题。而带来的效益是，对于数据实时性要求不是特别Critical的应用，只需要通过廉价的pcserver来扩展Slave的数量，将读压力分散到多台Slave的机器上面，即可通过分散单台数据库服务器的读压力来解决数据库端的读性能瓶颈，毕竟在大多数数据库应用系统中的读压力还是要比写压力大很多。这在很大程度上解决了目前很多中小型网站的数据库压力瓶颈问题，甚至有些大型网站也在使用类似方案解决数据库瓶颈。 双主模型：Master - Master 两个节点互为主从，每个节点的写操作都需要记录与二进制日志中，并发送给对方，以达到数据同步的目的，其中需要server id发挥作用server id：sever_id是记录于二进制日志中的server标识，标明日志事件中的写操作是在哪个server执行的，日志在从节点中重放会保留server id，所以，在双主模型中，若server接收到的日志包含server id为自己时，将不会对日志的事件进行重放 场景： 假设1和2两个节点互为主从，其server_id就是对应的数字，server1写完后，将二进制日志发送给server2一份，server2在本地完成重放之后，其也要将二进制日志发送给server1，server1接收到二进制日志后发现日志包含的server_id是自己，则不会在本地重放，直接忽略 提醒：双主模型可能会存在两个节点的数据不一致的问题，其场景是两个节点分别接收了“互斥”的写请求，造成了两个节点的数据不一致 虽然可以使用配置auto_increment_increment=2和auto_increment_offset=1可以解决自动插入的问题，允许同时插入数据的话，数据还是会不一致的。 例如：下面的两个命令同时执行：1234第一个主服务器：mysql&gt;update tbl set col=col+1;第二个主服务器：mysql&gt;update tbl set col=col*2; 结果是什么？一个服务器的值为4，而另外一个为3.并且根本没有replication的错误。所以，个人建议主动-被动的双主模式，只让一台服务器写就行了，让它对外服务，另外一台作为备用。只接受数据。 双主模型的前端调度无需做读写分离，随意调度，双主模型相当于高可用实现，一般用作高容灾方案 一从多主复制模型 Slaves - Master – Master一从多主的复制模型，其限制条件是，从节点仅能从多个主节点中复制不同的数据库内容，即多个主节点中必须不能有相同的数据库（仅在mysql5.6及mariadb10之后的版本可以实现） 适合业务场景：公司几个主要的业务已经独立，放在不同的数据库服务器上面，但是有一个业务又需要关联多个业务库进行联合查询统计。这时候就需要将不同的业务库数据同步到一台从库进行统计。根据Mysql主从同步原理使用多从一从的方案解决。主库使用innodb引擎，从库开启多实例使用myisam引擎并将多个实例的数据同步到同一个目录详细实现步骤 级联复制模型 Master –Slaves - Slaves###使用场景 在有些应用场景中，可能读写压力差别比较大，读压力特别的大，一个Master可能需要上10台甚至更多的Slave才能够支撑读的压力。这时候，Master就会比较吃力了，因为仅仅连上来的SlaveIO线程就比较多了，这样写的压力稍微大一点的时候，Master端因为复制就会消耗较多的资源，很容易造成复制的延时。 在主从模型下，从节点还可以再有从节点，即从节点中的某个节点（假设为“Slave_A”）是其他从节点的主节点，为避免过大的压力，Slave_A一般不处理客户端的读请求，仅负责从主节点中复制二进制日志在本地完成重放，但其使用的表类型是black_hold，所以本地并没有保存数据，仅是将重放的写操作记录于二进制日志中，进而，其他从节点可以到Slave_A复制日志文件来同步数据参考 半同步复制模型： 主服务器需要等待一个从节点完成数据复制，才能对客户端返回OK，此模型下，主节点和完全同步的从节点一般需要在同一机房内，需要有足够稳定，足够大的带宽支持，其他节点可以跨网络分布 复制过滤器： 仅复制部分数据库内容，其实现方案有两种：(1)主节点只保存特定数据库的事件到二进制日志文件中，从节点复制重放(2)从节点复制所有数据库相关的事件，但在中继日志中过滤事件，选择特定的事件进行重放 复制结构中应该注意的问题123456789101112131415161718192021222324252627282930313233341、限制从服务器为只读在从服务器设置read_only=ON,对拥有SUPER权限的用户无效阻止所有用户：mysql&gt; FLUSH TABLES WITH READ LOCK;执行后不释放锁，断开与数据库的连接限制从服务器只读的作用是避免有数据写入导致主从数据不同步2、保证主从复制的事务安全在master节点启用的参数：sync_binlog=ON当事务提交时，将binlog内存缓冲区中记录的事件刷新到磁盘中InnoDB引擎需启用的参数：innodb_flush_logs_at_trx_commit=ON 刷写日志，提交事务时，立即将内存中的事务相关的数据保存到事务日志文件中innodb_suport_xa=ON分布式事务，分布式提交事务在slave节点启用的参数：skip_slave_start=ON (需要在配置文件中定义)取消复制进程随数据库启动而启动，此项很可能会导致主从数据不一致3、其他需要注意的参数：按需启用主节点：sync_master_info 是否立即将主服务器信息同步给从服务器slave节点：sync_relay_log是否立即将中继日志从内存刷写到磁盘中sync_relay_log_info是否立即将此文件中保存的信息立即从内存刷写到磁盘中 注意：以上一个同步选项开启必然会增大IO压力，具体情况，具体应用]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[web网站的几个并发连接]]></title>
      <url>%2Fposts%2F8e49ebb7%2F</url>
      <content type="text"><![CDATA[评价一个网站的“大小”，处于视角的不同，有很多种衡量的方法，类似文章数，页面数之类的数据非常明显，也没有什么可以争议的。但对于并发来说，争议非常之多，这里就从一个技术的角度开始，谈谈几个Web网站的数量级。 相信很多人谈论一个网站的热度，总免不了会询问日均PV，同时在线人数、注册用户数等运营数据，说实话从技术角度来说，这几个数值没有一个可以放在一起比较的——一个静态网站的PV跟一个SNS类/Web Game网站的PV根本就不是一回事。由于互联网有一个传说中的“3秒定律”，可能当下更多的网站技术指标要求1.5秒以内加载整页，或者至少可以达到阅读的标准。如果要较真什么“同时在线”，毫不客气的说，对于HTTP这类短链接的网络协议来说，在WebSocket还不普及的时代，能统计在线纯属扯淡，唯一能做的只是取个时间段，计算下访问用户而已。这些依然可以换算成QPS（Quest Per Second每秒请求数）。就并发而言，我唯一推崇的只有理论最大QPS和悲观QPS。 这里就大致根据理论最大QPS，给网站做几个分类50QPS以下——小网站 没什么好说的，简单的小网站而已，就如同本站这样，你可以用最简单的方法快速搭建，短期没有太多的技术瓶颈，只要服务器不要太烂就好。 50～100QPS——DB极限型 大部分的关系型数据库的每次请求大多都能控制在0.01秒左右，即便你的网站每页面只有一次DB请求，那么页面请求无法保证在1秒钟内完成100个请求，这个阶段要考虑做Cache或者多DB负载。无论那种方案，网站重构是不可避免的。 300～800QPS——带宽极限型 目前服务器大多用了IDC提供的“百兆带宽”，这意味着网站出口的实际带宽是8M Byte左右。假定每个页面只有10K Byte，在这个并发条件下，百兆带宽已经吃完。首要考虑是CDN加速／异地缓存，多机负载等技术。 500～1000QPS——内网带宽极限＋Memcache极限型 由于Key/value的特性，每个页面对memcache的请求远大于直接对DB的请求，Memcache的悲观并发数在2w左右，看似很高，但事实上大多数情况下，首先是有可能在次之前内网的带宽就已经吃光，接着是在8K QPS左右的情况下，Memcache已经表现出了不稳定，如果代码上没有足够的优化，可能直接将压力转嫁到了DB层上，这就最终导致整个系统在达到某个阀值之上，性能迅速下滑。 1000～2000QPS——FORK/SELECT，锁模式极限型 好吧，一句话：线程模型决定吞吐量。不管你系统中最常见的锁是什么锁，这个级别下，文件系统访问锁都成为了灾难。这就要求系统中不能存在中央节点，所有的数据都必须分布存储，数据需要分布处理。总之，关键词：分布 2000QPS以上——C10K极限 尽管现在很多应用已经实现了C25K，但短板理论告诉我们，决定网站整体并发的永远是最低效的那个环节。我承认我生涯中从未遇到过2000QPS以上，甚至1.5K以上的网站，希望有此经验的哥们可以一起交流下 原文地址]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS Linux服务器安全设置]]></title>
      <url>%2Fposts%2F6d1e2a65%2F</url>
      <content type="text"><![CDATA[我们必须明白：最小的权限+最少的服务=最大的安全所以，无论是配置任何服务器，我们都必须把不用的服务关闭、把系统权限设置到最小话，这样才能保证服务器最大的安全。下面是CentOS服务器安全设置，供大家参考。 一、注释掉系统不需要的用户和用户组 注意：不建议直接删除，当你需要某个用户时，自己重新添加会很麻烦。 12345678910111213141516171819202122 cp /etc/passwd /etc/passwdbak #修改之前先备份 vi /etc/passwd #编辑用户，在前面加上#注释掉此行 #adm:x:3:4:adm:/var/adm:/sbin/nologin#lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin#sync:x:5:0:sync:/sbin:/bin/sync#shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown#halt:x:7:0:halt:/sbin:/sbin/halt#uucp:x:10:14:uucp:/var/spool/uucp:/sbin/nologin#operator:x:11:0:operator:/root:/sbin/nologin#games:x:12:100:games:/usr/games:/sbin/nologin#gopher:x:13:30:gopher:/var/gopher:/sbin/nologin#ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin #注释掉ftp匿名账号cp /etc/group /etc/groupbak #修改之前先备份vi /etc/group #编辑用户组，在前面加上#注释掉此行#adm:x:4:root,adm,daemon#lp:x:7:daemon,lp#uucp:x:14:uucp#games:x:20:#dip:x:40: 二、关闭系统不需要的服务1234567891011service acpid stop chkconfig acpid off #停止服务，取消开机启动 #电源进阶设定，常用在 Laptop 上service autofs stop chkconfig autofs off #停用自动挂载档桉系统与週边装置service bluetooth stop chkconfig bluetooth off #停用Bluetooth蓝芽service cpuspeed stop chkconfig cpuspeed off #停用控制CPU速度主要用来省电service cups stop chkconfig cups off #停用 Common UNIX Printing System 使系统支援印表机service ip6tables stop chkconfig ip6tables off #禁止IPv6如果要恢复某一个服务，可以执行下面操作service acpid start chkconfig acpid on 三、禁止非root用户执行/etc/rc.d/init.d/下的系统命令12chmod -R 700 /etc/rc.d/init.d/*chmod -R 777 /etc/rc.d/init.d/* #恢复默认设置 四、给下面的文件加上不可更改属性，从而防止非授权用户获得权限1234567891011121314chattr +i /etc/passwdchattr +i /etc/shadowchattr +i /etc/groupchattr +i /etc/gshadowchattr +i /etc/services #给系统服务端口列表文件加锁,防止未经许可的删除或添加服务lsattr /etc/passwd /etc/shadow /etc/group /etc/gshadow /etc/services #显示文件的属性 注意：执行以上权限修改之后，就无法添加删除用户了。如果再要添加删除用户，需要先取消上面的设置，等用户添加删除完成之后，再执行上面的操作chattr -i /etc/passwd #取消权限锁定设置 chattr -i /etc/shadow chattr -i /etc/group chattr -i /etc/gshadow chattr -i /etc/services #取消系统服务端口列表文件加锁现在可以进行添加删除用户了，操作完之后再锁定目录文件 五、限制不同文件的权限123456789101112chattr +a .bash_history #避免删除.bash_history或者重定向到/dev/nullchattr +i .bash_historychmod 700 /usr/bin 恢复 chmod 555 /usr/binchmod 700 /bin/ping 恢复 chmod 4755 /bin/pingchmod 700 /usr/bin/vim 恢复 chmod 755 /usr/bin/vimchmod 700 /bin/netstat 恢复 chmod 755 /bin/netstatchmod 700 /usr/bin/tail 恢复 chmod 755 /usr/bin/tailchmod 700 /usr/bin/less 恢复 chmod 755 /usr/bin/lesschmod 700 /usr/bin/head 恢复 chmod 755 /usr/bin/headchmod 700 /bin/cat 恢复 chmod 755 /bin/catchmod 700 /bin/uname 恢复 chmod 755 /bin/unamechmod 500 /bin/ps 恢复 chmod 755 /bin/ps 六、禁止使用Ctrl+Alt+Del快捷键重启服务器123cp /etc/inittab /etc/inittabbakvi /etc/inittab #ca::ctrlaltdel:/sbin/shutdown -t3 -r now #注释掉此行 七、使用yum update更新系统时不升级内核，只更新软件包1234567由于系统与硬件的兼容性问题，有可能升级内核后导致服务器不能正常启动，这是非常可怕的，没有特别的需要，建议不要随意升级内核。cp /etc/yum.conf /etc/yum.confbak1、修改yum的配置文件 vi /etc/yum.conf 在[main]的最后添加 exclude=kernel*2、直接在yum的命令后面加上如下的参数：yum --exclude=kernel* update查看系统版本 cat /etc/issue查看内核版本 uname -a 八、关闭Centos自动更新12345678910chkconfig --list yum-updatesd #显示当前系统状态yum-updatesd 0:关闭 1:关闭 2:启用 3:启用 4:启用 5:启用 6:关闭service yum-updatesd stop #关闭 开启参数为start停止 yum-updatesd： [确定]service yum-updatesd status #查看是否关闭yum-updatesd 已停chkconfig --level 35 yum-updatesd off #禁止开启启动（系统模式为3、5）chkconfig yum-updatesd off #禁止开启启动（所有启动模式全部禁止）chkconfig --list yum-updatesd #显示当前系统状态yum-updatesd 0:关闭 1:关闭 2:启用 3:关闭 4:启用 5:关闭 6:关闭 九、关闭多余的虚拟控制台 我们知道从控制台切换到 X 窗口，一般采用 Alt-F7 ，为什么呢？因为系统默认定义了 6 个虚拟控制台，所以 X 就成了第7个。实际上，很多人一般不会需要这么多虚拟控制台的，修改/etc/inittab ，注释掉那些你不需要的。 123456789cp /etc/inittab /etc/inittabbakvi /etc/inittab# Run gettys in standard runlevels1:2345:respawn:/sbin/mingetty tty1#2:2345:respawn:/sbin/mingetty tty2#3:2345:respawn:/sbin/mingetty tty3#4:2345:respawn:/sbin/mingetty tty4#5:2345:respawn:/sbin/mingetty tty5#6:2345:respawn:/sbin/mingetty tty6 十、删除MySQL历史记录 用户登陆数据库后执行的SQL命令也会被MySQL记录在用户目录的.mysql_history文件里。如果数据库用户用SQL语句修改了数据库密码，也会因.mysql_history文件而泄漏。所以我们在shell登陆及备份的时候不要在-p后直接加密码，而是在提示后再输入数据库密码。另外这两个文件我们也应该不让它记录我们的操作，以防万一。 123456cdcp .bash_history .bash_historybak #备份cp .mysql_history .mysql_historybakrm .bash_history .mysql_historyln -s /dev/null .bash_historyln -s /dev/null .mysql_history 十一、修改history命令记录123cp /etc/profile /etc/profilebakvi /etc/profile找到 HISTSIZE=1000 改为 HISTSIZE=50 十二、隐藏服务器系统信息 在缺省情况下，当你登陆到linux系统，它会告诉你该linux发行版的名称、版本、内核版本、服务器的名称。为了不让这些默认的信息泄露出来，我们要进行下面的操作，让它只显示一个”login:”提示符。删除/etc/issue和/etc/issue.net这两个文件，或者把这2个文件改名，效果是一样的。 12mv /etc/issue /etc/issuebakmv /etc/issue.net /etc/issue.netbak 十三、优化Linux内核参数123456789101112131415161718192021222324252627282930313233cp /etc/sysctl.conf /etc/sysctl.confbakvi /etc/sysctl.conf #在文件末尾添加以下内容net.ipv4.ip_forward = 1 #修改为1net.core.somaxconn = 262144net.core.netdev_max_backlog = 262144net.core.wmem_default = 8388608net.core.rmem_default = 8388608net.core.rmem_max = 16777216net.core.wmem_max = 16777216net.ipv4.netfilter.ip_conntrack_max = 131072net.ipv4.netfilter.ip_conntrack_tcp_timeout_established = 180net.ipv4.route.gc_timeout = 20net.ipv4.ip_conntrack_max = 819200net.ipv4.ip_local_port_range = 10024 65535net.ipv4.tcp_retries2 = 5net.ipv4.tcp_fin_timeout = 30net.ipv4.tcp_syn_retries = 1net.ipv4.tcp_synack_retries = 1net.ipv4.tcp_timestamps = 0net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_tw_len = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_keepalive_time = 120net.ipv4.tcp_keepalive_probes = 3net.ipv4.tcp_keepalive_intvl = 15net.ipv4.tcp_max_tw_buckets = 36000net.ipv4.tcp_max_orphans = 3276800net.ipv4.tcp_max_syn_backlog = 262144net.ipv4.tcp_wmem = 8192 131072 16777216net.ipv4.tcp_rmem = 32768 131072 16777216net.ipv4.tcp_mem = 94500000 915000000 927000000/sbin/sysctl -p #使配置立即生效 十四、CentOS 系统优化123456789cp /etc/profile /etc/profilebak2vi /etc/profile #在文件末尾添加以下内容ulimit -c unlimitedulimit -s unlimitedulimit -SHn 65535ulimit -S -c 0export LC_ALL=Csource /etc/profile #使配置立即生效ulimit -a #显示当前的各种用户进程限制 十五、服务器禁止ping1234cp /etc/rc.d/rc.local /etc/rc.d/rc.localbakvi /etc/rc.d/rc.local #在文件末尾增加下面这一行echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all参数0表示允许 1表示禁止 至此，CentOS Linux服务器安全设置基本完成，以上设置经过笔者实战测试（CentOS-5.5-x86_64）完全可用，更多的安全设置以及服务器优化，还请大家自行测试。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Tomcat安装配置与简单部署]]></title>
      <url>%2Fposts%2F977dfd0f%2F</url>
      <content type="text"><![CDATA[Tomcat简介 Tomcat是一个免费开源的web服务器应用程序,使用java编程语言所编写，运行于jvm（java虚拟机）之上，轻量安全是其特性，适用于反访问量不大的中小型服务系统Tomcat可以独立运行为一个web服务器，但其通常作为Apache web 服务的一个扩展，Apache处理html静态页面，tomcat处理动态内容 如果您要了解这种技术的细节可以查阅参考资料。 Tomcat基础组件与框架123456789101112131415161718192021222324252627282930server：位于最外层，一个server即一个tomcat实例 connecter（连接器），为辅助组件，附加在引擎之上，将用户的请求定义至指定的虚拟主机 service：把连接器与引擎关联起来的组件 engine：运行虚拟主机的容器 host：虚拟主机 提醒：一个引擎内部可以定义多个虚拟主机，每个虚拟主机可定义多个context（别名） 每个组件由“类”实现，分为如下几类： 顶级组件：server 服务组件：service 连接器组件：http，https，ajp 容器类：engine，host，context 被嵌套类组件：valve，logger，realm，loader，manager 框架： &lt;sever&gt; &lt;service&gt; &lt;connector/&gt; &lt;connectot/&gt; &lt;engine&gt; &lt;host&gt; &lt;context/&gt; … &lt;/host&gt; … &lt;/engine&gt; &lt;/service&gt; &lt;/server&gt; 准备工作 准备一台虚拟机, 均为CentOS-7-x86_64最小化安装, iptables与SELinux均处于关闭状态, 配置好yum源(base和epel). 做好快照, 以便每次实验后快速恢复. tomcat安装 综上所述，tomcat是用Java语言研发，运行于jvm(java virtual machine)之上，所以要安装的话需要提供JDK开发平台。由此，安装可分为两步：JDK+tomcat OracleJDK+Tomcat(binary)使用Oracle官方提供的JDK安装包和Apache官方提供的Tomcat二进制安装包来安装, 请自行去官方站点下载12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879# 安装OracleJDK[root@1478a474 ~]# rpm -ivh jdk-7u79-linux-x64.rpm Preparing... ################################# [100%]Updating / installing... 1:jdk-2000:1.7.0_79-fcs ################################# [100%]Unpacking JAR files... rt.jar... jsse.jar... charsets.jar... tools.jar... localedata.jar... jfxrt.jar...[root@1478a474 ~]# java -versionjava version "1.7.0_79"Java(TM) SE Runtime Environment (build 1.7.0_79-b15)Java HotSpot(TM) 64-Bit Server VM (build 24.79-b02, mixed mode)# 安装Tomcat[root@1478a474 ~]# tar -xf apache-tomcat-7.0.57.tar.gz -C /usr/local/[root@1478a474 ~]# ln -s apache-tomcat-7.0.57/ /usr/local/tomcat[root@1478a474 ~]# tree -L 1 /usr/local/tomcat//usr/local/tomcat/├── bin # 脚本及启动时用到的类├── conf # 配置文件├── lib # 类库├── LICENSE├── logs # 日志文件├── NOTICE├── RELEASE-NOTES├── RUNNING.txt├── temp # 临时文件├── webapps # 应用程序默认部署目录└── work # 工作目录, jsp代码编译成class文件装入JVM运行, 生成class文件就存放在此目录.7 directories, 4 files# 需要导出环境变量[root@1478a474 ~]# echo 'export PATH=/usr/local/tomcat/bin:$PATH' &gt; /etc/profile.d/tomcat.sh[root@1478a474 ~]# exec bash# 似乎也不用特别设置CATALINA_BASE和JAVA_HOME环境变量, 都自动识别出来了.[root@1478a474 ~]# catalina.sh versionUsing CATALINA_BASE: /usr/local/tomcatUsing CATALINA_HOME: /usr/local/tomcatUsing CATALINA_TMPDIR: /usr/local/tomcat/tempUsing JRE_HOME: /usrUsing CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jarServer version: Apache Tomcat/7.0.57Server built: Nov 3 2014 08:39:16 UTCServer number: 7.0.57.0OS Name: LinuxOS Version: 3.10.0-327.el7.x86_64Architecture: amd64JVM Version: 1.7.0_79-b15JVM Vendor: Oracle Corporation# 直接启动[root@1478a474 ~]# catalina.sh startUsing CATALINA_BASE: /usr/local/tomcatUsing CATALINA_HOME: /usr/local/tomcatUsing CATALINA_TMPDIR: /usr/local/tomcat/tempUsing JRE_HOME: /usrUsing CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jarTomcat started.# 监听了三个端口, 8080是http监控端口, 8009是ajp协议监控端口, 8005端口是控制端口, 可以用来关闭tomcat. [root@1478a474 ~]# ss -tnlState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:22 *:* LISTEN 0 100 127.0.0.1:25 *:* LISTEN 0 100 :::8009 :::* LISTEN 0 100 :::8080 :::* LISTEN 0 128 :::22 :::* LISTEN 0 100 ::1:25 :::* LISTEN 0 1 ::ffff:127.0.0.1:8005 :::*# 可以看到JVM是以root用户身份启动的, 这个是不安全的. # 官方是建议使用普通用户来启动的, 这也是为什么默认使用8080端口而不80端口的原因, 因为只有管理员身份启动的进程才能监听在特权端口(1-1024)上.[root@1478a474 ~]# ps aux | grep -v grep | grep javaroot 30867 3.6 6.8 1544928 68260 pts/2 Sl 21:24 0:05 /usr/bin/java -Djava.util.logging.config.file=/usr/local/tomca......# 所以建立一个普通用户来启动tomcat[root@1478a474 ~]# useradd -r tomcat[root@1478a474 ~]# chown -R tomcat:tomcat /usr/local/tomcat/[root@1478a474 ~]# ps aux | grep -v grep | grep javatomcat 31726 167 6.2 1343180 62448 ? Sl 21:44 0:03 /usr/bin/java -Djava.util.logging.config.file=/usr/local/tomca...... yum源安装使用centos官方yum中提供的OpenJDK与Tomcat安装包来安装. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# 提供了三个版本的, 根据实际需要选择. 一般生产环境追求的是稳定, 不会激进地采用最新版本.[root@1478a474 ~]# yum list | grep -i openjdkjava-1.6.0-openjdk.x86_64 1:1.6.0.36-1.13.8.1.el7_1 local java-1.6.0-openjdk-demo.x86_64 1:1.6.0.36-1.13.8.1.el7_1 local java-1.6.0-openjdk-devel.x86_64 1:1.6.0.36-1.13.8.1.el7_1 local java-1.6.0-openjdk-javadoc.x86_64 1:1.6.0.36-1.13.8.1.el7_1 local java-1.6.0-openjdk-src.x86_64 1:1.6.0.36-1.13.8.1.el7_1 local java-1.7.0-openjdk.x86_64 1:1.7.0.91-2.6.2.3.el7 local java-1.7.0-openjdk-accessibility.x86_64 1:1.7.0.91-2.6.2.3.el7 local java-1.7.0-openjdk-demo.x86_64 1:1.7.0.91-2.6.2.3.el7 local java-1.7.0-openjdk-devel.x86_64 1:1.7.0.91-2.6.2.3.el7 local java-1.7.0-openjdk-headless.x86_64 1:1.7.0.91-2.6.2.3.el7 local java-1.7.0-openjdk-javadoc.noarch 1:1.7.0.91-2.6.2.3.el7 local java-1.7.0-openjdk-src.x86_64 1:1.7.0.91-2.6.2.3.el7 local java-1.8.0-openjdk.x86_64 1:1.8.0.65-3.b17.el7 local java-1.8.0-openjdk-accessibility.x86_64 1:1.8.0.65-3.b17.el7 local java-1.8.0-openjdk-accessibility-debug.x86_64java-1.8.0-openjdk-debug.x86_64 1:1.8.0.65-3.b17.el7 local java-1.8.0-openjdk-demo.x86_64 1:1.8.0.65-3.b17.el7 local java-1.8.0-openjdk-demo-debug.x86_64 1:1.8.0.65-3.b17.el7 local java-1.8.0-openjdk-devel.x86_64 1:1.8.0.65-3.b17.el7 local java-1.8.0-openjdk-devel-debug.x86_64 1:1.8.0.65-3.b17.el7 local java-1.8.0-openjdk-headless.x86_64 1:1.8.0.65-3.b17.el7 local java-1.8.0-openjdk-headless-debug.x86_64 1:1.8.0.65-3.b17.el7 local java-1.8.0-openjdk-javadoc.noarch 1:1.8.0.65-3.b17.el7 local java-1.8.0-openjdk-javadoc-debug.noarch 1:1.8.0.65-3.b17.el7 local java-1.8.0-openjdk-src.x86_64 1:1.8.0.65-3.b17.el7 local java-1.8.0-openjdk-src-debug.x86_64 1:1.8.0.65-3.b17.el7 local# 选择1.7, 中庸之道.[root@1478a474 ~]# yum install -y java-1.7.0-openjdk java-1.7.0-openjdk-devel java-1.7.0-openjdk-headless# 再来安装tomcat[root@1478a474 ~]# yum install -y tomcat tomcat-lib tomcat-webapps tomcat-admin-webapps# 好像也不用配什么JAVA_HOME还有CATALINA_BASE这些环境变量, 直接就可以启动了.[root@1478a474 ~]# systemctl start tomcat.service# 这个8005端口好像监听会慢一些, 总是得等一会才能看到. [root@1478a474 ~]# ss -tnlState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:22 *:* LISTEN 0 100 127.0.0.1:25 *:* LISTEN 0 100 :::8009 :::* LISTEN 0 100 :::8080 :::* LISTEN 0 128 :::22 :::* LISTEN 0 100 ::1:25 :::* LISTEN 0 1 ::ffff:127.0.0.1:8005 :::*# 如果要配的话, 除了可以配置环境变量, 也可以修改/etc/sysconfig/tomcat这个文件.[root@1478a474 ~]# cat /etc/sysconfig/tomcat...# Where your java installation lives#JAVA_HOME="/usr/lib/jvm/java"# Where your tomcat installation lives#CATALINA_BASE="/usr/share/tomcat"#CATALINA_HOME="/usr/share/tomcat"#JASPER_HOME="/usr/share/tomcat"#CATALINA_TMPDIR="/var/cache/tomcat/temp"# 这里面还可以配置jvm的启动参数, 比如指定使用内存大小. # 这个在大内存的时候有用, 因为JVM有个32G内存限制, 使用超过32G内存性能反而会下降. # 所以如果内存超过32G时, 最好分多个JVM实例启动, 每个JVM实例使用不超过32G内存.# -Xms：初始值# -Xmx：最大值# -Xmn：最小值#JAVA_OPTS="-Xms512m -Xmx1024m"...# 可以看到JVM是以tomcat用户身份启动的, 所以安全问题也不用操心了.[root@1478a474 ~]# ps aux | grep -v grep | grep javatomcat 30217 1.8 9.1 1932192 91672 ? Ssl 20:40 0:15 java -classpath /usr/share/tomcat/bin/bootstrap.jar:/usr/share/tomc... 管理接口用户认证用浏览器打开http://172.18.71.130:8080, 默认主页是tomcat的管理接口. 但是访问管理接口是需要通过身份认证的, 这需要在tomcat-users.xml配置角色/用户/口令. yum源安装时, 此文件是放在/etc/tomcat目录中, 二进制包安装时此文件是放在/usr/local/tomcat/conf目录中.Server Status是查看服务器运行状态的管理接口, 对应的角色是manager-status.Manager App是应用程序管理接口, 对应的角色是manager-gui.Host Manager是虚拟主机管理接口, 对应的角色是admin-gui.为某管理接口创建认证用户就是要在tomcat-users.xml配置文件中创建用户和口令, 并属于对应的角色. 以为Manager App创建认证用户为例.123456[root@1478a474 ~]# vim /etc/tomcat/tomcat-users.xml&lt;tomcat-users&gt; &lt;role rolename="manager-gui"/&gt; &lt;user username="tomcat" password="magedu" roles="manager-gui"/&gt;&lt;/tomcat-users&gt;[root@1478a474 ~]# systemctl restart tomcat.service 应用部署在应用程序部署目录webapps下创建一个新应用demo. WEB-INF 私有资源目录, 通常存放当前应用自用的web.xml.META-INF 私有资源目录, 通常存放当前应用自用的context.xml.classes 此应用的私有类.lib 此应用的私有类, 被打包为jar格式类.index.jsp 此应用的主页. 123456789101112131415161718192021[root@1478a474 ~]# mkdir -p /var/lib/tomcat/webapps/demo/&#123;classes,META-INF,WEB-INF,lib&#125;[root@1478a474 ~]# cat &lt;&lt; EOF &gt; /var/lib/tomcat/webapps/demo/index.jsp&lt;%@ page language="java" %&gt;&lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color="red"&gt;TomcatA.magedu.com&lt;/font&gt;&lt;/h1&gt; &lt;table align="centre" border="1"&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;% session.setAttribute("magedu.com","magedu.com"); %&gt; &lt;td&gt;&lt;%= session.getId() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;&lt;%= session.getCreationTime() %&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt;EOF 虚拟主机1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@1478a474 ~]# vim /etc/tomcat/server.xml...&lt;!-- 将默认虚拟主机改为自定义的虚拟主机www.twoyang.net --&gt;&lt;Engine name="Catalina" defaultHost="www.twoyang.net"&gt; ... &lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log." suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;!-- 自定义虚拟主机www.twoyang.net, 应用基础路径为/data/webapps. --&gt; &lt;Host name="www.twoyang.net" appBase="/data/webapps" unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log." suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt;&lt;/Engine&gt;...[root@1478a474 ~]# mkdir -p /data/webapps[root@1478a474 ~]# mv /var/lib/tomcat/webapps/demo/ /data/webapps/[root@1478a474 ~]# chown -R tomcat:tomcat /data/webapps[root@1478a474 ~]# systemctl restart tomcat.service# 增加本地对www.twoyang.net的解析[root@1478a474 ~]# echo "172.18.71.130 www.twoyang.net" &gt;&gt; /etc/hosts[root@1478a474 ~]# curl http://www.twoyang.net:8080/demo/&lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color="red"&gt;TomcatA.magedu.com&lt;/font&gt;&lt;/h1&gt; &lt;table align="centre" border="1"&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;td&gt;B733951E170B4A86839C70C9C633EB2B&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;1465651810125&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt; #反向代理 使用nginx或haproxy作为前端反向代理时, 只能走http协议. 只有使用httpd作为前端反向代理时, 才能走ajp协议.而通过httpd来向后做反向代理时, 可以分为几种模块, 一种是通过mode_proxy_http模块, 一种是通过mode_proxy_ajp模块, 还有一种是用过mod_jk模块. 其中第三种模块是一种比较老的方式, 多见于一些较老的httpd版本, 后来已经被mode_proxy_ajp模块所取代, 但是目前仍然有一些企业在使用.不过既然后来已经被淘汰了, 就不演示它了, 真的要用了再去研究吧. 只演示一下使用httpd分别通过http协议和ajp协议来进行反向代理. mode_proxy_http1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@1478a474 ~]# yum install -y httpd[root@1478a474 ~]# httpd -M | grep proxy_http proxy_http_module (shared)[root@1478a474 ~]# vim /etc/httpd/conf.d/proxy_http.conf# 用于控制在http首部是否使用Via, 主要用于在多级代理中控制代理请求的流向.# 默认为Off, 即不启用此功能; On表示每个请求和响应报文均添加Via.# Full表示每个Via行都会添加当前apache服务器的版本号信息.# Block表示每个代理请求报文中的Via都会被移除.ProxyVia Off# 是否开启apache正向代理的功能, 启用此项时为了代理http协议必须启用mod_proxy_http模块.# 同时, 如果为apache设置了ProxyPass, 则必须将ProxyRequests设置为Off.ProxyRequests Off# 如果启用此功能, 代理会将用户请求报文中的Host行发送给后端的服务器, 而不再使用ProxyPass指定的服务器地址.# 如果想在反向代理中支持虚拟主机, 则需要开启此项, 否则就无需打开此功能.ProxyPreserveHost Off# 将请求反向代理至后端主机ProxyPass / http://172.18.71.130:8080/# 用于让apache调整HTTP重定向响应报文中的Location, Content-Location及URI标签所对应的URL.# 在反向代理环境中必须使用此指令避免重定向报文绕过proxy服务器.ProxyPassReverse / http://172.18.71.130:8080/&lt;Proxy *&gt; Require all granted&lt;/Proxy&gt;&lt;Location / &gt; Require all granted&lt;/Location&gt;[root@1478a474 ~]# httpd -tSyntax OK[root@1478a474 ~]# systemctl start httpd.service[root@1478a474 ~]# ss -tnl | grep -w 80LISTEN 0 128 :::80 :::*[root@1478a474 ~]# curl http://172.18.71.130/demo/&lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color="red"&gt;TomcatA.magedu.com&lt;/font&gt;&lt;/h1&gt; &lt;table align="centre" border="1"&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;td&gt;BADEAC947662D40AF3B7662014B10742&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;1465654377253&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt; mode_proxy_ajp1234567891011121314151617181920212223242526272829303132333435363738394041[root@1478a474 ~]# yum install -y httpd[root@1478a474 ~]# httpd -M | grep proxy_ajp proxy_ajp_module (shared)[root@1478a474 ~]# mv /etc/httpd/conf.d/proxy_http.conf&#123;,.bak&#125;[root@1478a474 ~]# vim /etc/httpd/conf.d/proxy_ajp.confProxyVia OffProxyRequests OffProxyPreserveHost Off# 与走http协议的配置基本一致, 只是这个地方需要使用ajp协议和响应的8009端口.ProxyPass / ajp://172.18.71.130:8009/ProxyPassReverse / ajp://172.18.71.130:8009/&lt;Proxy *&gt; Require all granted&lt;/Proxy&gt;&lt;Location / &gt; Require all granted&lt;/Location&gt;[root@1478a474 ~]# httpd -tSyntax OK[root@1478a474 ~]# systemctl restart httpd.service[root@1478a474 ~]# ss -tnl | grep -w 80LISTEN 0 128 :::80 :::*[root@1478a474 ~]# curl http://172.18.71.130/demo/&lt;html&gt; &lt;head&gt;&lt;title&gt;TomcatA&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;font color="red"&gt;TomcatA.magedu.com&lt;/font&gt;&lt;/h1&gt; &lt;table align="centre" border="1"&gt; &lt;tr&gt; &lt;td&gt;Session ID&lt;/td&gt; &lt;td&gt;BADEAC947662D40AF3B7662014B10742&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Created on&lt;/td&gt; &lt;td&gt;1465654377253&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt; 其实tomcat一侧也是需要配置的, 只不过tomcat有默认的Connector配置. 如果tomcat没有使用默认配置, 那么httpd也需要做相应修改.123456789[root@1478a474 ~]# vim /etc/tomcat/server.xml&lt;Service name="Catalina"&gt;...&lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt;&lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" /&gt;...&lt;/Service&gt; 参考http://twoyang.net]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ansible教程]]></title>
      <url>%2Fposts%2Fd2b5ca2e%2F</url>
      <content type="text"><![CDATA[ansible简介ansible是新出现的 自动化 运维工具 ， 基于Python研发 。 糅合了众多老牌运维工具的优点实现了批量操作系统配置、批量程序的部署、批量运行命令等功能。 仅需在管理工作站上安装 ansible 程序配置被管控主机的 IP 信息，被管控的主机无客户端。 ansible 应用程序存在于 epel( 第三方社区 ) 源，依赖于很多 python 组件 ansible 特性 模块化 设计 ，调用特定的模块来完成特定任务 ，本身是核心组件，短小精悍 ； 基于Python语言实现，由Paramiko (python 的一个可并发连接 ssh 主机功能库 ) , PyYAML和Jinja2 ( 模板化 ) 三个关键模块实现； 部署简单，agentless 无客户端工具； 主从模式 工作； 支持自定义模块 功能； 支持playbook 剧本，连续任务按先后设置顺序完成； 期望每个命令具有 幂等性： ansible 架构 ansible core ： ansible 自身核心模块 host inventory： 主机库，定义可管控的主机列表 connection plugins： 连接插件，一般默认基于 ssh 协议连接 modules：core modules ( 自带模块 ) 、 custom modules ( 自定义模块 ) playbooks ：剧本，按照所设定编排的顺序执行完成安排任务 ansible的基本使用 安装软件yum install ansible -y # 对应的软件在 epel 仓库中也可自己手动编译源码地址 https://pypi.python.org/packages/source/a/ansible/ansible-1.5.tar.gz 123456789101112定义Host Inventory # vim /etc/ansible/hosts [webhosts] 172.16.10.22 ansible_ssh_user=root ansible_ssh_pass=guoting 172.16.10.33 ansible_ssh_user=root ansible_ssh_pass=guoting 解释 #ansible_ssh_user=root 是ssh登陆用户 #ansible_ssh_pass=guoting 是ssh登陆密码3、测试各个模块 # 注意每个模块的用法可以使用 ansible-doc MOD 来查看例如ansible-doc copy ansible命令最常用的用法 ansible &lt;Host-partten&gt; -m MOE -a 'MOD_ARV'所支持的模块可以使用ansible-doc -l来查看 ansible示例1、查看时间信息。command、shell模块 2、在控制端添加添加用户。user模块 3、实现ssh秘钥认证。shell、copy模块 此时就可以实现基于ssh秘钥通信了此时/etc/ansible/hosts可以修改如下 1234###### /etc/ansible/hosts [webhosts] 172.16.10.22 172.16.10.33 4、安装软件和启动服务。yum、service模块 5、支持管道的命令。raw模块，类似于shell模块 YAML语言介绍YAML简介123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657YAML是一个可读性高的用来表达资料序列的格式。YAML参考了其他多种语言包括XML、C语言、Python、Perl以及电子邮件格式RFC2822等。Clark Evans在2001年在首次发表了这种语言另外Ingy dtNet与Oren Ben-Kiki也是这语言的共同设计者。 YAML Ain't Markup Language即YAML不是XML。不过在开发的这种语言时YAML的意思其实是"Yet Another Markup Language"仍是一种标记语言。其特性: YAML的可读性好 YAML和脚本语言的交互性好 YAML使用实现语言的数据类型 YAML有一个一致的信息模型 YAML易于实现 YAML可以基于流来处理 YAML表达能力强扩展性好 更多的内容及规范参见http://www.yaml.org。 ##########################YAML语法 YAML的语法和其他高阶语言类似并且可以简单表达清单、散列表、标量等数据结构。其结构Structure通过空格来展示序列Sequence里的项用"-"来代表 Map里的键值对用":"分隔。YAML文件扩展名通常为.yaml或者.yml。下面是一个示例。 name: John Smith age: 41gender: Male spouse: name: Jane Smith age: 37 gender: Female children: - name: Jimmy Smith age: 17 gender: Male - name: Jenny Smith age 13 gender: Female YAML 2 个重要的结构组成部分list和directory ################################# list 列表的所有元素均使用“-”打头例如 # A list of tasty fruits - Apple - Orange - Strawberry - Mango ##############################dictionary 字典通过key与valuef进行标识例如 --- # An employee record name: Example Developer job: Developer skill: Elite 也可以将key:value放置于&#123;&#125;中进行表示例如 --- # An employee record &#123;name: Example Developer, job: Developer, skill: Elite&#125; 多个映射关系组成一个字典一个列表可以包含多个字典。 2、ymal中的变量12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849################################## 变量命名 变量名仅能由字母、数字和下划线组成且只能以字母开头。 ################################## facts facts是由正在通信的远程目标主机发回的信息这些信息被保存在ansible变量中。要获取指定的远程主机所支持的所有facts可使用如下命令进行 # ansible hostname -m setup 这个命令可以获得被监控端主机的各种信息将这些信息得到后保存到变量中。 ################################ 自定义变量 在 yaml 中可以使用vars关键字来定义变量 vars: var_name: value ############################# 变量的引用 &#123;&#123; var_name &#125;&#125; ########################### 特殊的变量迭代 当有需要重复性执行的任务时可以使用迭代机制。其使用格式为将需要迭代的内容定义为item变量引用并通过with_items语句来指明迭代的元素列表即可。 #######################################示例 例如在被控端添加 2 个用户 方式1一般做法 - name: add user testuser1 user: name=testuser1 state=present groups=wheel - name: add user testuser2 user: name=testuser2 state=present groups=wheel 方式2使用变量方式 - name: add several users vars: user1: testuser1 user2: testuser2 user: name=&#123;&#123; user1 &#125;&#125; state=present groups=wheel user: name=&#123;&#123; user2 &#125;&#125; state=present groups=wheel 方式3使用迭代方式 - name: add several users user: name=&#123;&#123; item &#125;&#125; state=present groups=wheel with_items: - testuser1 - testuser2 事实上with_items中可以使用元素还可为hashes例如 - name: add several users user: name=&#123;&#123; item.name &#125;&#125; state=present groups=&#123;&#123; item.groups &#125;&#125; with_items: - &#123; name: 'testuser1', groups: 'wheel' &#125; - &#123; name: 'testuser2', groups: 'root' &#125; 3、Inentory文件的格式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263inventory文件遵循INI文件风格中括号中的字符为组名。可以将同一个主机同时归并到多个不同的组中此外当如若目标主机使用了非默认的SSH端口还可以在主机名称之后使用冒号加端口号来标明。 [webservers] www1.magedu.com:2222 www2.magedu.com [dbservers] db1.magedu.com db2.magedu.com db3.magedu.com 如果主机名称遵循相似的命名模式还可以使用列表的方式标识各主机例如 [webservers] www[01:50].example.com [databases] db-[a:f].example.com #################### 主机变量 可以在inventory中定义主机时为其添加主机变量以便于在playbook中使用。例如 [webservers] www1.magedu.com http_port=80 maxRequestsPerChild=808 www2.magedu.com http_port=303 maxRequestsPerChild=909 ################### 组变量 组变量是指赋予给指定组内所有主机上的在playbook中可用的变量。例如 [webservers] www1.magedu.com www2.magedu.com [webservers:vars] ntpntp_server=ntp.magedu.com nfsnfs_server=nfs.magedu.com ################## 组嵌套 inventory中组还可以包含其它的组并且也可以向组中的主机指定变量。不过这些变量只能在ansible-playbook中使用而ansible不支持。例如 [apache] httpd1.magedu.com httpd2.magedu.com [nginx] ngx1.magedu.com ngx2.magedu.com [webservers:children] apache nginx [webservers:vars] ntpntp_server=ntp.magedu.com ######################### inventory参数 ansible基于ssh连接inventory中指定的远程主机时还可以通过参数指定其交互方式常用的参数如下所示 ansible_ssh_host # 要连接的主机名 ansible_ssh_port # 端口号默认是22 ansible_ssh_user # ssh连接时默认使用的用户名 ansible_ssh_pass # ssh连接时的密码 ansible_sudo_pass # 使用sudo连接用户是的密码 ansible_ssh_private_key_file # 秘钥文件如果不想使用ssh-agent管理时可以使用此选项 ansible_shell_type # shell的类型默认sh ######################################################################################### ansible的循环机制还有更多的高级功能具体请参见官方文档http://docs.ansible.com/playbooks_loops.html。 4、playbooks12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364playbook是由一个或多个“play”组成的列表。play的主要功能在于将事先归并为一组的主机装扮成事先通过ansible中的task定义好的角色。 从根本上来讲所谓task无非是调用ansible的一个module。将多个play组织在一个playbook中即可以让它们联同起来按事先编排的机制同唱一台大戏。 ###########################playbook基础组件 1、Hosts和Users playbook中的每一个play的目的都是为了让某个或某些主机以某个指定的用户身份执行任务。 hosts用于指定要执行指定任务的主机其可以是一个或多个由冒号分隔主机组。 remote_user则用于指定远程主机上的执行任务的用户。 不过remote_user也可用于各task中。也可以通过指定其通过sudo的方式在远程主机上执行任务其可用于play全局或某任务。 此外甚至可以在sudo时使用sudo_user指定sudo时切换的用户。 - hosts: webnodes remote_user: mageedu tasks: - name: test connection ping: remote_user: mageedu sudo: yes 2、任务列表和action play的主体部分是task list。task list中的各任务按次序逐个在hosts中指定的所有主机上执行即在所有主机上完成第一个任务后再开始第二个。 在运行自下而下某playbook时如果中途发生错误所有已执行任务都将回滚因此在更正playbook后重新执行一次即可。 task的目的是使用指定的参数执行模块而在模块参数中可以使用变量。模块执行是幂等的这意味着多次执行是安全的因为其结果均一致。 每个task都应该有其name用于playbook的执行结果输出建议其内容尽可能清晰地描述任务执行步骤。如果未提供name则action的结果将用于输出。 定义task的可以使用“action: module options”或“module: options”的格式推荐使用后者以实现向后兼容。 如果action一行的内容过多也中使用在行首使用几个空白字符进行换行。 tasks: - name: make sure apache is running service: name=httpd state=running 在众多模块中只有command和shell模块仅需要给定一个列表而无需使用“key=value”格式例如 tasks: - name: disable selinux command: /sbin/setenforce 0如果命令或脚本的退出码不为零可以使用如下方式替代 tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand || /bin/true 或者使用ignore_errors来忽略错误信息 tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand ignore_errors: True 3、handlers 用于当关注的资源发生变化时采取一定的操作。 “notify”这个action可用于在每个play的最后被触发这样可以避免多次有改变发生时每次都执行指定的操作取而代之仅在所有的变化发生完成后一次性地执行指定操作。在notify中列出的操作称为handler也即notify中调用handler中定义的操作。 - name: template configuration file template: src=template.j2 dest=/etc/foo.conf notify: - restart memcached - restart apache handler是task列表这些task与前述的task并没有本质上的不同。 handlers: - name: restart memcached service: name=memcached state=restarted - name: restart apache service: name=apache state=restarted 5、tags123456789101112131415161718192021222324252627282930313233343536373839404142tags用于让用户选择运行或路过playbook中的部分代码。ansible具有幂等性因此会自动跳过没有变化的部分即便如此有些代码为测试其确实没有发生变化的时间依然会非常地长。此时如果确信其没有变化就可以通过tags跳过此些代码片断。 示例基于playbooks实现web服务的部署 1、提供好Inventory文件 # /etc/ansible/hosts基于秘钥认证 [webhosts] 172.16.10.22 172.16.10.33 2、编辑 palybooks 剧本 # vim /root/web.yaml - name: web service remote_user: root hosts: webhosts vars: packages: httpd tasks: - name: install httpd yum: name=&#123;&#123; packages &#125;&#125; state=present tags: install - name: configuration httpd copy: src=/root/httpd.conf dest=/etc/httpd/conf/httpd.conf tags: conf notify: - restart httpd - name: service httpd start service: name=httpd enabled=no state=started tags: start - name: add centos and hadoop user user: name=&#123;&#123; item &#125;&#125; state=absent tags: adduser with_items: - centos - hadoop handlers: - name: restart httpd service: name=httpd state=restarted 3、准备好配置文件 将web的配置放到指定目录 src=/root/httpd.conf 4、开始部署 ansible-playbooks /root/web.yml 结果示例 查看端口 此时如果配置文件发生变化 至此基本使用配置完成]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[TCP三次握手四次挥手详解]]></title>
      <url>%2Fposts%2Fc3aadb%2F</url>
      <content type="text"><![CDATA[TCP报文格式TCP/IP协议的详细信息参看《TCP/IP协议详解》三卷本。下面是TCP报文格式图： 上图中有几个字段需要重点介绍下：123456789（1）序号：Seq序号，占32位，用来标识从TCP源端向目的端发送的字节流，发起方发送数据时对此进行标记。（2）确认序号：Ack序号，占32位，只有ACK标志位为1时，确认序号字段才有效，Ack=Seq+1。（3）标志位：共6个，即URG、ACK、PSH、RST、SYN、FIN等， 具体含义如下： （A）URG：紧急指针（urgent pointer）有效。 （B）ACK：确认序号有效。 （C）PSH：接收方应该尽快将这个报文交给应用层。 （D）RST：重置连接。 （E）SYN：发起一个新连接。 （F）FIN：释放一个连接。 需要注意的是： （A）不要将确认序号Ack与标志位中的ACK搞混了。 （B）确认方Ack=发起方Req+1，两端配对。 三次握手 所谓三次握手（Three-Way Handshake）即建立TCP连接，就是指建立一个TCP连接时，需要客户端和服务端总共发送3个包以确认连接的建立。在socket编程中，这一过程由客户端执行connect来触发，整个流程如下图所示： （1）第一次握手： Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。 （2）第二次握手： Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。 （3）第三次握手： Client收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server，Server检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。 SYN攻击：在三次握手过程中，Server发送SYN-ACK之后，收到Client的ACK之前的TCP连接称为半连接（half-open connect），此时Server处于SYN_RCVD状态，当收到ACK后，Server转入ESTABLISHED状态。SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server回复确认包，并等待Client的确认，由于源地址是不存在的，因此，Server需要不断重发直至超时，这些伪造的SYN包将产时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络堵塞甚至系统瘫痪。SYN攻击时一种典型的DDOS攻击，检测SYN攻击的方式非常简单，即当Server上有大量半连接状态且源IP地址是随机的，则可以断定遭到SYN攻击了，使用如下命令可以让之现行： 1~]# netstat -nap | grep SYN_RECV 三、四次挥手 三次握手耳熟能详，四次挥手估计就… 。所谓四次挥手（Four-Way Wavehand）即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。在socket编程中，这一过程由客户端或服务端任一方执行close来触发，整个流程如下图所示： 由于TCP连接时全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个FIN来终止这一方向的连接，收到一个FIN只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个TCP连接上仍然能够发送数据，直到这一方向也发送了FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭，上图描述的即是如此。 （1）第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。（2）第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态。（3）第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。（4）第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1，Server进入CLOSED状态，完成四次挥手。 上面是一方主动关闭，另一方被动关闭的情况，实际中还会出现同时发起主动关闭的情况，具体流程如下图： 流程和状态在上图中已经很明了了，在此不再赘述，可以参考前面的四次挥手解析步骤。 四、附注1234关于三次握手与四次挥手通常都会有典型的面试题，在此提出供有需求的参考：（1）三次握手是什么或者流程？四次握手呢？答案前面分析就是。（2）为什么建立连接是三次握手，而关闭连接却是四次挥手呢？这是因为服务端在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。而关闭连接时，当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方也未必全部数据都发送给对方了，所以己方可以立即close，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ssh主机互信]]></title>
      <url>%2Fposts%2Fc34b8b4a%2F</url>
      <content type="text"><![CDATA[什么是linux主机互信 Linux主机互信，就是主机之间相互信任，什么是信任，就像人与人之间一样，不需要利用金钱等（除了你自己以外其他的东西）来取得对方的信任，大家相互信任对方，不需要额外的凭证。就好比你，你的家人之间，不需要钱来维持你们之间的信任。同样，linux主机之间也是，我们从一台主机登陆到另一台时，往往需要验证你，需要你输入用户密码，才允许你登陆。这样在多台机器之间来回切换登陆就会频繁输入密码，非常麻烦，看看，一切的根源来自于互不信任。可不可以不用输入密码就直接登陆呢？答案是可以，但条件是主机之间相互信任对方。因此ssh互信就诞生了。我们在主机值之间配置了公钥认证后，也就是取得信任之后，就不必再输入密码了（当然实际上是ssh使用rsa算法帮你完成了验证过程）。 公钥认证的基本思想 对信息的加密和解密采用不同的key，这对key分别称作private key和publickey，其中，public key存放在欲登录的服务器上，而privatekey为特定的客户机所持有。当客户机向服务器发出建立安全连接的请求时，首先发送自己的public key，如果这个public key是被服务器所允许的，服务器就发送一个经过public key加密的随机数据给客户机，这个数据只能通过private key解密，客户机将解密后的信息发还给服务器，服务器验证正确后即确认客户机是可信任的，从而建立起一条安全的信息通道。通过这种方式，客户机不需要向外发送自己的身份标志“private key”即可达到校验的目的，并且private key是不能通过public key反向推断出来的。这避免了网络窃听可能造成的密码泄露。客户机需要小心的保存自己的private key，以免被其他人窃取，一旦这样的事情发生，就需要各服务器更换受信的publickey列表。 使用过github的用户就会知道，用git登陆远程仓库github的时候，也会有公钥认证（当然是首次使用git时），首次使用git，就会要求你在客户端生成一个rsa key pairs，一个public-key存放于id_rsa.pub，一个private-key存放于id_rsa，并且上传你的公钥public-key到github上，这样做的目的就是你可以取得github的信任，也就是github信任你，下次你登录的时候，github会使用你上传的公钥来验证你的身份，从而不用输入密码。当然这个过程只是单向的信任，也就是github现在信任你，但是你并没有建立对github的信任，需要建立么，其实没有必要，因为github是不会主动向你发出请求的，大多数情况是你需要主动向github发送请求。 知道了单向信任，那么相互信任就简单了，就是主机之间的公钥都要告知对方，这样才能相互信任，你信任我，我信任你。那么，以下就是互信建立的步骤了： 配置ssh互信的步骤如下互信的原理了解了，我们可以把配置ssh互信的步骤进行有效的分割。1.在要配置互信的机器(web-1和web-2)上生成各自经过认证的key文件。2.将所有的key文件汇总到一个总的认证文件夹中。3.将打包的key发给想要进行互信的机器(web-1,web-2)4.互信的验证 经过分析，思路变的清晰了，下面我们动手来实际操作：1.在两台机器上生成认证文件，就是ssh互信的认证文件，需要放在用户的home目录中，所以我们需要先创建这个目录，且保证这个目录的权限为755123456789[root@web-1 ~]# mkdir ~/.ssh[root@web-1 ~]# chmod 755 ~/.ssh[root@web-1 ~]# /usr/bin/ssh-keygen -t rsa ＃下面默认回车就行[root@web-1 ~]# /usr/bin/ssh-keygen -t dsa [root@web-2 ~]# mkdir ~/.ssh[root@web-2 ~]# chmod 755 ~/.ssh[root@web-2 ~]# /usr/bin/ssh-keygen -t rsa[root@web-2 ~]# /usr/bin/ssh-keygen -t dsa 2.必须将每个主机上的公共密钥文件id_rsa.pub和id_dsa.pub的内容复制到其他每一个主机的~/.ssh/authorized_keys文件中。注意，当您第一次使用ssh访问远程主机时，其RSA密钥是未知的，所以提示确认一下，确认完毕后SSH将纪录远程主机的RSA密钥，以后连接该主机将不再做出相应的提示。1234[root@web-1 ~]# cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys[root@web-1 ~]# cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys[root@web-1 ~]# ssh root@web-2 cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys[root@web-1 ~]# ssh root@web-2 cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys 3.经过上述两步，在web-1上存了一份完整的key认证文件，我们只需要把这个目录拷贝到web-2这台机器的对应目录里去就可以了，别忘了把authorized_keys 的权限设置成60012[root@web-1 ~]# scp ~/.ssh/authorized_keys web-2:~/.ssh/authorized_keys[root@web-1 ~]# chmod 600 ~/.ssh/authorized_keys]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[初探KVM虚拟化]]></title>
      <url>%2Fposts%2Fb2f2c31e%2F</url>
      <content type="text"><![CDATA[准备工作 CentOS 7安装图形化桌面 关闭iptables与selinux 配置好IP地址和主机名 配置好yum源 开启虚拟机的虚拟化技术 查看硬件是否支持虚拟化技术 vmx对应Intel VT-x, svm对应AMD-V.有内容输出, 说明CPU支持虚拟化技术. 1[root@node1 ~]# egrep --color '(vmx|svm)' /proc/cpuinfo 检查内核模块123[root@node1 ~]# lsmod | grep kvmkvm_intel 162153 0 kvm 525259 1 kvm_intel 如果没有, 需要手动装载.12[root@node1 ~]# modprobe kvm[root@node1 ~]# modprobe kvm_intel 实验步骤安装需要的包组12[root@node1 ~]# yum groupinstall -y "Virtualization" "Virtualization Platform" "Virtualization Client" "Virtualization Tools" "GNOME 桌面"步骤略 安装kvm相关的包1[root@node1 ~]# yum install -y qemu-kvm libvirt virt-manager 配置运行的网络环境12345678910111213141516171819202122232425cp /etc/sysconfig/network-script/ifcfg-eno16777736&#123;,.bak&#125;cp /etc/sysconfig/network-script/ifcfg-eno16777736 /etc/sysconfig/network-script/br0Vim /etc/sysconfig/network-script/ifcfg-br0TYPE=BridgeBOOTPROTO=noneDEFROUTE="yes"IPV4_FAILURE_FATAL="no"NAME="eno16777736"UUID="134a2cd7-c7fb-4493-b23b-3973eac55167"DEVICE=br0ONBOOT="yes"IPADDR=172.18.1.120PREFIX=16GATEWAY=172.18.1.1DNS1=172.18.1.1IPV6_PEERDNS=yesIPV6_PEERROUTES=yesVim /etc/sysconfig/network-script/ifcfg-eno16777736DEVICE=eno16777736BRIDGE=br0ONBOOT=yesBOOTPROTO=none 重启网络服务123456789101112131415161718192021222324252627[root@node1 network-scripts]# systemctl restart network.service[root@node1 network-scripts]# ifconfig br0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.18.1.120 netmask 255.255.0.0 broadcast 172.18.255.255 inet6 fe80::20c:29ff:fe57:f99c prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:57:f9:9c txqueuelen 0 (Ethernet) RX packets 629 bytes 32255 (31.4 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 872 bytes 206884 (202.0 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0eno16777736: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet6 fe80::20c:29ff:fe57:f99c prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0c:29:57:f9:9c txqueuelen 1000 (Ethernet) RX packets 17228 bytes 19524395 (18.6 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 10573 bytes 1265787 (1.2 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 0 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 启动virt-manager12#在图形化界面下[root@node1 network-scripts]# virt-manager]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[AWK使用案例总结]]></title>
      <url>%2Fposts%2F1e93adae%2F</url>
      <content type="text"><![CDATA[企业中常见AWK使用案例总结 1、Nginx日志分析日志格式1'$remote_addr - $remote_user [$time_local] "$request" $status $body_bytes_sent "$http_referer" "$http_user_agent" "$http_x_forwarded_for"' 日志记录127.189.231.39 - - [09/Apr/2016:17:21:23 +0800] "GET /Public/index/images/icon_pre.png HTTP/1.1" 200 44668 "http://www.test.com/Public/index/css/global.css" "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36" "-" 案例分享1）统计日志中访问最多的10个IP 思路：对第一列进行去重，并输出出现的次数 方法1：1$ awk '&#123;a[$1]++&#125;END&#123;for(i in a)print a[i],i|"sort -k1 -nr|head -n10"&#125;' access.log 方法2：1$ awk '&#123;print $1&#125;' access.log |sort |uniq -c |sort -k1 -nr |head -n10 说明：a[$1]++ 创建数组a，以第一列作为下标，使用运算符++作为数组元素，元素初始值为0。处理一个IP时，下标是IP，元素加1，处理第二个IP时，下标是IP，元素加1，如果这个IP已经存在，则元素再加1，也就是这个IP出现了两次，元素结果是2，以此类推。因此可以实现去重，统计出现次数。 2）统计日志中访问大于100次的IP12345方法1：$ awk '&#123;a[$1]++&#125;END&#123;for(i in a)&#123;if(a[i]&gt;100)print i,a[i]&#125;&#125;' access.log方法2：$ awk '&#123;a[$1]++;if(a[$1]&gt;100)&#123;b[$1]++&#125;&#125;END&#123;for(i in b)&#123;print i,a[i]&#125;&#125;' access.log 说明：方法1是将结果保存a数组后，输出时判断符合要求的IP。方法2是将结果保存a数组时，并判断符合要求的IP放到b数组，最后打印b数组的IP。 3）统计2016年4月9日一天内访问最多的10个IP 思路：先过滤出这个时间段的日志，然后去重，统计出现次数 12方法1：$ awk '$4&gt;="[9/Apr/2016:00:00:01" &amp;&amp; $4&lt;="[9/Apr/2016:23:59:59" &#123;a[$1]++&#125;END&#123;for(i in a)print a[i],i|"sort -k1 -nr|head -n10"&#125;' access.log方法2：$ sed -n '/\[9\/Apr\/2016:00:00:01/,/\[9\/Apr\/2016:23:59:59/p' access.log |sort |uniq -c |sort -k1 -nr |head -n10 #前提开始时间与结束时间日志中必须存在 4）统计当前时间前一分钟的访问数 思路：先获取当前时间前一分钟对应日志格式的时间，再匹配统计 123$ date=$(date -d '-1 minute' +%d/%b/%Y:%H:%M);awk -vdate=$date '$0~date&#123;c++&#125;END&#123;print c&#125;' access.log$ date=$(date -d '-1 minute' +%d/%b/%Y:%H:%M);awk -vdate=$date '$4&gt;="["date":00" &amp;&amp; $4&lt;="["date":59"&#123;c++&#125;END&#123;print c&#125;' access.log$ grep -c $(date -d '-1 minute' +%d/%b/%Y:%H:%M) access.log 说明：date +%d/%b/%Y:%H:%M –&gt; 09/Apr/2016:01:55 5）统计访问最多的前10个页面（$request）1$ awk '&#123;a[$7]++&#125;END&#123;for(i in a)print a[i],i|"sort -k1 -nr|head -n10"&#125;' access.log 6）统计每个URL访问内容的总大小（$body_bytes_sent）1$ awk '&#123;a[$7]++;size[$7]+=$10&#125;END&#123;for(i in a)print a[i],size[i],i&#125;' access.log 7）统计每个IP访问状态码数量（$status）1$ awk '&#123;a[$1" "$9]++&#125;END&#123;for(i in a)print i,a[i]&#125;' access.log 8）统计访问状态码为404的IP及出现次数1$ awk '&#123;if($9~/404/)a[$1" "$9]++&#125;END&#123;for(i in a)print i,a[i]&#125;' access.log 2、两个文件对比文件内容如下：1234567891011121314$ cat a 1 2 3 4 5 6$ cat b 3 4 5 6 7 8 1）找出相同记录123456方法1：$ awk 'FNR==NR&#123;a[$0];next&#125;($0 in a)' a b3456 解释前，先看下FNR和NR区别： 1234567891011121314151617181920212223242526$ awk '&#123;print NR,$0&#125;' a b1 12 23 34 45 56 67 38 49 510 611 712 8$ awk '&#123;print FNR,$0&#125;' a b1 12 23 34 45 56 61 32 43 54 65 76 8 可以看出NR是处理一行记录，编号就会加1，同时也可以看到awk将两个文件当成一个合并后的文件处理。而FNR则是处理一行记录，编号也会加1，但是，处理到第二个文件时，编号重新计数。说明：FNR和NR是内置变量。FNR==NR常用于对两个文件处理，这个例子可以理解为awk将两个文件当成一个文件处理。处理a文件时，FNR是等于NR的，条件为真，执行a[$0],next表达式，意思是将每条记录存放到a数组作为下标（无元素），next是跳出，类似于continue，不执行后面表达式。执行过程以此类推，直到处理b件时，FNR不等于NR（FNR重新计数是1，NR继续加1是7），条件为假，不执行后面a[$0],next表达式，直接执行($0 in a)表达式，这句意思是处理b文件第一条继续判断是否在a数组中，如果在则打印这条记录，以此类推。 这样可能更好理解些：1$ awk 'FNR==NR&#123;a[$0]&#125;NR&gt;FNR&#123;if($0 in a)print $0&#125;' a b 方法2：1234$ awk 'FNR==NR&#123;a[$0]=1;next&#125;(a[$0])' a b #小括号可以不加$ awk 'FNR==NR&#123;a[$0]=1;next&#125;(a[$0]==1)' a b$ awk 'FNR==NR&#123;a[$0]=1;next&#125;&#123;if(a[$0]==1)print&#125;' a b$ awk 'FNR==NR&#123;a[$0]=1&#125;FNR!=NR&amp;&amp;a[$0]==1' a b 说明：先要知道后面的a[$0]不是一个数组，而是通过下标（b文件每条记录）来访问a数组元素。如果a[b的一行记录]获取的a数组元素是1，则为真，也就是等于1，打印这条记录，否则获取不到元素，则为假。 方法3：12$ awk 'ARGIND==1&#123;a[$0]=1&#125;ARGIND==2&amp;&amp;a[$0]==1' a b$ awk 'FILENAME=="a"&#123;a[$0]=1&#125;FILENAME=="b"&amp;&amp;a[$0]==1' a b 说明：ARGIND内置变量，处理文件标识符，第一个文件为1，第二个文件为2。FILENAME也是内置变量，表示输入文件的名字 方法4：1$ sort a b |uniq -d 方法5：1$ grep -f a b 2）找不同记录（同上，取反）12345678$ awk 'FNR==NR&#123;a[$0];next&#125;!($0 in a)' a b$ awk 'FNR==NR&#123;a[$0]=1;next&#125;!a[$0]' a b$ awk 'ARGIND==1&#123;a[$0]=1&#125;ARGIND==2&amp;&amp;a[$0]!=1' a b$ awk 'FILENAME=="a"&#123;a[$0]=1&#125;FILENAME=="b"&amp;&amp;a[$0]!=1' a b78方法2：$ sort a b |uniq -d方法3：$ grep -vf a b 3、合并两个文件1）将d文件性别合并到c文件1234567$ cat czhangsan 100lisi 200wangwu 300$ cat dzhangsan manlisi woman 方法1：1234$ awk 'FNR==NR&#123;a[$1]=$0;next&#125;&#123;print a[$1],$2&#125;' c dzhangsan 100 manlisi 200 womanwangwu 300 man 方法2：1$ awk 'FNR==NR&#123;a[$1]=$0&#125;NR&gt;FNR&#123;print a[$1],$2&#125;' c d 说明：NR==FNR匹配第一个文件，NR&gt;FNR匹配第二个文件，将$1为数组下标 ###方法3：1$ awk 'ARGIND==1&#123;a[$1]=$0&#125;ARGIND==2&#123;print a[$1],$2&#125;' c d 2）将a.txt文件中服务名称合并到一个IP中1234567$ cat a.txt192.168.2.100 : httpd192.168.2.100 : tomcat192.168.2.101 : httpd192.168.2.101 : postfix192.168.2.102 : mysqld192.168.2.102 : httpd 方法1：1$ awk -F: -vOFS=":" '&#123;a[$1]=a[$1] $2&#125;END&#123;for(i in a)print i,a[i]&#125;' a.txt 方法2:1234$ awk -F: -vOFS=":" '&#123;a[$1]=$2 a[$1]&#125;END&#123;for(i in a)print i,a[i]&#125;' a.txt192.168.2.100 : httpd tomcat192.168.2.101 : httpd postfix192.168.2.102 : mysqld httpd 说明：a[$1]=$2 第一列为下标，第二个列是元素，后面跟的a[$1]是通过第一列取a数组元素（服务名），结果是$1=$2 $2，并作为a数组元素。 3）将第一行附加给下面每行开头12345$ cat a.txtxiaolia 100b 110c 120 方法1：1$ awk 'NF==1&#123;a=$0;next&#125;&#123;print a,$0&#125;' a.txt 方法2：1234$ awk 'NF==1&#123;a=$0&#125;NF!=1&#123;print a,$0&#125;' a.txtxiaoli a 100xiaoli b 110xiaoli c 120 4、倒叙列打印文本123456789$ cat a.txtxiaoli a 100xiaoli b 110xiaoli c 120$ awk '&#123;for(i=NF;i&gt;=1;i--)&#123;printf "%s ",$i&#125;print s&#125;' a.txt100 a xiaoli110 b xiaoli120 c xiaoli$ awk '&#123;for(i=NF;i&gt;=1;i--)if(i==1)printf $i"\n";else printf $i" "&#125;' a.txt 说明：利用NF降序输出，把最后一个域作为第一个输出，然后自减，print s或print “”打印一个换行符 5、从第二列打印到最后方法1：1$ awk '&#123;for(i=2;i&lt;=NF;i++)if(i==NF)printf $i"\n";else printf $i" "&#125;' a.txt 方法2：1234$ awk '&#123;$1=""&#125;&#123;print $0&#125;' a.txta 100b 110c 120 6、将c文件中第一列放到到d文件中的第三列12345678$ cat cabc$ cat d1 one2 two3 three 方法1：1$ awk 'FNR==NR&#123;a[NR]=$0;next&#125;&#123;$3=a[FNR]&#125;1' c d 说明：以NR编号为下标，元素是每行，当处理d文件时第三列等于获取a数据FNR（重新计数1-3）编号作为下标。 方法2：1234$ awk '&#123;getline f&lt;"c";print $0,f&#125;' d1 one a2 two b3 three c 1）替换第二列1234$ awk '&#123;getline f&lt;"c";gsub($2,f,$2)&#125;1' d1 a2 b3 c 2）替换第二列的two1234$ awk '&#123;getline f&lt;"c";gsub("two",f,$2)&#125;1' d1 one2 b3 three 7、数字求和方法1：1$ seq 1 100 |awk '&#123;sum+=$0&#125;END&#123;print sum&#125;' 方法2：1$ awk 'BEGIN&#123;sum=0;i=1;while(i&lt;=100)&#123;sum+=i;i++&#125;print sum&#125;' 方法3：1$ awk 'BEGIN&#123;for(i=1;i&lt;=100;i++)sum+=i&#125;END&#123;print sum&#125;' /dev/null 方法4：1$ seq -s + 1 100 |bc 8、每隔三行添加一个换行符或内容12345方法1：$ awk '$0;NR%3==0&#123;printf "\n"&#125;' a方法2：$ awk '&#123;print NR%3?$0:$0"\n"&#125;' a方法3：$ sed '4~3s/^/\n/' a 9、字符串拆分方法1：1234567$ echo "hello" |awk -F '' '&#123;for(i=1;i&lt;=NF;i++)print $i&#125;'$ echo "hello" |awk -F '' '&#123;i=1;while(i&lt;=NF)&#123;print $i;i++&#125;&#125;'hello 方法2：123456$ echo "hello" |awk '&#123;split($0,a,"''");for(i in a)print a[i]&#125;' #无序lohel 10、统计字符串中每个字母出现的次数1234$ echo a,b.c.a,b.a |tr "[,. ]" "\n" |awk -F '' '&#123;for(i=1;i&lt;=NF;i++)a[$i]++&#125;END&#123;for(i in a)print i,a[i]|"sort -k2 -rn"&#125;'a 3b 2c 1 11、第一列排序1$ awk '&#123;a[NR]=$1&#125;END&#123;s=asort(a,b);for(i=1;i&lt;=s;i++)&#123;print i,b[i]&#125;&#125;' a.txt 说明：以每行编号作为下标值为$1，并将a数组值放到数组b，a下标丢弃，并将asort默认返回值（原a数组长度）赋值给s，使用for循环小于s的行号，从1开始到数组长度打印排序好的数组。 12、删除重复行，顺序不变1$ awk '!a[$0]++' file 13、删除指定行删除第一行：1234$ awk 'NR==1&#123;next&#125;&#123;print $0&#125;' file #$0可省略$ awk 'NR!=1&#123;print&#125;' file$ sed '1d' file$ sed -n '1!p' file 14、在指定行前后加一行在第二行前一行加txt：12$ awk 'NR==2&#123;sub('/.*/',"txt\n&amp;")&#125;&#123;print&#125;' a.txt$ sed'2s/.*/txt\n&amp;/' a.txt 在第二行后一行加txt：12$ awk 'NR==2&#123;sub('/.*/',"&amp;\ntxt")&#125;&#123;print&#125;' a.txt$ sed'2s/.*/&amp;\ntxt/' a.txt 15、通过IP获取网卡名1$ ifconfig |awk -F'[: ]' '/^eth/&#123;nic=$1&#125;/192.168.18.15/&#123;print nic&#125;' 16、浮点数运算（数字46保留小数点）1234567$ awk 'BEGIN&#123;print 46/100&#125;'$ awk 'BEGIN&#123;printf "%.2f\n",46/100&#125;'$ echo 46|awk '&#123;print $0/100&#125;'$ echo 'scale=2;46/100' |bc|sed 's/^/0/'$ printf "%.2f\n" $(echo "scale=2;46/100" |bc)结果：0.46 17、替换换行符为逗号12345$ cat a.txt123替换后：1,2,3 方法1：1$ awk '&#123;s=(s?s","$0:$0)&#125;END&#123;print s&#125;' a.txt 说明：三目运算符(a?b:c)，第一个s是变量，s?s”,”$0:$0,第一次处理1时，s变量没有赋值初值是0，0为假，结果打印1，第二次处理2时，s值是1，为真，结果1,2。以此类推，小括号可以不写。 方法2：1$ tr '\n' ',' &lt; a.txt 方法3：1$ sed ':a;N;s/\n/,/;$!b a' a.txt 说明：第一个标签a，先读取第一行记录1追加到模式空间，此时模式空间内容是1$，执行$!b（$!最后一行不跳转，b是控制流跳转命令）跳转到a标签，继续读取第二行记录2追加到模式空间，因为使用N命令，每个记录以换行符（\n）分割，此时模式空间内容是1\n2$，执行将换行符替换逗号命令，继续跳转到a标签… 方法4：1$ sed ':a;$!N;s/\n/,/;t a' a.txt 说明：与上面类似，其中t是测试命令，当上一个命令（替换）执行成功才跳转。 方法5：1$ awk '&#123;if($0!=3)printf "%s,",$0;else print $0&#125;' a.txt 说明：3是文本最后一个数 方法6：1234while read line; do a+=($line)done &lt; a.txtecho $&#123;a[*]&#125; |sed 's/ /,/g' 说明：将每行放到数组，然后替换 18、把奇数换行符去掉1234567$ cat b.txtstringnumbera1b2 方法11$ awk 'ORS=NR%2?"\t":"\n"' b.txt #把奇数行换行符去掉 方法21234$ xargs -n2 &lt; a.txt #将两个字段作为一行string numbera 1b 2 19、费用统计12345678910$ cat a.txt姓名 费用 数量zhangsan 8000 1zhangsan 5000 1lisi 1000 1lisi 2000 1wangwu 1500 1zhaoliu 6000 1zhaoliu 2000 1zhaoliu 3000 1 统计每人总费用、总数量：123456$ awk '&#123;name[$1]++;number[$1]+=$3;money[$1]+=$2&#125;END&#123;for(i in name)print i,number[i],money[i]&#125;' a.txtzhaoliu 3 11000zhangsan 2 13000wangwu 1 1500lisi 2 3000 20、打印乘法口诀方法1：1234567891011$ awk 'BEGIN&#123;for(n=0;n++&lt;9;)&#123;for(i=0;i++&lt;n;)printf i"x"n"="i*n" ";print ""&#125;&#125;'1x1=11x2=2 2x2=41x3=3 2x3=6 3x3=91x4=4 2x4=8 3x4=12 4x4=161x5=5 2x5=10 3x5=15 4x5=20 5x5=251x6=6 2x6=12 3x6=18 4x6=24 5x6=30 6x6=361x7=7 2x7=14 3x7=21 4x7=28 5x7=35 6x7=42 7x7=491x8=8 2x8=16 3x8=24 4x8=32 5x8=40 6x8=48 7x8=56 8x8=641x9=9 2x9=18 3x9=27 4x9=36 5x9=45 6x9=54 7x9=63 8x9=72 9x9=81 方法2：123456789#!/bin/bashfor ((i=1;i&lt;=9;i++)); do for ((j=1;j&lt;=i;j++)); do result=$(($i*$j)) #let "result=i*j" echo -n "$i*$j=$result " done echodone 21、只打印奇数或偶数行打印奇数行：方法1：1$ seq 1 5 |awk 'i=!i' 说明：先知道对于数值运算，未定义变量初值为0，对于字符运算，未定义变量初值为空字符串。读取第一行记录，然后进行模式匹配，i是未定义变量，也就是i=!0，!取反意思。感叹号右边是个布尔值，0或空字符串为假，非0或非空字符串为真，!0就是真，因此i=1，条件为真打印第一条记录。没有print为什么会打印呢？因为模式后面没有动作，默认会打印整条记录。读取第二行记录，进行模式匹配，因为上次i的值由0变成了1，此时就是i=!1，条件为假不打印。读取第三行记录，因为上次条件为假，i恢复初值为0，继续打印。以此类推…可以看出，运算时并没有判断记录，而是利用布尔值真假判断。 方法2：1$ seq 1 5 |awk 'NR%2!=0' 方法3：1$ seq 1 5 |sed -n '1~2p' 说明：步长，每隔一行打印一次 方法4：1$ seq 1 5 |sed -n 'p;n' 说明：先打印第一行，执行n命令读取当前行的下一行2，放到模式空间，后面再没有打印模式空间行操作，所以只保存不打印，同等方式继续打印第三行。 结果123135 打印偶数行：1234$ seq 1 5 |awk '!(i=!i)'$ seq 1 5 |awk 'NR%2==0'$ seq 1 5 |sed -n '0~2p'$ seq 1 5 |sed -n 'n;p' 说明：读取当前行的下一行2，放到模式空间，使用p命令打印模式空间的行，输出2。 原文地址:点我]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HAProxy实现动静分离和负载均衡]]></title>
      <url>%2Fposts%2F62f0f54b%2F</url>
      <content type="text"><![CDATA[实验环境 由于电脑配置渣，带不动多台虚拟机，所以采用httpd虚拟主机的方式来实现 123CentOS 6.7httpd: 2.2.15HAProxy: 1.5.4 主机规划12345- 172.18.1.49:8080 --&gt;web server1- 172.18.1.49:8081 --&gt;web server2- 172.18.1.49:8088 --&gt;app server1- 172.18.1.49:8089 --&gt;app server2- 网站资源根目录定义在/data/下 配置虚拟主机安装httpd及PHP12yum install httpd php -y #步骤省略yum install haproxy -y 修改httpd主机监听的端口1234567# 注释掉80Listen 8080Listen 8081Listen 8088Listen 8089#DocumentRoot "/var/www/html" # 注释掉此行 配置虚拟主机websrv1注意：CentOS7默认安装的是Httpd2.4+,所以，在配置虚拟主机时，allow from all要改为Require all granted 123456789vim /etc/httpd/conf.d/websrv1.confDirectoryIndex index.html&lt;virtualhost 172.18.1.49:8080&gt; DocumentRoot /data/webdoc1/ &lt;directory "/data/webdoc1"&gt; allow from all # apache2.4版本要改为Require all granted，下同！ &lt;/directory&gt;&lt;/virtualhost&gt; 配置虚拟主机websrv2123456789vim /etc/httpd/conf.d/websrv2.confDirectoryIndex index.html&lt;virtualhost 172.18.1.49:8081&gt; DocumentRoot /data/webdoc2/ &lt;directory "/data/webdoc2"&gt; allow from all &lt;/directory&gt;&lt;/virtualhost&gt; 配置虚拟主机appsrv1123456789vim /etc/httpd/conf.d/app1.confDirectoryIndex index.php&lt;virtualhost 172.18.1.49:8088&gt; DocumentRoot /data/appdoc1/ &lt;directory "/data/appdoc1"&gt; allow from all &lt;/directory&gt;&lt;/virtualhost&gt; 配置虚拟主机appsrv2123456789vim /etc/httpd/conf.d/app2.confDirectoryIndex index.php&lt;virtualhost 172.18.1.49:8089&gt; DocumentRoot /data/appdoc2/ &lt;directory "/data/appdoc2"&gt; allow from all &lt;/directory&gt;&lt;/virtualhost&gt; 为各主机提供测试页123456789101112131415161718192021#websrv1vim /data/webdoc1/index.html&lt;h1&gt;web-server1&lt;/h1&gt;#websrv2vim /data/webdoc2/index.html&lt;h1&gt;web-server2&lt;/h1&gt;#appsrv1vim /data/appdoc1/index.php&lt;h1&gt;app-server1&lt;/h1&gt;&lt;?php phpinfo();?&gt;#appsrv2vim /data/appdoc2/index.php&lt;h1&gt;app-server2&lt;/h1&gt;&lt;?php phpinfo();?&gt; 修改HAProxy配置1234567891011121314151617181920212223242526frontend http-in bind 172.18.1.49:80 #监听的端口 acl url_static path_end -i .jpg .png .html .css .jsp #acl规则分离静态资源 use_backend websrv if url_static default_backend appsrv #默认使用动态后端主机backend websrv #后端静态主机组 balance roundrobin server srv1 172.18.1.49:8080 check server srv2 172.18.1.49:8081 checkbackend appsrv #后端动态主机组 balance roundrobin server app1 172.18.1.49:8088 check server app2 172.18.1.49:8089 checklisten stats 172.18.1.49:9001 #提供一个管理页面 stats enable stats uri /admin?stats stats hide-version stats auth admin:admin#保存退出service httpd startservice haproxy start]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Apache配置虚拟主机的三种方式]]></title>
      <url>%2Fposts%2F667f3f35%2F</url>
      <content type="text"><![CDATA[Apache 配置虚拟主机三种方式一、基于IP 假设服务器有个IP地址为192.168.1.10，使用ifconfig在同一个网络接口eth0上绑定3个IP： 123[root@localhost root]# ifconfig eth0:1 192.168.1.11[root@localhost root]# ifconfig eth0:2 192.168.1.12[root@localhost root]# ifconfig eth0:3 192.168.1.13 修改hosts文件，添加三个域名与之一一对应： 123192.168.1.11 www.test1.com192.168.1.12 www.test2.com192.168.1.13 www.test3.com 建立虚拟主机存放网页的根目录，如在/www目录下建立test1、test2、test3文件夹，其中分别存放1.html、2.html、3.html 123/www/test1/1.html/www/test2/2.html/www/test3/3.html 在httpd.conf中将附加配置文件httpd-vhosts.conf包含进来，接着在httpd-vhosts.conf中写入如下配置： 123456789101112131415161718192021222324252627282930&lt;VirtualHost 192.168.1.11:80&gt; ServerName www.test1.com DocumentRoot /www/test1/ &lt;Directory "/www/test1"&gt; options Indexes FollowSymLinks AllowOverride None Order allow,deny Allow From All &lt;/Directory&gt;&lt;/VirtualHost&gt;&lt;VirtualHost 192.168.1.12:80&gt; ServerName www.test1.com DocumentRoot /www/test2/ &lt;Directory "/www/test2"&gt; Options Indexes FollowSymLinks AllowOverride None Order allow,deny Allow From All &lt;/Directory&gt;&lt;/VirtualHost&gt;&lt;VirtualHost 192.168.1.13:80&gt; ServerName www.test1.com DocumentRoot /www/test3/ &lt;Directory "/www/test3"&gt; Options Indexes FollowSymLinks AllowOverride None Order allow,deny Allow From All &lt;/Directory&gt;&lt;/VirtualHost&gt; 大功告成，测试下每个虚拟主机，分别访问www.test1.com、www.test2.com、www.test3.com 二、基于主机名 设置域名映射同一个IP，修改hosts： 123192.168.1.10 www.test1.com192.168.1.10 www.test2.com192.168.1.10 www.test3.com 跟上面一样，建立虚拟主机存放网页的根目录 123/www/test1/1.html/www/test2/2.html/www/test3/3.html 在httpd.conf中将附加配置文件httpd-vhosts.conf包含进来，接着在httpd-vhosts.conf中写入如下配置： 为了使用基于域名的虚拟主机，必须指定服务器IP地址（和可能的端口）来使主机接受请求。可以用NameVirtualHost指令来进行配置。 如果服务器上所有的IP地址都会用到， 你可以用*作为NameVirtualHost的参数。在NameVirtualHost指令中指明IP地址并不会使服务器自动侦听那个IP地址。 这里设定的IP地址必须对应服务器上的一个网络接口。 下一步就是为你建立的每个虚拟主机设定配置块，的参数与NameVirtualHost指令的参数是一样的。每个定义块中，至少都会有一个ServerName指令来指定伺服哪个主机和一个DocumentRoot指令来说明这个主机的内容存在于文件系统的什么地方。 如果在现有的web服务器上增加虚拟主机，必须也为现存的主机建造一个定义块。其中ServerName和DocumentRoot所包含的内容应该与全局的保持一致，且要放在配置文件的最前面，扮演默认主机的角色。 1234567891011121314151617181920212223242526272829303132333435363738NameVirtualHost *:80&lt;VirtualHost *:80&gt; ServerName * DocumentRoot /www/ &lt;/VirtualHost&gt;#虚拟主机1&lt;VirtualHost *:80&gt; ServerName www.test1.com DocumentRoot /www/test1/ &lt;Directory "/www/test1"&gt; Options Indexes FollowSymLinks AllowOverride None Order allow,deny Allow from all &lt;/Directory&gt;&lt;/VirtualHost&gt; #虚拟主机2&lt;VirtualHost *:80&gt; ServerName www.test2.com DocumentRoot /www/test2/ &lt;Directory "/www/test2"&gt; Options Indexes FollowSymLinks AllowOverride None Order allow,deny Allow from all &lt;/Directory&gt;&lt;/VirtualHost&gt;#虚拟主机3&lt;VirtualHost *:80&gt; ServerName www.test3.com DocumentRoot /www/test3/ &lt;Directory "/www/test3"&gt; Options Indexes FollowSymLinks AllowOverride None Order allow,deny Allow from all &lt;/Directory&gt;&lt;/VirtualHost&gt; 大功告成，测试下每个虚拟主机，分别访问www.test1.com、www.test2.com、www.test3.com 三、基于端口 修改配置文件 将原来的Listen 80 改为Listen 80 Listen 8080 更改虚拟主机设置 123456789&lt;VirtualHost 192.168.1.10:80&gt; DocumentRoot /var/www/test1/ ServerName www.test1.com&lt;/VirtualHost&gt;#虚拟主机2&lt;VirtualHost 192.168.1.10:8080&gt; DocumentRoot /var/www/test2 ServerName www.test2.com&lt;/VirtualHost&gt; 验证即可]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[LAMP--CentOS-7平台三机FastCGI模型]]></title>
      <url>%2Fposts%2Fc3277995%2F</url>
      <content type="text"><![CDATA[需求1234CentOS-7平台上搭建LAMP，其中php作为独立的服务工作；(1) 三者分离于三台主机；(2) 一个虚拟主机用于提供phpMyAdmin；另一个虚拟主机用于提供wordpress；(3) 安装xcache，为php提供加速； 解析 由于CentOS-7平台提供了以上各应用的rpm安装包，且均包含了各应用的新特性，所以各应用程序可以直接使用yum源安装，而无需通过编译源码来安装。 xcache为EPEL源中提供的应用程序，因此需要配置启用EPEL源。 因为php要作为独立的服务单独运行于一台服务器上，因此不在是安装php，而是要安装php-fpm了。 httpd与php之间需要通过FastCGI协议来连接，httpd其实是作为作为反向代理来工作的，httpd中就需要加载mod_proxy和mod_proxy_fcgi模块了。 规划准备 准备两台CentOS-7主机，均为最小化安装。为避免安全设置影响实验结果，将iptables和SELinux均设置为关闭状态。 HostA作为前端Web服务器，IP地址为: 172.18.71.201。 HostB作为中间App服务器，IP地址为: 172.18.71.202。 HostC作为后端DB服务器，IP地址为: 172.18.71.203。 需要配置DNS服务，或者修改主机hosts文件来实现名称解析。 两台主机均需要配置好yum源，除发行版base源外还需要EPEL源。 配置名称解析和yum源不在本文介绍范围内，请参考其他资料。各程序安装包不提供，请自行下载。* 如图所示： 配置配置时一般习惯按照从后端到前端的顺序来进行，便于测试验证前一步配置，思路上也比较清晰，容易梳理。所以首先配置后端DB服务器HostC，然后配置中间App服务器HostB，最后配置后端Web服务器HostA。 HostC安装mariadb1[root@localhost ~]# yum instal -y mariadb-server 在默认配置基础上增加一些配置，包括设置默认字符集、默认字符排序、默认存储引擎、独立表空间、不做域名反解。12345678910111213[root@localhost ~]# vim /etc/my.cnf.d/client.cnf[client]default-character-set=utf8[root@localhost ~]# vim /etc/my.cnf.d/mysql-clients.cnf[mysql]default-character-set=utf8[root@localhost ~]# vim /etc/my.cnf.d/server.cnf[mysqld]character-set-server=utf8collation-server=utf8_general_cidefault-storage-engine=InnoDBinnodb-file-per-table=TRUEskip-name-resolve=TRUE 启动mariadb1[root@localhost ~]# systemctl start mariadb 初始化安全设置，主要这是设置root用户口令，删除匿名用户，不允许root远程登录，删除test数据库和访问test数据库的相关权限设置，重载权限表。 注：这里如果设置允许root远程登录，后面也还是要再次显式授权才可以。123456789101112131415[root@localhost ~]# mysql_secure_installationSet root password? [Y/n] yNew password:Re-enter new password:Remove anonymous users? [Y/n] y ... Success! Disallow root login remotely? [Y/n] y ... skipping. Remove test database and access to it? [Y/n] y - Dropping test database... ... Success! - Removing privileges on test database... ... Success! Reload privilege tables now? [Y/n] y ... Success! 登录mariadb，做以下设置。12345678910111213[root@localhost ~]# mysql -u root -p# 授权root可从172.18.71.0/24网段内的主机登录操作所有数据库。MariaDB [(none)]&gt; grant all privileges on *.* to 'root'@'172.18.71.%' identified by 'magedu';# 给wordpress创建数据wpdb。MariaDB [(none)]&gt; create database wpdb;# 给wordpress创建用户wp。MariaDB [(none)]&gt; create user 'wp'@'172.18.71.%' identified by 'magedu';# 授权wp可从172.18.71.0/24网段内的主机登录操作wpdb数据库。MariaDB [(none)]&gt; grant all privileges on wpdb.* to 'wp'@'172.18.71.%' identified by 'magedu';# 重载权限表MariaDB [(none)]&gt; flush privileges;# 退出MariaDB [(none)]&gt; \q 这样HostC就配置完成了，再来配置HostB。 HostB正式配置HostB之前，应首先验证以下HostC的配置，即测试一下能否从HostB上连接HostC的数据库。1234# 安装mariadb的客户端[root@localhost ~]# yum install -y mariadb# 测试连接HostB数据库[root@localhost ~]# mysql -u root -h 172.18.71.203 -p 安装php-fpm应用1[root@localhost ~]# yum install -y php-fpm php-mysql php-mbstring 修改php-fpm的连接池配置文件12345[root@localhost ~]# vim /etc/php-fpm.d/www.conf# 监听在本机的外部可访问地址上listen = 172.18.71.202:9000# 仅允许前端Web服务器连接listen.allowed_clients = 172.18.71.201 创建session存放目录，并修改其权限。12[root@localhost ~]# mkdir /var/lib/php/session[root@localhost ~]# chown -R apache:apache /var/lib/php/session 部署php程序代码phpMyAdmin和wordpress。 注：由于php-fpm是独立工作的服务，对于访问php页面的请求，前端的httpd仅作为反向代理将请求转发至php-fpm服务器上，由php-fpm找到对应的php程序代码文件进行解释执行，然后将结果返回给前端。所以需要将php程序代码放在php-fpm服务器上。 建立php程序相应的存放目录。1234[root@localhost ~]# mkdir -pv /htdocs/www.twoyang.&#123;com,net&#125;mkdir: created directory ‘/htdocs’mkdir: created directory ‘/htdocs/www.twoyang.com’mkdir: created directory ‘/htdocs/www.twoyang.net’ 将phpMyAdmin安装包放置在/htdocs/www.twoyang.com的目录下，并修改配置文件。1234567891011[root@localhost ~]# cd /htdocs/www.twoyang.com[root@localhost www.twoyang.com]# unzip phpMyAdmin-4.4.14.1-all-languages.zip[root@localhost www.twoyang.com]# ln -sv phpMyAdmin-4.4.14.1-all-languages pma‘pma’ -&gt; ‘phpMyAdmin-4.4.14.1-all-languages’[root@localhost www.twoyang.com]# cd pma[root@localhost pma]# cp config.sample.inc.php config.inc.php[root@localhost pma]# openssl rand -base64 200fkgcykLDfyRgG71FOjE9W6LKa8=[root@localhost pma]# vim config.inc.php$cfg['blowfish_secret'] = '0fkgcykLDfyRgG71FOjE9W6LKa8'; /* YOU MUST FILL IN THIS FOR COOKIE AUTH! */$cfg['Servers'][$i]['host'] = '172.18.71.203'; 将wordpress安装包放置在/htdocs/www.twoyang.com的目录下，并修改配置文件。12345678910111213141516171819[root@localhost ~]# cd /htdocs/www.twoyang.net[root@localhost www.twoyang.net]# unzip wordpress-4.3.1-zh_CN.zip[root@localhost www.twoyang.net]# ln -sv wordpress wp‘wp’ -&gt; ‘wordpress’[root@localhost www.twoyang.net]# cd wp[root@localhost wp]# cp wp-config-sample.php wp-config.php[root@localhost wp]# vim wp-config.php/** WordPress数据库的名称 */define('DB_NAME', 'wpdb');/** MySQL数据库用户名 */define('DB_USER', 'wp');/** MySQL数据库密码 */define('DB_PASSWORD', 'magedu');/** MySQL主机 */define('DB_HOST', '172.18.71.203'); 启动php-fpm服务1[root@localhost ~]# systemctl start php-fpm 查看php-fpm服务是否监听在指定套接字上12[root@localhost ~]# ss -tnl | grep 9000LISTEN 0 128 172.18.71.202:9000 *:* HostA安装httpd1[root@localhost ~]# yum install -y httpd 修改主配置文件123456789101112[root@localhost ~]# vim /etc/httpd/conf/httpd.conf# 设置服务器名，其实这项不设置也可以，但是启动服务时会有警告。ServerName www.twoyang.net# 由于准备使用虚拟主机，需要把MainServer的DocumentRoot关掉。#DocumentRoot "/var/www/html"# 另外需要增加php类型的主页和MIME&lt;IfModule dir_module&gt; DirectoryIndex index.php index.html&lt;/IfModule&gt;&lt;IfModule mime_module&gt; AddType application/x-httpd-php .php&lt;/IfModule&gt; 移除欢迎页面配置文件1[root@localhost ~]# mv /etc/httpd/conf.d/welcome.conf&#123;,.bak&#125; 新建虚拟主机配置文件/etc/httpd/conf.d/vhosts.conf1234567891011121314151617181920212223242526272829[root@localhost ~]# vim /etc/httpd/conf.d/vhosts.conf&lt;VirtualHost 172.18.71.201:80&gt; ServerName www.twoyang.com DocumentRoot "/htdocs/www.twoyang.com/pma" &lt;Directory "/htdocs/www.twoyang.com/pma"&gt; OPTIONS FollowSymLinks AllowOverride None Require all granted &lt;/Directory&gt; # 由于正向代理和反向代理不能同时存在，这里关闭正向代理。 ProxyRequests Off # 将直接访问/的url请求，通过fcgi协议指向后端php-fpm服务器对应目录的index.php。 ProxyPassMatch ^/$ fcgi://172.18.71.202:9000/htdocs/www.twoyang.com/pma/index.php # 将访问以.php结尾的url请求，通过fcgi协议指向后端php-fpm服务器对应目录的对应文件。 ProxyPassMatch ^/(.*\.php)$ fcgi://172.18.71.202:9000/htdocs/www.twoyang.com/pma/$1&lt;/VirtualHost&gt;&lt;VirtualHost 172.18.71.201:80&gt; ServerName www.twoyang.net DocumentRoot "/htdocs/www.twoyang.net/wp" &lt;Directory "/htdocs/www.twoyang.net/wp"&gt; OPTIONS FollowSymLinks AllowOverride None Require all granted &lt;/Directory&gt; ProxyRequests Off ProxyPassMatch ^/$ fcgi://172.18.71.202:9000/htdocs/www.twoyang.net/wp/index.php ProxyPassMatch ^/(.*\.php)$ fcgi://172.18.71.202:9000/htdocs/www.twoyang.net/wp/$1&lt;/VirtualHost&gt; 建立虚拟主机DocumentRoot对应的目录。1234[root@localhost ~]# mkdir -pv /htdocs/www.twoyang.&#123;com,net&#125;mkdir: created directory ‘/htdocs’mkdir: created directory ‘/htdocs/www.twoyang.com/’mkdir: created directory ‘/htdocs/www.twoyang.net/’ 将phpMyAdmin安装包放置在虚拟主机www.twoyang.com的DocumentRoot目录下。1234[root@localhost ~]# cd /htdocs/www.twoyang.com[root@localhost www.twoyang.com]# unzip phpMyAdmin-4.4.14.1-all-languages.zip[root@localhost www.twoyang.com]# ln -sv phpMyAdmin-4.4.14.1-all-languages pma‘pma’ -&gt; ‘phpMyAdmin-4.4.14.1-all-languages’ 将wordpress安装包放置在虚拟主机www.twoyang.net的DocumentRoot目录下。1234[root@localhost ~]# cd /htdocs/www.twoyang.net[root@localhost www.twoyang.net]# unzip wordpress-4.3.1-zh_CN.zip[root@localhost www.twoyang.net]# ln -sv wordpress wp‘wp’ -&gt; ‘wordpress’ 注: 这里将phpMyAdmin和wordpress安装包在HostA上重新部署一次，是因为httpd仅将有关php的请求转发至php-fpm服务器去处理。而事实上一个完整页面当中还存在图片等静态内容，这些内容是不会转发的，还是要在本地的DocumentRoot目录中去找。 这么做以后，在HostA上的虚拟机DocumentRoot目录就会存在无用的php程序代码文件占用磁盘，可以将其删除。1234[root@localhost ~]# cd /htdocs/www.twoyang.com/pma[root@localhost pma]# find . -name "*.php" | xargs rm -rf[root@localhost ~]# cd /htdocs/www.twoyang.com/wp[root@localhost wp]# find . -name "*.php" | xargs rm -rf 你可以跳过在HostA上部署phpMyAdmin和wordpress安装包的步骤来验证以上结论，可预期的结果是一些页面当中的图片链接无法显示。 启动httpd服务，修改一下/htdocs目录的属主和属组，以免出现权限问题。1[root@localhost ~]# chown -R apache:apache /htdocs 这时便可以启动httpd服务，测试访问phpMyAdmin和wordpress了。1[root@localhost ~]# systemctl start httpd xcache但是这个时候还是没有安装xcache的，可以用ab测试一下并发访问时服务器响应情况。1[root@localhost ~]# ab -n 1000 -c 100 http://www.twoyang.com/ 这时在HostB上安装xcache和php-cli（后者提供php命令行工具，可查看当前加载的php模块有哪些）。1[root@localhost ~]# yum install -y php-xcache php-cli 修改xcache配置文件，打开xcache.cacher开关。12[root@localhost ~]# vim /etc/php.d/xcache.inixcache.cacher = On 重启服务注意因为此时php是作为独立服务来工作的，因此需要重启HostB上的php-fpm服务。12345678910[root@localhost ~]# systemctl restart php-fpm[root@localhost ~]# php -m | grep XCacheXCacheXCache CacherXCache CoveragerXCache OptimizerXCacheXCache CacherXCache CoveragerXCache Optimizer 再次使用ab测试1[root@localhost ~]# ab -n 1000 -c 100 http://www.twoyang.com/ 注：本文转载自:twoyang.net]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[PHP的三种工作方式]]></title>
      <url>%2Fposts%2F7997f177%2F</url>
      <content type="text"><![CDATA[1.CGI（Common Gateway Interface） CGI即通用网关接口(Common Gateway Interface)，它是一段程序, 通俗的讲CGI就象是一座桥，把网页和WEB服务器中的执行程序连接起来，它把HTML接收的指令传递给服务器的执行程序，再把服务器执行程序的结果返还给HTML页。 CGI 的跨平台性能极佳，几乎可以在任何操作系统上实现。CGI已经是比较老的模式了，这几年都很少用了。每有一个用户请求，都会先要创建cgi的子进程，然后处理请求，处理完后结束这个子进程，这就是fork-and-execute模式。 当用户请求数量非常多时，会大量挤占系统的资源如内存，CPU时间等，造成效能低下。所以用cgi方式的服务器有多少连接请求就会有多少cgi子进程，子进程反复加载是cgi性能低下的主要原因。如果不想把 PHP 嵌入到服务器端软件（如 Apache）作为一个模块安装的话，可以选择以 CGI 的模式安装。或者把 PHP 用于不同的 CGI 封装以便为代码创建安全的 chroot 和 setuid 环境。这样每个客户机请求一个php文件，Web服务器就调用php.exe（win下是php.exe,linux是php）去解释这个文件，然后再把解释的结果以网页的形式返回给客户机。 这种安装方式通常会把 PHP 的可执行文件安装到 web 服务器的 cgi-bin 目录。CERT 建议书 CA-96.11 建议不要把任何的解释器放到 cgi-bin 目录。CGI已经是比较老的模式了，这几年都很少用了 php运行原理 2.Fastcgi模式fastcgi工作方式 ast-cgi 是cgi的升级版本，FastCGI 像是一个常驻 (long-live) 型的 CGI，它可以一直执行着，只要激活后，不会每次都要花费时间去 fork 一次 (这是 CGI 最为人诟病的 fork-and-execute 模式)。 FastCGI的工作原理是： Web Server启动时载入FastCGI进程管理器【PHP的FastCGI进程管理器是PHP-FPM(php-FastCGI Process Manager)】（IIS ISAPI或Apache Module); FastCGI进程管理器自身初始化，启动多个CGI解释器进程 (在任务管理器中可见多个php-cgi.exe)并等待来自Web Server的连接。 当客户端请求到达Web Server时，FastCGI进程管理器选择并连接到一个CGI解释器。Web server将CGI环境变量和标准输入发送到FastCGI子进程php-cgi。 FastCGI子进程完成处理后将标准输出和错误信息从同一连接返回Web Server。当FastCGI子进程关闭连接时，请求便告处理完成。FastCGI子进程接着等待并处理来自FastCGI进程管理器（运行在 WebServer中）的下一个连接。在正常的CGI模式中，php-cgi.exe在此便退出了。 在CGI模式中，你可以想象 CGI通常有多慢。每一个Web请求PHP都必须重新解析php.ini、重新载入全部dll扩展并重初始化全部数据结构。使用FastCGI，所有这些都只在进程启动时发生一次。一个额外的好处是，持续数据库连接(Persistent database connection)可以工作。 Fastcgi的优点： 1）从稳定性上看, fastcgi是以独立的进程池运行来cgi,单独一个进程死掉,系统可以很轻易的丢弃,然后重新分 配新的进程来运行逻辑.2）从安全性上看,Fastcgi支持分布式运算. fastcgi和宿主的server完全独立, fastcgi怎么down也不会把server搞垮.3）从性能上看, fastcgi把动态逻辑的处理从server中分离出来, 大负荷的IO处理还是留给宿主server, 这样宿主server可以一心一意作IO,对于一个普通的动态网页来说, 逻辑处理可能只有一小部分, 大量的图片等静态 FastCGI缺点： 说完了好处，也来说说缺点。从我的实际使用来看，用FastCGI模式更适合生产环境的服务器。但对于开发用机器来说就不太合适。因为当使用 Zend Studio调试程序时，由于 FastCGI会认为PHP进程超时，从而在页面返回 500错误。这一点让人非常恼火 模块模式 模块模式是以mod_php5模块的形式集成，此时mod_php5模块的作用是接收Apache传递过来的PHP文件请求，并处理这些请求，然后将处理后的结果返回给Apache。如果我们在Apache启动前在其配置文件中配置好了PHP模块（mod_php5）， PHP模块通过注册apache2的ap_hook_post_config挂钩，在Apache启动的时候启动此模块以接受PHP文件的请求。除了这种启动时的加载方式，Apache的模块可以在运行的时候动态装载，这意味着对服务器可以进行功能扩展而不需要重新对源代码进行编译，甚至根本不需要停止服务器。我们所需要做的仅仅是给服务器发送信号HUP或者AP_SIG_GRACEFUL通知服务器重新载入模块。但是在动态加载之前，我们需要将模块编译成为动态链接库。此时的动态加载就是加载动态链接库。 Apache中对动态链接库的处理是通过模块mod_so来完成的，因此mod_so模块不能被动态加载，它只能被静态编译进Apache的核心。这意味着它是随着Apache一起启动的。 Apache是如何加载模块的呢？我们以前面提到的mod_php5模块为例。首先我们需要在Apache的配置文件httpd.conf中添加一行： 该运行模式是我们以前在windows环境下使用apache服务器经常使用的，而在模块化(DLL)中，PHP是与Web服务器一起启动并运行的。（是apache在CGI的基础上进行的一种扩展，加快PHP的运行效率）LoadModule php5_module modules/mod_php5.so 这里我们使用了LoadModule命令，该命令的第一个参数是模块的名称，名称可以在模块实现的源码中找到。第二个选项是该模块所处的路径。如果需要在服务器运行时加载模块，可以通过发送信号HUP或者AP_SIG_GRACEFUL给服务器，一旦接受到该信号，Apache将重新装载模块，而不需要重新启动服务器。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx性能优化技巧]]></title>
      <url>%2Fposts%2F1aabbb95%2F</url>
      <content type="text"><![CDATA[一、编译安装过程优化1、减小Nginx编译后的文件大小 在编译nginx时，默认以debug模式进行，而在debug的模式下会插入很多跟踪和ASSERT之类的信息，编译完成后，一个nginx要有好几兆字节，而编译之前取消debug模式，编译完成之后只有几百千字节，因此，在编译之前，修改相关源码：在解压nginx源码文件后，找到源码目录下的auto/cc/gcc文件。打开然后在其中找到如下几行：123#debugCFLAGS="$CFLAGS -g"注释或者删掉这两行。 2、为特定的CPU指定CPU类型编译优化 在编译nginx时，默认的GCC编译参数是”-O”，要优化GCC编译，可以使用以下两个参数： 12345--with-cc-opt='-o3'--with-cpu-opt=CPU #为特定的CPU编译，有效的值包括：pentium、pentiumpro、pentium3、pentium4、athlon、opteron、amd64、sparc32、sparc64、ppc64要确定CPU类型，可以通过如下命令实现：cat /proc/cpuinfo |grep "model name" 二、利用TCMalloc优化Nginx的性能 为了Nginx支持Tcmalloc，需要在安装的过程中添加–with-google_perftools_module，其他都一样。在安装完成之后，需要对配置文档做相应的一些配置，否则Nginx默认不会启用Tcmalloc。具体的配置如下： 1234567# mkdir /tmp/tcmalloc# chown -R www.www /tmp/tcmalloc# vim nginx.conf···pid logs/nginx.pid;google_perftools_profiles /tmp/tcmalloc/;··· 检查Nginx是否使用Tcmalloc的命令可以使用：1lsof | grep tcmalloc 三、Nginx内核参数优化 Nginx内核参数的优化主要是在Linux系统中针对Nginx应用而进行的系统内核参数优化。下面给出的一个优化实例以供参考： 1234567net.ipv4.tcp_max_tw_buckets = 6000net.ipv4.ip_local_port_range = 1024 65000net.ipv4.tcp_tw_recyle = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_syncookies = 1net.core.somaxconn = 262144net.core.netdev_max_backlog = 262144]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[nginx反向代理、负载均衡、页面缓存、URL重写及读写分离]]></title>
      <url>%2Fposts%2Fa7ce75d9%2F</url>
      <content type="text"><![CDATA[官网下载： http://nginx.org/download/nginx-1.8.1.tar.gz 一、安装nginx时必须先安装相应的编译工具1~]# yum -y install pcre-devel openssl-devel zlib-devel 建立nginx 组123~]# groupadd -r nginx~]# useradd -s /sbin/nologin -g nginx -r nginx~]# id nginx zlib:nginx提供gzip模块，需要zlib库支持 openssl:nginx提供ssl功能 pcre:支持地址重写rewrite功能 二、解压1tar -zxvf nginx-1.8.1.tar.gz 三、进入目录1cd nginx-1.8.1 四、配置12345678910111213141516171819202122232425262728293031323334~]# ./configure \--prefix=/usr/local--sbin-path=/usr/sbin/nginx--conf-path=/etc/nginx/nginx.conf--error-log-path=/var/log/nginx/error.log--http-log-path=/var/log/nginx/access.log--pid-path=/var/run/nginx.pid--lock-path=/var/run/nginx.lock--http-client-body-temp-path=/var/cache/nginx/client_temp--http-proxy-temp-path=/var/cache/nginx/proxy_temp--http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp--http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp--http-scgi-temp-path=/var/cache/nginx/scgi_temp--user=nginx--group=nginx--with-http_ssl_module--with-http_realip_module--with-http_addition_module--with-http_sub_module--with-http_dav_module--with-http_flv_module--with-http_mp4_module--with-http_gunzip_module--with-http_gzip_static_module--with-http_random_index_module--with-http_secure_link_module--with-http_stub_status_module--with-http_auth_request_module--with-threads--with-stream--with-stream_ssl_module--with-http_slice_module--with-file-aio--with-http_v2_module 五、编译&amp;&amp;安装1make &amp;&amp; make install 六、配置反向代理(proxy_pass模块) apache服务器：172.18.1.49nginx服务器：172.18.1.180 123456vim /etc/nginx/nginx.conf#添加此locationlocation / &#123; proxy_pass http://172.18.1.49; proxy_set_header X-Real-IP $remote_addr; #显示客户机真实IP &#125; 注，大家可以看到日志记录的还是代理的IP，没有显示真实客户端的IP，需要修改一下httpd的配置文件。 查看并修改httpd配置文件[root@web1 ~]# vim /etc/httpd/conf/httpd.conf1234567891011#注，大家可以这里记录日志的参数还是%h，下面我们修改一下参数。LogFormat "%h %l %u %t \"%r\" %&gt;s %b \"%&#123;Referer&#125;i\" \"%&#123;User-Agent&#125;i\"" combinedLogFormat "%h %l %u %t \"%r\" %&gt;s %b" commonLogFormat "%&#123;Referer&#125;i -&gt; %U" refererLogFormat "%&#123;User-agent&#125;i" agent#修改为：LogFormat "%&#123;X-Real-IP&#125;i %l %u %t \"%r\" %&gt;s %b \"%&#123;Referer&#125;i\" \"%&#123;User-Agent&#125;i\"" combinedLogFormat "%h %l %u %t \"%r\" %&gt;s %b" commonLogFormat "%&#123;Referer&#125;i -&gt; %U" refererLogFormat "%&#123;User-agent&#125;i" agent 注，这是修改后的参数，将h%修改为%{X-Real-IP}i，好的下面我们再来测试一下。 七、添加upstream实现负载均衡 upstream支持的负载均衡算法： 轮询(默认):可指定weight权重 ip_hash:来自同一个IP的发往固定的后端主机 fair:根据后端服务器的响应时间分配请求 url_hash:使url定向到同一个后端服务器 配置nginx负载均衡1234567891011121314#vim /etc/nginx/nginx.confupstream webservers &#123; server 192.168.18.201 weight=1; server 192.168.18.202 weight=1; &#125; server &#123; listen 80; server_name localhost; location / &#123; proxy_pass http://webservers; proxy_set_header X-Real-IP $remote_addr; &#125;&#125; 注，upstream是定义在server{ }之外的，不能定义在server{ }内部。定义好upstream之后，用proxy_pass引用一下即可。 八、配置nginx对健康状态进行检查12345[root@nginx ~]# vim /etc/nginx/nginx.confupstream webservers &#123; server 192.168.18.201 weight=1 max_fails=2 fail_timeout=2; server 192.168.18.202 weight=1 max_fails=2 fail_timeout=2; &#125; 重载配置1234[root@nginx ~]# service nginx reloadnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful重新载入 nginx： 九、配置sorrysever 如果不幸的是后端所有服务器都不能提供服务了怎么办，用户打开页面就会出现出错页面，那么会带来用户体验的降低，所以我们能不能像配置LVS是配置sorry_server呢，答案是可以的，但这里不是配置sorry_server而是配置backup。 123456789101112131415root@nginx ~]# vim /etc/nginx/nginx.confserver &#123; listen 8080; server_name localhost; root /data/www/errorpage; index index.html; &#125;upstream webservers &#123; server 192.168.18.201 weight=1 max_fails=2 fail_timeout=2; server 192.168.18.202 weight=1 max_fails=2 fail_timeout=2; server 127.0.0.1:8080 backup; &#125;[root@nginx ~]# mkdir -pv /data/www/errorpage[root@nginx errorpage]# cat index.html&lt;h1&gt;Sorry......&lt;/h1&gt; 十、Nginx之页面缓存1.指令说明 proxy_cache_path 语法：proxy_cache_path path [levels=number] keys_zone=zone_name:zone_size [inactive=time] [max_size=size];默认值：None使用字段：http 指令指定缓存的路径和一些其他参数，缓存的数据存储在文件中，并且使用代理url的哈希值作为关键字与文件名。levels参数指定缓存的子目录数，例如： 1proxy_cache_path /data/nginx/cache levels=1:2 keys_zone=one:10m; 文件名类似于： 1/data/nginx/cache/c/29/b7f54b2df7773722d382f4809d65029c levels指定目录结构，可以使用任意的1位或2位数字作为目录结构，如 X, X:X,或X:X:X 例如: “2”, “2:2”, “1:1:2“，但是最多只能是三级目录。所有活动的key和元数据存储在共享的内存池中，这个区域用keys_zone参数指定。one指的是共享池的名称，10m指的是共享池的大小。 注意每一个定义的内存池必须是不重复的路径，例如： 123proxy_cache_path /data/nginx/cache/one levels=1 keys_zone=one:10m;proxy_cache_path /data/nginx/cache/two levels=2:2 keys_zone=two:100m;proxy_cache_path /data/nginx/cache/three levels=1:1:2 keys_zone=three:1000m; 如果在inactive参数指定的时间内缓存的数据没有被请求则被删除，默认inactive为10分钟。一个名为cache manager的进程控制磁盘的缓存大小，它被用来删除不活动的缓存和控制缓存大小，这些都在max_size参数中定义，当目前缓存的值超出max_size指定的值之后，超过其大小后最少使用数据（LRU替换算法）将被删除。内存池的大小按照缓存页面数的比例进行设置，一个页面（文件）的元数据大小按照操作系统来定，如FreeBSD/i386下为64字节，FreeBSD/amd64下为128字节。 proxy_cache语法：proxy_cache zone_name;默认值：None使用字段：http, server, location 设置一个缓存区域的名称，一个相同的区域可以在不同的地方使用。在0.7.48后，缓存遵循后端的”Expires”, “Cache-Control: no-cache”, “Cache-Control: max-age=XXX”头部字段，0.7.66版本以后，”Cache-Control:“private”和”no-store”头同样被遵循。nginx在缓存过程中不会处理”Vary”头，为了确保一些私有数据不被所有的用户看到，后端必须设置 “no-cache”或者”max-age=0”头，或者proxy_cache_key包含用户指定的数据如$cookie_xxx，使用cookie的值作为proxy_cache_key的一部分可以防止缓存私有数据，所以可以在不同的location中分别指定proxy_cache_key的值以便分开私有数据和公有数据。缓存指令依赖代理缓冲区(buffers)，如果proxy_buffers设置为off，缓存不会生效。 proxy_cache_valid 语法：proxy_cache_valid reply_code [reply_code …] time;默认值：None使用字段：http, server, location为不同的应答设置不同的缓存时间，例如： 12proxy_cache_valid 200 302 10m;proxy_cache_valid 404 1m; 为应答代码为200和302的设置缓存时间为10分钟，404代码缓存1分钟。如果只定义时间： 1proxy_cache_valid 5m; 那么只对代码为200, 301和302的应答进行缓存。同样可以使用any参数任何应答。 123proxy_cache_valid 200 302 10m;proxy_cache_valid 301 1h;proxy_cache_valid any 1m; 定义一个简单nginx缓存服务器1234567891011121314[root@nginx ~]# vim /etc/nginx/nginx.confproxy_cache_path /data/nginx/cache/webserver levels=1:2 keys_zone=webserver:20m max_size=1g; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; proxy_pass http://webservers; proxy_set_header X-Real-IP $remote_addr; proxy_cache webserver; proxy_cache_valid 200 10m; &#125;&#125; 新建缓存目录1[root@nginx ~]# mkdir -pv /data/nginx/cache/webserver 重新加载一下配置文件1234[root@nginx webserver]# service nginx reloadnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful重新载入 nginx： [确定] 缓存变量说明$server_addr 服务器地址，在完成一次系统调用后可以确定这个值，如果要绕开系统调用，则必须在listen中指定地址并且使用bind参数。 $upstream_cache_status 0.8.3版本中其值可能为： MISS 未命中 EXPIRED expired。请求被传送到后端。 UPDATING expired。由于proxy/fastcgi_cache_use_stale正在更新，将使用旧的应答。 STALE expired。由于proxy/fastcgi_cache_use_stale，后端将得到过期的应答。 HIT 命中 1234567891011121314151617[root@nginx ~]# vim /etc/nginx/nginx.confproxy_cache_path /data/nginx/cache/webserver levels=1:2 keys_zone=webserver:20m max_size=1g; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; #增加两头部 add_header X-Via $server_addr; add_header X-Cache $upstream_cache_status; location / &#123; proxy_pass http://webservers; proxy_set_header X-Real-IP $remote_addr; proxy_cache webserver; proxy_cache_valid 200 10m; &#125;&#125; 重新加载一下配置文件1234[root@nginx ~]# service nginx reloadnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful重新载入 nginx： [确定] 浏览器开调试模式，选择Network选项，我们可以看到，Response Headers，在这里我们可以看到，我们请求的是否是缓存 Nginx之URL重写1.URL重写模块（Rewrite） 摘要这个模块允许使用正则表达式重写URI（需PCRE库），并且可以根据相关变量重定向和选择不同的配置。如果这个指令在server字段中指定，那么将在被请求的location确定之前执行，如果在指令执行后所选择的location中有其他的重写规则，那么它们也被执行。如果在location中执行这个指令产生了新的URI，那么location又一次确定了新的URI。这样的循环可以最多执行10次，超过以后nginx将返回500错误。 指令break 语法：break 默认值：none 使用字段：server, location, if 完成当前设置的规则，停止执行其他的重写指令。示例： 1234if ($slow) &#123; limit_rate 10k; break;&#125; if 语法：if (condition) { … } 默认值：none 使用字段：server, location 注意：在使用if指令之前请查看if is evil page并且尽量考虑用try_files代替。判断一个条件，如果条件成立，则后面的大括号内的语句将执行，相关配置从上级继承。可以在判断语句中指定下列值： 一个变量的名称；不成立的值为：空字符传”“或者一些用“0”开始的字符串。 一个使用=或者!=运算符的比较语句。 使用符号~*和~模式匹配的正则表达式： ~为区分大小写的匹配。 ~*不区分大小写的匹配（firefox匹配FireFox）。 !~和!~*意为“不匹配的”。 使用-f和!-f检查一个文件是否存在。 使用-d和!-d检查一个目录是否存在。 使用-e和!-e检查一个文件，目录或者软链接是否存在。 使用-x和!-x检查一个文件是否为可执行文件。 正则表达式的一部分可以用圆括号，方便之后按照顺序用$1-$9来引用。 示例配置：12345678910111213141516171819202122232425262728if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break;&#125; if ($http_cookie ~* "id=([^;] +)(?:;|$)" ) &#123; set $id $1;&#125; if ($request_method = POST ) &#123; return 405;&#125; if (!-f $request_filename) &#123; break; proxy_pass http://127.0.0.1;&#125; if ($slow) &#123; limit_rate 10k;&#125; if ($invalid_referer) &#123; return 403;&#125; if ($args ~ post=140)&#123; rewrite ^ http://example.com/ permanent;&#125; 内置变量$invalid_referer用指令valid_referers指定。 return 语法：return code 默认值：none 使用字段：server, location, if 这个指令结束执行配置语句并为客户端返回状态代码，可以使用下列的值：204，400，402-406，408，410, 411, 413, 416与500-504。此外，非标准代码444将关闭连接并且不发送任何的头部。 rewrite 语法：rewrite regex replacement flag 默认值：none 使用字段：server, location, if 按照相关的正则表达式与字符串修改URI，指令按照在配置文件中出现的顺序执行。可以在重写指令后面添加标记。如果替换的字符串以http://开头，请求将被重定向，并且不再执行多余的rewrite指令。 尾部的标记(flag)可以是以下的值： last 完成重写指令，之后搜索相应的URI或location。 break 完成重写指令。 redirect 返回302临时重定向，如果替换字段用http://开头则被使用。 permanent 返回301永久重定向。 注意如果一个重定向是相对的（没有主机名部分），nginx将在重定向的过程中使用匹配server_name指令的“Host”头或者server_name指令指定的第一个名称，如果头不匹配或不存在，如果没有设置server_name，将使用本地主机名，如果你总是想让nginx使用“Host”头，可以在server_name使用“*”通配符（查看http核心模块中的server_name）。例如： 123rewrite ^(/download/.*)/media/(.*)\..*$ $1/mp3/$2.mp3 last;rewrite ^(/download/.*)/audio/(.*)\..*$ $1/mp3/$2.ra last;return 403; 但是如果我们将其放入一个名为/download/的location中，则需要将last标记改为break，否则nginx将执行10次循环并返回500错误。 12345location /download/ &#123; rewrite ^(/download/.*)/media/(.*)\..*$ $1/mp3/$2.mp3 break; rewrite ^(/download/.*)/audio/(.*)\..*$ $1/mp3/$2.ra break; return 403;&#125; 如果替换字段中包含参数，那么其余的请求参数将附加到后面，为了防止附加，可以在最后一个字符后面跟一个问号：1rewrite ^/users/(.*)$ /show?user=$1? last; 注意：大括号（{和}），可以同时用在正则表达式和配置块中，为了防止冲突，正则表达式使用大括号需要用双引号（或者单引号）。例如要重写以下的URL：1/photos/123456 为:1/path/to/photos/12/1234/123456.png 则使用以下正则表达式（注意引号）：1rewrite "/photos/([0-9] &#123;2&#125;)([0-9] &#123;2&#125;)([0-9] &#123;2&#125;)" /path/to/photos/$1/$1$2/$1$2$3.png; 如果指定一个“？”在重写的结尾，Nginx将丢弃请求中的参数，即变量$args，当使用$request_uri或$uri&amp;$args时可以在rewrite结尾使用“？”以避免nginx处理两次参数串。在rewrite中使用$request_uri将www.example.com重写到example.com： 1234server &#123; server_name www.example.com; rewrite ^ http://example.com$request_uri? permanent;&#125; 同样，重写只对路径进行操作，而不是参数，如果要重写一个带参数的URL，可以使用以下代替： 123if ($args ^~ post=100)&#123; rewrite ^ http://example.com/new-address.html? permanent;&#125; 注意$args变量不会被编译，与location过程中的URI不同（参考http核心模块中的location）。 rewrite_log 语法：rewrite_log on | off 默认值：rewrite_log off 使用字段：server, location, if 变量：无 启用时将在error log中记录notice 标记的重写日志。set 语法：set variable value 默认值：none 使用字段：server, location, if 指令设置一个变量并为其赋值，其值可以是文本，变量和它们的组合。可以使用set定义一个新的变量，但是不能使用set设置$http_xxx头部变量的值。 uninitialized_variable_warn 语法：uninitialized_variable_warn on|off 默认值：uninitialized_variable_warn on 使用字段：http, server, location, if 开启或关闭在未初始化变量中记录警告日志。 事实上，rewrite指令在配置文件加载时已经编译到内部代码中，在解释器产生请求时使用。 这个解释器是一个简单的堆栈虚拟机，如下列指令： 12345678location /download/ &#123; if ($forbidden) &#123; return 403; &#125; if ($slow) &#123; limit_rate 10k; &#125; rewrite ^/(download/.*)/media/(.*)\..*$ /$1/mp3/$2.mp3 break; 将被编译成以下顺序： 1234567891011121314variable $forbiddenchecking to zerorecovery 403completion of entire codevariable $slowchecking to zerocheckings of regular excodessioncopying "/"copying $1copying "/mp3/"copying $2copying ".mp3"completion of regular excodessioncompletion of entire sequence 注意并没有关于limit_rate的代码，因为它没有提及ngx_http_rewrite_module模块，“if”块可以类似”location”指令在配置文件的相同部分同时存在。如果$slow为真，对应的if块将生效，在这个配置中limit_rate的值为10k。 指令：1rewrite ^/(download/.*)/media/(.*)\..*$ /$1/mp3/$2.mp3 break; 如果我们将第一个斜杠括入圆括号，则可以减少执行顺序：1rewrite ^(/download/.*)/media/(.*)\..*$ $1/mp3/$2.mp3 break; 之后的顺序类似如下：1234567checking regular excodessioncopying $1copying "/mp3/"copying $2copying ".mp3"completion of regular excodessioncompletion of entire code 2.简单案例 注，由于配置文件内容较多，为了让大家看着方便，我们备份一下配置文件，打开一个新的配置文件。 123456789101112131415[root@nginx ~]# cd /etc/nginx/[root@nginx nginx]# mv nginx.conf nginx.conf.proxy[root@nginx nginx]# cp nginx.conf.bak nginx.conf[root@nginx nginx]# vim /etc/nginx/nginx.confserver &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; rewrite ^/bbs/(.*)$ http://192.168.18.201/forum/$1; &#125;&#125; 准备forum目录与测试文件 1234567[root@web1 ~]# cd /var/www/html/[root@web1 html]# lsindex.html[root@web1 html]# mkdir forum[root@web1 html]# cd forum/[root@web1 forum]# vim index.html&lt;h1&gt;forum page!&lt;/h1&gt; 测试一下 下面我们来测试一下rewrite重写。 3.重新加载一下配置文件1234[root@nginx 63]# service nginx reloadnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful重新载入 nginx： [确定] 4.测试一下 注，大家可以从图中看出，status code 302指的是临时重定向，那就说明我们rewrite重写配置成功。大家知道302是临时重定向而301是永久重定向，那么怎么实现永久重定向呢。一般服务器与服务器之间是临时重定向，服务器内部是永久重定向。下面我们来演示一下永久重定向 5.配置永久重定向123456789101112[root@nginx nginx]# vim /etc/nginx/nginx.confserver &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; rewrite ^/bbs/(.*)$ /forum/$1; &#125;&#125; 准备forum目录与测试文件 1234567[root@nginx ~]# cd /usr/html/[root@nginx html]# ls50x.html index.html[root@nginx html]# mkdir forum[root@nginx html]# cd forum/[root@nginx forum]# vim index.html&lt;h1&gt;192.168.18.208 forum page&lt;/h1&gt; 6.重新加载一下配置文件 123456789101112131415161718192021222324252627[root@nginx ~]# service nginx reloadnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful重新载入 nginx： [确定]``` 7.测试一下![](http://img1.51cto.com/attachment/201309/4/2033581_1378277141NTPi.png)&gt; 注，大家从图中可以看到，我们访问bbs/是直接帮我们跳转到forum/下，这种本机的跳转就是永久重定向也叫隐式重定向。好了，rewrite重定向我们就说到这里了，想要查询更多关于重定向的指令请参考官方文档。最后，我们来说一下读写分离。## 十二、Nginx读写分离### 1.实验拓扑![](http://img1.51cto.com/attachment/201309/4/2033581_1378277142c7NS.png)&gt; 需求分析，前端一台nginx做负载均衡反向代理，后面两台httpd服务器。整个架构是提供BBS(论坛)服务，有一需求得实现读写分离，就是上传附件的功能，我们上传的附件只能上传到Web1，然后在Web1上利用rsync+inotify实现附件同步，大家都知道rsync+inotify只能是主向从同步，不能双向同步。所以Web1可进行写操作，而Web2只能进行读操作，这就带来读写分离的需求，下面我们就来说一下，读写分离怎么实现。### 2.WebDAV功能说明&gt; WebDAV （Web-based Distributed Authoring and Versioning） 一种基于 HTTP 1.1协议的通信协议。它扩展了HTTP 1.1，在GET、POST、HEAD等几个HTTP标准方法以外添加了一些新的方法，使应用程序可直接对Web Server直接读写，并支持写文件锁定(Locking)及解锁(Unlock)，还可以支持文件的版本控制。这样我们就能配置读写分离功能了，下面我们来具体配置一下。### 3.修改配置文件 [root@nginx nginx]# vim /etc/nginx/nginx.confserver { listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { proxy_pass http://192.168.18.202; if ($request_method = &quot;PUT&quot;){ proxy_pass http://192.168.18.201; } } }12### 4.重新加载一下配置文件 [root@nginx ~]# service nginx reloadnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful重新载入 nginx： [确定]12### 5.配置httpd的WebDAV功能 [root@web1 ~]# vim /etc/httpd/conf/httpd.conf1234567![](http://img1.51cto.com/attachment/201309/4/2033581_1378277143SBSg.png)&gt; 注，在&lt;Directory "/var/www/html"&gt;下启用就行。### 6.重新启动一下httpd [root@web1 ~]# service httpd restart停止 httpd： [确定]正在启动 httpd： [确定]12### 7.测试一下 [root@nginx ~]# curl http://192.168.18.201 web1.test.com[root@nginx ~]# curl http://192.168.18.202 web2.test.com12&gt; 注，web1与web2访问都没问题。 [root@nginx ~]# curl -T /etc/issue http://192.168.18.202&lt;!DOCTYPE HTML PUBLIC “-//IETF//DTD HTML 2.0//EN”&gt; 405 Method Not Allowed Method Not AllowedThe requested method PUT is not allowed for the URL /issue. Apache/2.2.15 (CentOS) Server at 192.168.18.202 Port 8012&gt; 注，我们上传文件到，web2上时，因为web2只人读功能，所以没有开户WebDAV功能，所以显示是405 Method Not Allowed。 [root@nginx ~]# curl -T /etc/issue http://192.168.18.201&lt;!DOCTYPE HTML PUBLIC “-//IETF//DTD HTML 2.0//EN”&gt; 403 Forbidden ForbiddenYou don’t have permission to access /issueon this server. Apache/2.2.15 (CentOS) Server at 192.168.18.201 Port 8012&gt; 注，我们在Web1开启了WebDAV功能，但我们目录是root目录是不允许apache用户上传的，所以显示的是403 Forbidden。下面我们给apache授权，允许上传。 [root@web1 ~]# setfacl -m u:apache:rwx /var/www/html/1下面我们再来测试一下， [root@nginx ~]# curl -T /etc/issue http://192.168.18.201&lt;!DOCTYPE HTML PUBLIC “-//IETF//DTD HTML 2.0//EN”&gt; 201 Created CreatedResource /issue has been created. Apache/2.2.15 (CentOS) Server at 192.168.18.201 Port 8012&gt; 注，大家可以看到我们成功的上传了文件，说明nginx读写分离功能配置完成。最后，我们来查看一下上传的文件。 [root@web1 ~]# cd /var/www/html/[root@web1 html]# ll总用量 12drwxr-xr-x 2 root root 4096 9月 4 13:16 forum-rw-r–r– 1 root root 23 9月 3 23:37 index.html-rw-r–r– 1 apache apache 47 9月 4 14:06 issue``` 好了，到这里nginx的反向代理、负载均衡、页面缓存、URL重写及读写分离就全部讲解完成。希望大家有所收获]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Apache编译参数及编译安装方法]]></title>
      <url>%2Fposts%2F7608b15b%2F</url>
      <content type="text"><![CDATA[常用编译参数一览本文列举一些apache编译过程中常见的编译参数和编译步骤，大致如下所示 123456789101112131415161718192021222324252627282930313233343536373839404142434445./configure #配置源代码树–prefix=/usr/local/apache2 #体系无关文件的顶级安装目录PREFIX ，也就Apache的安装目录。–enable-module=so //打开 so 模块，so 模块是用来提 DSO 支持的 apache 核心模块–enable-deflate=shared //支持网页压缩–enable-expires=shared //支持 HTTP 控制–enable-rewrite=shared //支持 URL 重写–enable-cache //支持缓存–enable-file-cache //支持文件缓存–enable-mem-cache //支持记忆缓存–enable-disk-cache //支持磁盘缓存–enable-static-support //支持静态连接(默认为动态连接)–enable-static-htpasswd //使用静态连接编译 htpasswd – 管理用于基本认证的用户文件–enable-static-htdigest //使用静态连接编译 htdigest – 管理用于摘要认证的用户文件–enable-static-rotatelogs //使用静态连接编译 rotatelogs – 滚动 Apache 日志的管道日志程序–enable-static-logresolve //使用静态连接编译 logresolve – 解析 Apache 日志中的IP地址为主机名–enable-static-htdbm //使用静态连接编译 htdbm – 操作 DBM 密码数据库–enable-static-ab //使用静态连接编译 ab – Apache HTTP 服务器性能测试工具–enable-static-checkgid //使用静态连接编译 checkgid–disable-cgid //禁止用一个外部 CGI 守护进程执行CGI脚本–disable-cgi //禁止编译 CGI 版本的 PHP–disable-userdir //禁止用户从自己的主目录中提供页面–-with-mpm=worker // 让apache以worker方式运行–enable-authn-dbm=shared // 对动态数据库进行操作。Rewrite时需要。 以下是分门别类的更多参数注解，与上面的会有重复 用于apr的configure脚本的选项： 可选特性1234567891011121314151617181920212223242526272829303132333435363738394041--enable-experimental-libtool启用试验性质的自定义libtool--disable-libtool-lock取消锁定(可能导致并行编译崩溃)--enable-debug启用调试编译，仅供开发人员使用。--enable-maintainer-mode打开调试和编译时警告，仅供开发人员使用。--enable-profile打开编译profiling(GCC)--enable-pool-debug[=yes|no|verbose|verbose-alloc|lifetime|owner|all]打开pools调试--enable-malloc-debug打开BeOS平台上的malloc_debug--disable-lfs在32-bit平台上禁用大文件支持(large file support)--enable-nonportable-atomics若只打算在486以上的CPU上运行Apache ，那么使用该选项可以启用更加高效的基于互斥执行的原子操作。--enable-threads启用线程支持，在线程型的MPM上必须打开它--disable-threads禁用线程支持，如果不使用线程化的MPM ，可以关闭它以减少系统开销。--disable-dso禁用DSO支持--enable-other-child启用可靠子进程支持--disable-ipv6禁用IPv6支持 12345678910111213141516171819202122232425262728&gt; 可选的额外程序包--with-gnu-ld指定C编译器使用 GNU ld--with-pic只使用 PIC/non-PIC 对象[默认为两者都使用]--with-tags[=TAGS]包含额外的配置--with-installbuilddir=DIR指定APR编译文件的存放位置(默认值为：’$&#123;datadir&#125;/build’)--without-libtool禁止使用libtool连接库文件--with-efence[=DIR]指定Electric Fence的安装目录--with-sendfile强制使用sendfile(译者注：Linux2.4/2.6内核都支持)--with-egd[=DIR]使用EDG兼容的socket--with-devrandom[=DEV]指定随机设备[默认为：/dev/random] 用于apr-util的configure脚本的选项： 可选的额外程序包1234567891011121314151617181920212223242526272829303132333435363738394041--with-apr=PATH指定APR的安装目录(–prefix选项值或apr-config的路径)--with-ldap-include=PATHldap包含文件目录(带结尾斜线)--with-ldap-lib=PATHldap库文件路径--with-ldap=library使用的ldap库--with-dbm=DBM选择使用的DBM类型DBM=&#123;sdbm,gdbm,ndbm,db,db1,db185,db2,db3,db4,db41,db42,db43,db44&#125;--with-gdbm=PATH指定GDBM的位置--with-ndbm=PATH指定NDBM的位置--with-berkeley-db=PATH指定Berkeley DB的位置--with-pgsql=PATH指定PostgreSQL的位置--with-mysql=PATH参看INSTALL.MySQL文件的内容--with-sqlite3=PATH指定sqlite3的位置--with-sqlite2=PATH指定sqlite2的位置--with-expat=PATH指定Expat的位置或’builtin’--with-iconv=PATHiconv的安装目录 编译安装 任何一个程序包被编译操作依赖到时，需要安装此程序包的“开发”组件，其包名一般类似于name-devel-VERSION； 实验环境：CentOS 7 httpd-2.4 1234567891011121314151617~]# yum install pcre-devel apr-devel apr-util-devel openssl-devel~]# ./configure \--prefix=/usr/local/apache24 \--sysconfdir=/etc/httpd24 \--enable-so \--enable-ssl \--enable-rewrite \--with-zlib \--with-pcre \--with-apr=/usr \--with-apr-util=/usr \--enable-modules=most \--enable-mpms-shared=all \--with-mpm=prefork~]# make -j 4 &amp;&amp; make install]]></content>
    </entry>

    
  
  
</search>
